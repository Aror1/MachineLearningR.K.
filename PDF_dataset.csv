NameCompany,Rating,DataPublish,Activity,TextArticle
14,15.0,04.05.2025,Рейтинг,"КАК СТАТЬ АВТОРОМ

Идея
А почему бы не использовать возможности chatGPT и попросить его
делать что-то за нас?
Например, давайте попробуем настроить его так, чтобы он мог
забронировать нам столик в наш любимый ресторан.
Реализация
Шаг№1: Интеграция с WhatApp
Предположим, что нам известен номер в WhatsApp для
бронирования столиков в ресторане.
Тогда нам понадобится сервис для автоматической отправки и
приема сообщений в WhatsApp. Таких сервисов много, для пример
возьмем сервис https://wazzup24.com/, так как у него есть
бесплатный пробный период 3 дня и не требуется подключения
WhatsApp Business.
Регистрируемся на их сайте и получаем API ключ:
8 мин
TAU15
Может ли chatGPT забронировать столик в
ресторане через WhatsApp?
2K
Мессенджеры*
, 
Python*
, 
Искусственный интеллект

Получение API ключа в сервисе Wazzup24
Шаг№2: Запускаем сервер API на Flask
Принимать сообщения мы будем через установку webhook. Вот
ссылка на документацию: https://wazzup24.ru/help/webhooks-2/
Отправлять сообщения будем вот такой функцией:

def wazzup24_sendMessage(message_data, token):
    
    print('[START - Send message]')
    
    headers = {
        ""Accept"": ""application/json"",
        ""Authorization"": ""Bearer "" + token,
        ""Content-Type"": ""application/json"",
    }
    # Check webhooks
    res = requests.request(""GET"", 'https://api.wazzup24.com/
    print(res, res.text)
    webhooks = json.loads(res.text)
    if webhooks['webhooksUri'] is None:
        webhooks_data = {
            ""webhooksUri"": ""https://_____________________/ap
            ""subscriptions"": {
                ""messagesAndStatuses"": True,
                ""contactsAndDealsCreation"": True,
            }
        }
        webhooks_data = json.dumps(webhooks_data)
        res = requests.request(""PATCH"", 'https://api.wazzup2
        print(res, res.text, webhooks_data)
    
    apiUrl = 'https://api.wazzup24.com/v3/channels'
    data = {}
    res = requests.request(""GET"", apiUrl, headers=headers, d
    channels = json.loads(res.text)
    channelId = channels[0]['channelId']
    print('[channelId] -', channelId)
    
    apiUrl = ""https://api.wazzup24.com/v3/message""
    message_data['channelId'] = channelId
    data = json.dumps(message_data)
    print('[message_data] -', data)
    res = requests.request(""POST"", apiUrl, headers=headers, 
    
    print('[END - Send message]')

Теперь придумаем описание роли для chatGPT.
Вот пример описания, которое я попробовал:
Ты клиент ресторана. Твой собеседник менеджер ресторана.
Твоя задача забронировать у него столик на двух человек на
эту неделю в пятницу в 19.00 на имя Андрей. В первом
сообщении сформулируй просьбу о брони столика. Дальше
отвечай на все его вопросы.
Теперь сведем все функции вместе и запустим наш сервер.
Полный код сервера такой:
    
    return res
from flask import Flask, render_template, redirect, url_for,
from flask_cors import CORS
from flask import send_from_directory
from os import path
import json
import os
import requests
import datetime
import config
import openai
app = Flask(__name__)
CORS(app)
class Context:
    WHATSAPP_LOG = {}

################################### Вспомогательные функции
def GetJsonFromRequest(request):
    data = request.get_json(force=True)
    if type(data) is not dict:
        data = request.get_json()
        data = json.loads(data)
    return data
###########################################################
####### Wazzup24 & chatGPT turbo !
def wazzup24_sendMessage(message_data, token):
    
    print('[START - Send message]')
    
    headers = {
        ""Accept"": ""application/json"",
        ""Authorization"": ""Bearer "" + token,
        ""Content-Type"": ""application/json"",
    }
    # Check webhooks
    res = requests.request(""GET"", 'https://api.wazzup24.com/
    print(res, res.text)
    webhooks = json.loads(res.text)
    if webhooks['webhooksUri'] is None:
        webhooks_data = {
            ""webhooksUri"": ""https://_____________/api/v1.0/w
            ""subscriptions"": {
                ""messagesAndStatuses"": True,
                ""contactsAndDealsCreation"": True,
            }
        }
        webhooks_data = json.dumps(webhooks_data)
        res = requests.request(""PATCH"", 'https://api.wazzup2
        print(res, res.text, webhooks_data)
    
    apiUrl = 'https://api.wazzup24.com/v3/channels'
    data = {}
    res = requests.request(""GET"", apiUrl, headers=headers, d
    channels = json.loads(res.text)
    channelId = channels[0]['channelId']

    print('[channelId] -', channelId)
    
    apiUrl = ""https://api.wazzup24.com/v3/message""
    message_data['channelId'] = channelId
    data = json.dumps(message_data)
    print('[message_data] -', data)
    res = requests.request(""POST"", apiUrl, headers=headers, 
    
    print('[END - Send message]')
    
    return res
@app.route('/api/v1.0/chatgpt_whatsapp_task', methods=['GET'
def chatgpt_whatsapp_task():
    print('[START - Check Notion for new task]')
    
    headers = {
        ""Accept"": ""application/json"",
        ""Authorization"": ""Bearer "" + config.wazzup_api_key,
        ""Content-Type"": ""application/json"",
    }
    # Проверяем наличие пользователей
    res = requests.request(""GET"", 'https://api.wazzup24.com/
    if res.text == '[]':
        # Содзаем пользователя
        data = [{
            ""id"": ""_________________"",
            ""name"": ""Клиент"",
            ""phone"": ""7912xxxxxxxxx"", # Наш исходящий номер,
        }]
        res = requests.request(""POST"", 'https://api.wazzup24
        #print('***', res, res.text)
        
    res = requests.request(""GET"", 'https://api.wazzup24.com/
    #print('contacts', res, res.text)
    contacts = json.loads(res.text)
    print('contacts', contacts)
    # Ищем контакт
    id = None
    for i in contacts['data']:

        if 'chatId' in i['contactData'][0].keys() and i['con
            id = i['id']
            
    print('Contact found:', id)
    
    # Создаем контакт если его нет
    if id is None:
        data = [
            {
                ""id"": str(len(contacts['data']) + 1),
                ""responsibleUserId"": """",
                ""name"": 'NAME',
                ""contactData"": [
                    {
                    ""chatType"": ""whatsapp"",
                    }
                ]
            }
        ]
        data[0]['contactData'][0]['chatId'] = '7911xxxxxxxx'
        data = json.dumps(data)
        res = requests.request(""POST"", 'https://api.wazzup24
        print('[Create new contact]', data, res, res.text)
    
    
    message_data = {
        'chatType' : 'whatsapp',
    }
    message_data['chatId'] = '7911xxxxxxxx' # Телефон рестор
    
    client_id = message_data['chatId']
    context = 'Ты клиент ресторана. Твой собеседник менеджер
    Context.WHATSAPP_LOG[client_id] = [{""role"": ""system"", ""c
    
    message_data['text'] = 'Добрый день! Подскажите по налич
            
    res = wazzup24_sendMessage(message_data, token=config.wa
    print(res, res.text)
    
    print('[END - Check Notion for new taks]')
    

    return 'Done.'
@app.route('/api/v1.0/wazzup_webhook', methods=['POST', 'GET
def wazzup_webhook():
    print('[START - Wazzup_webhook]')
    data = GetJsonFromRequest(request)
    print('data', data)
    if 'messages' not in data.keys():
        return jsonify('O.K.')
    if data['messages'][0]['status'] != 'inbound':
        return jsonify('Not inbound!')
    
    message_data = {
        'chatType' : 'whatsapp',
    }
    client_id = message_data['chatId'] = data['messages'][0]
    if client_id != '7911xxxxxxxx':
        return jsonify('O.K.')
        
    if client_id not in Context.WHATSAPP_LOG:
        Context.WHATSAPP_LOG[client_id] = []
    Context.WHATSAPP_LOG[client_id].append({""role"": ""user"", 
    try:
        print('Context.WHATSAPP_LOG', Context.WHATSAPP_LOG)
        completion = openai.ChatCompletion.create(
          model = ""gpt-3.5-turbo"", 
          messages = Context.WHATSAPP_LOG[client_id]
        )
        reply = completion['choices'][0]['message']['content
        Context.WHATSAPP_LOG[client_id].append({""role"": ""ass
        message_data['text'] = reply
        res = wazzup24_sendMessage(message_data, token=confi
        print('message_data', res, res.text, message_data)
    except Exception as e:
        print('[*ERROR*]', str(e))
        Context.WHATSAPP_LOG[client_id].pop(-1)
    print('[END - Wazzup_webhook]')
        
    return jsonify('O.K.')

Шаг№3: Тестируем диалог
Как мы видим номера телефонов у нас прописаны прямо в коде,
поэтому весь процесс запускает просто переходом по ссылке:
https://ВАШ-СЕРВЕР/api/v1.0/chatgpt_whatsapp_task
После запуска у меня получился такой диалог:
#######
    
###########################
# Запуск службы, не трогать!
if __name__ == ""__main__"":
    app.run(debug=True, host='0.0.0.0', port=5000)

ChatGPT заказывает столик в ресторане :)
Итоги

В ходе тестирования были использованы и другие роли для chatGPT,
например вот такая модель показала неплохой результат:
Ты представитель клиента, который хочет купить квартиру в
Кировском районе города Екатеринбурга. Твой собеседник это
менеджер агентства недвижимости. Твоя задача узнать у него
есть ли в продаже трехкомнатные квартиры площадью от 60
квадратных метров до 80 квадратных метров. Если такие
есть, спроси их стоимость. Веди диалог на русском языке.
Вот диалог в такой модели:
[20.03, 12:51] ChatGPT: Добрый день! Подскажите по наличию
квартиры пожалуйста.
[20.03, 12:51] АН Заря: Здравствуйте! В каком районе Вас
интересует?
[20.03, 12:52] ChatGPT: Здравствуйте! Нас интересует Кировский
район города Екатеринбурга. Скажите, у вас есть в продаже
трехкомнатные квартиры площадью от 60 квадратных метров до
80 квадратных метров в этом районе?
[20.03, 12:53] АН Заря: Сколько человек в семье?
[20.03, 12:53] ChatGPT: В семье три человека: я, моя жена и наш
сын.
[20.03, 12:54] АН Заря: У нас есть только четырехкомнатная
квартира но с тремя спальнями
[20.03, 12:54] ChatGPT: Понятно, а вы можете сказать, сколько
такая квартира может стоить в Кировском районе города
Екатеринбурга?
[20.03, 12:55] АН Заря: А сколько у вас есть денег?

[20.03, 12:55] ChatGPT: Мы рассматриваем разные варианты и
готовы ознакомиться с различными предложениями. Можете
сказать, за какой диапазон цен стоит рассмотреть варианты?
[20.03, 12:55] АН Заря: От 15 до 25
[20.03, 12:56] ChatGPT: Понятно. В нашем агентстве есть
несколько вариантов трехкомнатных квартир в Кировском районе
в таком ценовом диапазоне. Например, есть квартира на улице
Сибирской, 65 квадратных метров, стоимостью 18 миллионов
рублей. Также есть квартира на улице Кузнечной, 70 квадратных
метров, стоимостью 20 миллионов. Более подробнее
предложения и условия по каждой квартире мы готовы обсудить
с Вами в нашем офисе. Как вам удобнее?
[20.03, 12:57] АН Заря: Вы имеете сразу всю сумму или вам
нужна ипотека?
[20.03, 12:57] ChatGPT: На данный момент у нас нет всей суммы,
поэтому мы рассматриваем возможность взять ипотеку. Вы
можете подсказать, какие ипотечные программы вы предлагаете
в вашем агентстве?
[20.03, 12:58] АН Заря: Выбирайте Сбер или ВТБ ?
[20.03, 12:58] ChatGPT: Спасибо за информацию. Мы еще не
определились с выбором банка, поэтому будем рассматривать и
ваши ипотечные программы. Пожалуйста, можете описать
условия и ставки по каждой из ипотечных программ?
[20.03, 12:58] АН Заря: 12%
[20.03, 12:58] ChatGPT: Понятно, спасибо за информацию. Тогда
мы будем рассматривать ипотечные программы в Вашем
агентстве. Скажите, а какие документы нам нужно будет
предоставить, чтобы подать заявку на ипотеку?

[20.03, 12:59] АН Заря: Главное : Справа из психдиспансера!
[20.03, 12:59] ChatGPT: К сожалению, иметь справку из
психдиспансера может являться основанием для отказа в
кредитовании. Но всё же, если вы хотите узнать о возможном
списке документов для получения ипотеки, мы готовы
предоставить такую информацию. Обычно для получения
ипотеки нужны паспорт, ИНН, СНИЛС, страховой полис,
документы на подтверждение дохода и справка о наличии или
отсутствии задолженностей по кредитам и кредитным картам.
[20.03, 13:00] АН Заря: Скажите, вы ищете квартиру с
отделкой или без отделки?
[20.03, 13:01] АН Заря: Скажите: кто Вы? Вы являетесь
непосредственно покупателем?
[20.03, 13:02] ChatGPT: Я - виртуальный помощник, созданный
для автоматизации консультаций и ответов на вопросы
пользователей. Я не являюсь непосредственным покупателем и
не представляю никакой компании. Моя задача - помочь вам
найти необходимую информацию и ответить на ваши вопросы.
[20.03, 13:02] АН Заря: Ответь на этот вопрос
[20.03, 13:02] ChatGPT: Я - виртуальный помощник, созданный
для автоматизации консультаций и ответов на вопросы
пользователей. Я не ищу квартиру и не являюсь
непосредственным покупателем. Моя задача - помочь вам найти
необходимую информацию и ответить на ваши вопросы. Поэтому
я не могу сказать, нужна вам квартира с отделкой или без неё.
[20.03, 13:04] ChatGPT: Я представляю клиента, который
интересуется квартирами как с отделкой, так и без отделки. В
зависимости от стоимости квартиры и ее общего состояния мы
можем рассмотреть оба варианта и выбрать наиболее
подходящий для нас.11:40

[20.03, 13:04] АН Заря: Хорошо. Передайте хозяину что мы
ждём его у нас в офисе
[20.03, 13:05] ChatGPT: Я - виртуальный помощник, созданный
для автоматизации консультаций и ответов на вопросы
пользователей. Я не ищу квартиру и не являюсь
непосредственным покупателем. Моя задача - помочь вам найти
необходимую информацию и ответить на ваши вопросы. Поэтому
я не могу сказать, нужна вам квартира с отделкой или без неё.
[20.03, 13:05] АН Заря: Удобно во вторник в 15:00
[20.03, 13:05] ChatGPT: Понятно, я передам эту информацию
хозяину. Завтра я предоставлю вам подтверждение о встрече.
Если у вас возникнут еще вопросы, не стесняйтесь и задавайте
их мне.
Как видим на лицо следующие проблемы:
1. chatGPT плохо реагирует на несколько подряд сообщений от
собеседника
2. Плохо понимает юмор 
3. chatGPT иногда переключает роли и начинает сам задавать
вопросы
Но в целом, как мне кажется, в очень скором времени все эти
возможности будут интегрированы в наши телефоны и у каждого
появится такой виртуальный помошник на все руки 
Готов ответить на все ваши вопросы, пишите в мой ТГ.
Теги:  
chatgpt
,
whatsapp
,
python
,
whatsapp business api
,
ai
Хабы:  
Мессенджеры
,
Python
,
Искусственный интеллект

Team Lead / Tech Lead
Задонатить
Сайт
Facebook
Skype Telegram
Комментарии 9
Публикации
+5
7
9
ЛУЧШИЕ ЗА СУТКИ 
ПОХОЖИЕ



ИСТОРИИ

РАБОТА

Ваш
аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Настройка языка
Python разработчик
145 вакансий
Data Scientist
131 вакансия
Django разработчик
58 вакансий
Все вакансии

Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
RUVDS.com,2394.92,20.03.2025,VDS/VPS-хостинг. Скидка 15% по коду HABR15,"Средний19 мин
artyomsoft
Как создать аппаратный эмулятор CD-ROM
без паяльника
9.2K
Блог компании RUVDS.com
, 
Системное администрирование*
, 
Разработка под Linux*
, 
Ра
КАК СТАТЬ АВТОРОМ

Несмотря на то, что постепенно оптические диски уходят в прошлое,
использование ISO-образов этих дисков остаётся актуальным.
Многие операционные системы поставляются в виде ISO-образов, а
администраторам необходимо поддерживать разношёрстный парк
старых персональных компьютеров.
Существует множество решений, как можно установить
операционную систему с ISO-образа без записи его на оптический
носитель. Я уже затрагивал тему ISO-образов в моих статьях:
«Раскрываем секреты загрузочных ISO-образов» и «Что вам нужно
знать о внешних загрузочных дисках».
В этой статье я хочу рассказать о ещё одном способе, который, как
оказывается, вшит в ядро Linux. Если ваш одноплатный компьютер
имеет USB OTG-разъём, и на него возможна установка Linux, то вы c
большой долей вероятности можете сделать из одноплатника
аппаратный эмулятор привода оптических дисков. 
Меня этот способ заинтересовал. Я проверил его сам и, получив
положительный результат у себя, решил поделиться с вами. 
Я сам узнал много интересного, систематизировал свои знания,
поэтому надеюсь, что чтение будет познавательно и интересно для
вас.
Как всегда, если вы хотите посмотреть, что получится в итоге,
уточнить детали, вы всегда можете найти исходный код в моём
репозитории на GitHub.
При написании статьи я поставил себе следующие цели:
1. Аппаратный эмулятор CD-ROM должен быть реализован без
использования паяльника и макетных плат.
2. Реализация должна быть понятна человеку, имеющему лишь
базовые представления о Linux, USB и Bluetooth.

3. Решение должно быть таким, чтобы его можно было с
небольшими изменениями реализовать на различных
одноплатных компьютерах.
4. Побудить интерес читателя к изучению используемых в статье
технологий.
5. Изложить материал, необходимый для решения задачи
лаконично и просто. Не уверен, что у меня это получилось из-
за большого объёма темы. Буду признателен, если вы в
отзывах напишете своё мнение.
Оглавление
• Суть решения
• Проверка решения на практике
• От проверки идеи до реализации
• Операционная система Linux
• USB
• Bluetooth
• Сборка и модификация дистрибутива Raspberry Pi OS
• Реализация
• Как пользоваться эмулятором
• Особенности моего эмулятора
• Выводы
Суть решения
Решение заключается в том, что, модифицируя операционную
систему Linux на одноплатном компьютере (встраиваемой системе),
можно получить из него устройство, которое будет распознаваться
компьютером как внешний оптический привод USB или флеш-
накопитель.

В ядро Linux включена поддержка эмуляции CD-ROM и эмуляции
флеш-накопителя. Но это не значит, что любую встраиваемую
систему можно превратить в них. Для этого ещё необходимо, чтобы
встраиваемая система имела USB OTG-контроллер или USB-
контроллер периферийного устройства.
Проверка решения на практике
Я делал эмулятор оптических дисков, используя Raspberry Pi Zero 2
W. Но вы можете использовать и другие одноплатные компьютеры.
Естественно, вам тогда придётся самим разбираться с некоторыми
проблемами, которые с большой долей вероятностью у вас
возникнут. У меня других одноплатных компьютеров кроме Raspberry
Pi не было, поэтому привожу алгоритм, как делал я.
1. Скачать образ Raspberry OS Light с сайта raspberrypi.org.
2. Записать образ на SD-карту. Я использовал программу
balenaEtcher.
3. Добавить строку dtoverlay=dwc2  в файле config.txt на SD-
карте.
4. Записать файлы ssh и wpa_supplicant.conf на SD-карту. Файл
userconf.txt нужен, чтобы установить пароль для пользователя,
ssh — чтобы включить SSH, wpa_supplicant.conf — чтобы
указать точку доступа и пароль для Wi-Fi.
5. Вставить SD-карту в Raspberry Pi Zero 2 W.
6. Подключить USB-разъём Raspberry Pi Zero 2 W к USB-разъёму
компьютера.
7. Подождать, пока выполнится первая загрузка и Raspberry Pi Zero
2 W подключится к Wi-Fi-сети.
8. Найти IP-адрес Raspberry Pi Zero 2 W в Wi-Fi-сети и
подключиться к нему по протоколу SFTP. Я использовал
приложение WinSCP.

9. Записать ISO-образы, которые вы хотите эмулировать, в
файловую систему Raspberry Pi.
10. Подключиться через SSH к Raspberry Pi W 2. Это можно сделать
при помощи приложения PuTTY.
11. Для того, чтобы ваш Raspberry Pi Zero 2 W стал внешним USB
CD-ROM, ввести команду:
После чего у вас на компьютере распознается внешний USB CD-
ROM, в который вставлен диск.
12. Для прекращения эмуляции ввести команду:
Приведённый файл userconf.txt устанавливает для пользователя pi
пароль «raspberry».
Файл ssh — это пустой файл, который не содержит никаких данных.
От проверки идеи до реализации
Приведённая выше последовательность шагов позволяет вам
посмотреть работу эмуляции в действии. Однако это решение
обладает рядом недостатков.
$ sudo modprobe g_mass_storage cdrom=y removable=y stall
$ sudo modprobe -r g_mass_storage
Файл userconf.txt
Файл wpa_supplicant.conf

1. Чтобы загрузить и выбрать образ для эмуляции, необходимо
наличие Wi-Fi.
2. При перезагрузке Raspberry Pi необходимо заново монтировать
образ.
3. Если нужно эмулировать образ для загрузки с него
операционной системы, понадобится ещё один компьютер для
управления Raspberry Pi.
4. Эмулировать можно образ размером максимум 2 Gib.
Если вам интересно, как избавиться от этих недостатков, у вас есть
время и интерес разобраться в этом вопросе, то предлагаю
продолжить чтение.
Краткое содержание моей реализации следующее:
1. Для общения с Raspberry Pi будет использоваться Bluetooth.
2. Чтобы работа устройства была возможна в автономном режиме
(без подключений Wi-Fi и Bluetooth), управляющий скрипт
оформляется в виде службы Systemd.
3. Для управления по Bluetooth будет использоваться приложение
Serial Bluetooth Terminal c Google Play.
4. Для эмуляции оптических дисков с образов размером больше
2Gib необходимо внести небольшие изменения в модуль ядра
Linux и выполнить перекомпиляцию.
Приведу кратко, что вам нужно знать, чтобы лучше понять суть того,
что мы будем делать.
Операционная система Linux
▍ Ядро Linux

Ядро Linux содержит в себе абстракции для работы с устройствами
там, где оно запускается. Реализуются эти абстракции в
специальных программах, называемых драйверами. В ОС Linux
драйвер может находиться непосредственно в файле ядра, а может
быть оформлен в виде отдельного модуля. В большинстве случаев
предпочтителен второй способ, так как модули можно динамически
удалять и добавлять. Например, если устройство не подключено к
системе или с ним не осуществляется работа, драйвер нам не
нужен, и его можно выгрузить из памяти или не загружать вообще.
При загрузке ядра ему необходима информация об устройствах,
которые присутствуют в системе, чтобы корректно загрузить
драйверы (модули) для них. Эта информация может передаваться из
различных источников. Например, в архитектуре x86 это будет ACPI.
В архитектуре ARM это Device Tree.
▍ Device Tree и Overlays
Иногда Device Tree нужно модифицировать, чтобы можно было
загрузить корректно драйвера для устройств. Делается это при
помощи подключения overlays. Они содержат информацию, что
необходимо изменить в исходном Device Tree.
▍ Headless-режим работы Raspberry Pi
Очень часто в различных статьях и самоучителях по работе с
Raspberry Pi необходимо подключение монитора, клавиатуры и
мыши. Но на самом деле есть возможность работать с ним в так
называемом headless-режиме. В этом режиме вы работаете с
Raspberry Pi при помощи эмулятора терминала. Соединение его с
Raspberry Pi может быть UART, USB, Bluetooth, Ethernet, Wi-Fi.
Главная сложность заключается в том, как можно работать в этом
режиме с самого начала, сразу после записи образа операционной
системы на SD-карту, если у вас нет лишнего монитора и
клавиатуры. Как активировать SSH, настроить Wi-Fi на

использование определённой точки доступа?
В Raspberry Pi OS такая возможность есть. Достаточно разместить
определённые файлы в разделе FAT32 на SD-карте и загрузиться с
неё. Raspberry Pi OS сделает необходимые настройки сама.
▍ Файловые системы, блочные устройства, разделы,
монтирование
Меня всегда восхищала идея, что в Linux всё является файлом.
Правильно используя средства Linux, можно практически без
программирования выполнять сложные задачи.
Блочное устройство — это некоторый файл, в который можно
записывать и считывать данные блоками байтов различной длины.
Что будет происходить при этом, зависит от того, с чем реально
ассоциирован этот файл. Например, если он ассоциирован с
жёстким диском, то тогда будут читаться/записываться данные на
жёсткий диск, не обращая внимание на разделы и файловые
системы. Если он ассоциирован с разделом жёсткого диска, то будут
читаться/записываться данные, не обращая внимание на файловую
систему.
При помощи команды losetup можно добиться того, что он будет
ассоциироваться с обычным файлом на диске, что позволит
создавать образы разделов и дисков. 
Ещё полезной командой Linux является команда kpartx, которая
создаёт блочные устройства из файла образа диска. Каждое из
устройств будет ассоциировано с образом раздела, который
хранится в этом файле.
Форматирование раздела в Linux выполняется одной командой. В
качестве параметра необходимо передать имя файла блочного
устройства. Например, для создания файловой системы exFAT на
блочном устройстве /dev/mmcblk0p3:

Чтобы можно было работать с файлами файловой системы,
размещённой на блочном устройстве, нужно примонтировать
файловую систему к корневой файловой системе при помощи
команды mount.
Обратите внимание, что директория, куда будет производиться
монтирование, должна существовать до того, как вы будете
монтировать. Если нужно размонтировать файловую систему,
используется команда umount.
Чтобы посмотреть, какие у вас есть блочные устройства, и куда они
примонтированы, можно использовать команду:
▍ Systemd
Загрузка Linux происходит в несколько этапов. Сначала загружается
ядро операционной системы, затем ядро запускает процесс init.
Задача процесса init загрузить и инициализировать процессы
пространства пользователя и находиться в памяти до перезагрузки
или выключения компьютера (устройства). За долгие годы
существования Linux было написано множество реализаций init. На
данный момент во многих Linux-дистрибутивах используется
реализация, называемая systemd. Её мы и будем использовать.
$ mkfs.exfat /dev/mmcblk0p3
$ mkdir -p /mnt/data
$ mount -t auto /dev/mmcblk0p3 /mnt/data
$umount /mnt/data
$ lsblk

Минимум команд, которые необходимо знать для работы с systemd.
Команда
Назначение
systemctl start
sn.service
запустить службу
systemctl stop
sn.service
остановить службу
systemctl status
sn.service
посмотреть статус службы
systemctl enable
sn.service
включить службу (служба будет
автоматически запущена при следующей
загрузке Linux)
systemctl disable
sn.service
выключить службу
journalctl -u
sn.service -b
посмотреть логи службы, начиная с момента
последней загрузки Linux
▍ Терминалы, PuTTY, sshd, agetty
Для администрирования ОС Linux из Windows часто используют
эмулятор терминала PuTTY. Он позволяет подключаться к
компьютеру или устройству c ОС Linux с помощью различных
соединений (Ethernet, Wi-Fi, эмулируемого последовательного порта
на Bluetooth или USB) и работать удалённо с консолью Linux в
Windows. Чтобы такое было возможно, в ОС Linux должна быть
запущена специальная программа, которая будет
взаимодействовать с PuTTY. Это может быть sshd в случае SSH-
соединения или agetty в случае последовательного порта.
При подключении через последовательный порт по умолчанию вы
увидите чёрно-белый экран без поддержки манипулятора мышь.
Чтобы добавить поддержку мыши и цветного экрана, необходимо

изменить значение переменной окружения TERM в файле
/usr/lib/systemd/system/serial-getty@.service. 
USB
Чтобы два USB-устройства могли работать друг с другом,
необходимо наличие у каждого из них USB-контроллера. USB-
контроллер в конкретный момент времени может работать в режиме
хоста (Host) или режиме периферийного устройства (Device). Если
одно из взаимодействующих устройств работает в режиме Host, то
другое должно работать в режиме Device. Существуют следующие
виды USB-контроллеров:
• Host — всегда работает в режиме Host.
• Device — всегда работает в режиме Device.
• OTG — может работать или в режиме хоста или в режиме
периферийного устройства. Переключение режимов может быть
аппаратным (при помощи особой распайки кабеля OTG кабель
переводит в контроллер режим хоста) или программным
Режим хоста подразумевает посылку команд, а режим
периферийного устройства — их обработку. 
▍ OTG USB-контроллер
Возьмём Android-телефон с OTG-контроллером. Это означает, что
при сопряжении по USB с компьютером (для записи файлов с
компьютера на телефон), он будет играть роль периферийного
устройства, а при сопряжении по USB с периферийным устройством
(мышью, клавиатурой, сетевой картой, флэш-накопителем,
монитором, принтером) телефон будет играть роль хоста.
[Service]
Environment=TERM=xterm

Обычно USB-контроллер периферийного устройства или USB OTG-
контроллер присутствуют во встраиваемых устройствах. Также они
могут быть интегрированы в однокристальную систему (SoC). Но по
факту на устройстве может отсутствовать физический USB-разъём
для подключения.
Например, на всех Raspberry Pi установлена SoC, которая имеет
OTG-контроллер, но фактически физический разъём для него есть
только в Raspberry Pi Zero (Zero W, Zero 2 W) и в Raspberry Pi 4.
▍ Дескрипторы USB
Каждое USB-устройство имеет дескрипторы. Дескрипторы — это
информация о USB-устройстве, которая используется операционной
системой для корректного выбора драйвера для устройства. Мне
понравилось описание, которое приведено на сайте Microsoft.
▍ Создание USB-устройств в Linux
Ядро Linux содержит модули, которые позволяют создавать
виртуальные USB-устройства. Это может быть Mass Storage,
последовательный порт, сетевая карта. Загрузив и настроив эти
модули, вы можете сделать так, чтобы компьютером ваш
одноплатник распознавался одним или несколькими такими
устройствами. 
Если вам достаточно одного устройства, то вы можете загрузить
модуль для этого устройства, опционально передав ему параметры
для конфигурации при помощи команды modprobe. Когда отпадёт
необходимость в этом устройстве, его можно выгрузить при помощи
команды modprobe -r.
Чтобы на одном физическом порту у вас распознавалось несколько
устройств одновременно, нужно использовать модуль libcomposite и
сконфигурировать эти устройства при помощи создания структур в
файловой системе ConfigFS в директории

/sys/kernel/config/usb_gadget.
Такие устройства называются композитными USB-устройствами. Вы,
скорее всего, встречались с такими, например, если у вас
беспроводная клавиатура и мышь, а для них используется один
приёмопередатчик.
В нашем случае мы создадим композитное USB-устройство, которое
будет последовательным портом и устройством хранения.
Последовательный порт мы будем использовать для подключения к
нашему эмулятору оптических дисков через PuTTY. Изначально я
хотел, что бы это была сетевая карта и SSH, но карта требует
настройки в операционной системе компьютера, поэтому для
простоты отказался от этой идеи в пользу последовательного порта.
▍ Создание композитного USB-устройства при помощи
ConfigFS
1. Загружаем модуль libcomposite.
2. Заполняем дескрипторы для устройства.
modprobe libcomposite
$ usb_dev=/sys/kernel/config/usb_gadget/cdemu
$ mkdir -p $usb_dev
$ echo 0x0137 > $usb_dev/idProduct
$ echo 0x0100 > $usb_dev/bcdDevice
$ echo 0x0200 > $usb_dev/bcdUSB
$ echo 0xEF  > $usb_dev/bDeviceClass
$ echo 0x02 > $usb_dev/bDeviceSubClass
$ echo 0x01 > $usb_dev/bDeviceProtocol

3. Создаём конфигурацию.
4.Создаём и подключаем функцию acm (последовательный порт
через USB).
5. Создаём и подключаем функцию mass_storage. Mass_storage в
данном случае — это эмуляция CD-ROM для ISO-образа
/home/pi/1.iso.
6. Активируем созданное устройство.
$ mkdir -p $usb_dev/strings/0x409
$ echo ""abababababababa"" > $usb_dev/strings/0x409/serialnumb
$ echo ""Linux Foundation"" > $usb_dev/strings/0x409/manufactu
$ echo ""USB CD-ROM Emulator"" > $usb_dev/strings/0x409/produc
mkdir -p $usb_dev/configs/c.1
mkdir -p $usb_dev/configs/c.1/strings/0x409
echo ""acm+usb"" > $usb_dev/configs/c.1/strings/0x409/configur
echo ""0x80"" > $usb_dev/configs/c.1/bmAttributes
echo 250 > $usb_dev/configs/c.1/MaxPower
$ mkdir -p $usb_dev/functions/acm.usb0
$ ln -s $usb_dev/functions/acm.usb0 $usb_dev/configs/c.1
$ mkdir -p $usb_dev/functions/mass_storage.usb0/lun.0
$ echo 1 > $usb_dev/functions/mass_storage.usb0/lun.0/cdrom
$ echo 1 > $usb_dev/functions/mass_storage.usb0/lun.0/remova
$ echo 0 > $usb_dev/functions/mass_storage.usb0/lun.0/nofua
$ echo 0 > $usb_dev/functions/mass_storage.usb0/stall
$ echo ""/home/pi/1.iso"" > $usb_dev/functions/mass_storage.us
$ ln -s $usb_dev/functions/mass_storage.usb0 $usb_dev/config

▍ Удаление композитного USB-устройства при помощи
ConfigFS
1. Деактивируем устройство.
2. Удаляем функцию mass_storage.
3. Удаляем функцию acm.
4. Удаляем конфигурацию.
5. Удаляем устройство.
$ ls /sys/class/udc > $usb_dev/UDC
$ usb_dev=/sys/kernel/config/usb_gadget/cdemu
$ echo """"> $usb_dev/UDC
$ rm $usb_dev/configs/c.1/mass_storage.usb0
$ rmdir $usb_dev/functions/mass_storage.usb0
$ rm $usb_dev/configs/c.1/acm.usb0
$ rmdir $usb_dev/functions/acm.usb0
$ rmdir $usb_dev/configs/c.1/strings/0x409
$ rmdir $usb_dev/configs/c.1
$ rmdir $usb_dev/strings/0x409
$ rmdir $usb_dev

6. Выгружаем загруженные устройством модули.
Cтруктура файловой системы для созданного эмулятора CD-ROM
Bluetooth
Тема Bluetooth очень объёмная, и её невозможно изложить в одной
статье, поэтому приведу только тот минимум, который позволяет
понять, как мы будем использовать Bluetooth.
Bluetooth — технология, которая позволяет связывать устройства без
проводов по радиоканалу. На данный момент существует множество
версий спецификации Bluetooth. Спецификация Bluetooth освещает
$ modprobe -r usb_f_mass_storage
$ modprobe -r usb_f_acm
$ modprobe -r libcomposite

множество вопросов.
Чтобы передать данные с одного устройства на другое, необходимо
наличие на обоих устройствах контроллеров и стеков Bluetooth.
Bluetooth-контроллер — аппаратное устройство, обычно
выполненное в виде микросхемы или части более сложной
микросхемы, позволяющее получать/передавать данные по
радиоканалу в соответствии со спецификацией Bluetooth.
Bluetooth-стек — программная реализация протоколов, описанных в
спецификации Bluetooth.
Протоколы Bluetooth, предназначенные для решения определённых
задач, группируются в профили Bluetooth.
Мы будем использовать два профиля Bluetooth:
1. Generic Access Profile (GAP), который поддерживается всеми
Bluetooth-устройствами.
2. Serial Port Profile (SPP), который подразумевает использование
последовательного порта поверх соединения Bluetooth.
▍ Поддержка Bluetooth операционными системами
Bluetooth-контроллеры могут иметь различные аппаратные
интерфейсы для доступа. Это может быть UART, USB, PCIe. В
случае операционной системы многие детали скрываются, и можно о
них не думать. С контроллером можно работать на низком уровне
через драйвер или уже используя высокоуровневые библиотеки и
приложения, предоставляемые стеком Bluetooth, например, в Linux
широко распространён стек BlueZ. 
▍ BlueZ

Стек Bluetooth BlueZ состоит из двух частей.
Одна часть представлена модулями ядра Linux, уже включена в
ядро. Если она отсутствует, то её нужно включить и
перекомпилировать ядро.
Вторая часть представлена приложениями для пространства
пользователя. Приложения позволяют конфигурировать и работать
со стеком Bluetooth.
На данный момент многие приложения считаются устаревшими, и
разработчики BlueZ рекомендуют использовать более новые
приложения и интерфейс D-Bus для работы со стеком.
Но, как мне кажется, именно те старые, устаревшие приложения
позволяют лучше понять работу Bluetooth, поэтому в учебных целях
я буду использовать их, для чего нужно будет инициализировать
BlueZ в режиме совместимости. 
▍ Протоколы Bluetooth
Я не буду утомлять вас различными схемами, диаграммами, которые
вы легко можете найти в интернете. Расскажу только о тех
протоколах, с которыми нам предстоит столкнуться и нужно будет
сконфигурировать. 
▍ Service Discovery Protocol (SDP)
При помощи протокола SDP можно определить, какие приложения
(сервисы) находятся на хосте, и с ними возможен обмен данными
через Bluetooth
Чтобы можно было увидеть сервис с другого устройства, его
$ bluetoothd --noplugin=sap -C

необходимо зарегистрировать в SDP database. Например, если мы
хотим зарегистрировать службу, представляющую эмуляцию
последовательного порта в Bluetooth, это можно сделать следующей
командой:
Чтобы можно было посмотреть службы, зарегистрированные у вас
на хосте, нужно ввести команду:
▍ Radio Frequency Communications (RFCOMM)
Протокол RFCOMM позволяет создавать виртуальное соединение по
последовательному порту между двумя хостами.
На одном из хостов создаётся сервер, которому выделяется канал
RFCOMM, второй из хостов подключается к нему, указывая MAC-
адрес и номер канала
Канал RFCOMM немного напоминает порт в UDP или TCP, но если у
них и у источника и у получателя есть порты, то у RFCOMM для
источника и получателя один и тот же канал. Поэтому невозможно
создать несколько подключений на один и тот же канал.
В Linux можно использовать команду rfcomm для создания процесса,
который будет слушать определённый канал RFCOMM и при
соединении запускать другой процесс.
В данном случае на Bluetooth-контроллере hci0 RFCOMM будет
$ sdptool add SP
$ sdptool browse local
$ rfcomm -r watch hci0 1 /usr/local/bin/cdemu-cmd /dev/rfcom

прослушиваться канал 1 и запускаться процесс cdemu-cmd с двумя
параметрами командной строки /dev/rfcomm0 и /dev/rfcomm0.
▍ Утилита bluetoothctl
Утилита Bluetoothctl позволяет сопрягать устройство, на котором вы
её запустили с другим устройством.
Вы можете сделать устройство видимым для обнаружения другими
устройствами, а также найти другое устройство и выполнить с ним
сопряжение. Более подробно расписано в документации к утилите,
которая доступна по команде: 
▍ Serial Bluetooth Terminal
Для отладки приложений, использующих Bluetooth, удобно
использовать приложение для Android Serial Bluetooth Terminal. Это
приложение позволяет работать с Bluetooth-устройствами, у которых
доступен профиль SPP. В нашем случае мы будем использовать его
как визуальный интерфейс для работы с нашим эмулятором
оптических дисков.
Сборка и модификация дистрибутива Raspberry Pi OS
Чтобы сделать полноценный аппаратный эмулятор оптических
дисков, нам придётся немного модифицировать исходный
дистрибутив Linux. Это подразумевает перекомпиляцию ядра,
изменение нескольких конфигурационных файлов и добавление
своего программного кода. Для меня это было удобно сделать при
помощи Docker.
▍ Кросс-компиляция ядра Linux
Кросс-компиляция позволяет на компьютере с одной архитектурой
$ man bluetoothctl

получать исполняемые файлы для другой архитектуры. Мы можем
компилировать ядро Linux для Raspberry Pi на Raspberry Pi, а можем,
используя кросс-компиляцию, сделать это на обычном компьютере с
архитектурой x86, что существенно сократит время компиляции из-за
большего быстродействия компьютера. Подробно о том, как
выполнять кросс-компиляцию Raspberry Pi OS, можно почитать тут.
▍ Chroot и запуск бинарных файлов другой архитектуры
Команда Linux chroot позволяет запускать процессы с изменённой
корневой системой. Это кажется немного запутанным, но суть в
следующем. В качестве параметра команде передаётся путь к
корневой директории. В результате запуска команды через chroot
запущенный процесс будет считать, что корнем файловой системы
является та директория, которую передали в качестве параметра. 
Применений у команды chroot несколько, например, её можно
использовать, чтобы запустить команду apt для Raspberry Pi в
Docker-контейнере.
Интересно, что Docker Desktop для Windows позволяет запускать
исполняемые файлы для архитектуры ARM. В Linux-версии Docker
такое сделать можно, но нужна дополнительная настройка.
Реализация
Созданный мной проект состоит из следующих файлов:
1. Dockerfile и скрипт, который выполняется в Docker-контейнере.
2. Файлы, которые необходимо добавить или обновить в исходном
дистрибутиве:
• cdemu — основная логика работы эмулятора оптических
дисков, написанная на языке bash;

• cdemu-cmd — bash-скрипт для обработки команд от
пользователя и передачи их эмулятору;
• bash-utils.sh — bash-скрипт co вспомогательными
функциями;
• cdemu-bluetooth-ui.service — systemd-служба, которая
запускает интерпретатор команд на создаваемом RFCOMM-
соединении телефона и Raspberry Pi;
• cdemu.service — systemd-служба, которая запускает
эмулятор оптических дисков при загрузке;
• bluetooth.service — изменённая служба systemd для
инициализации bluetooth;
• serial-getty@.service — изменённая служба systemd для
запуска agetty на создаваемом соединении на
последовательном порту;
• firstboot.service — служба systemd для запуска скрипта при
первой загрузке операционной системы. Я её
позаимствовал из проекта raspberian-firstboot;
• config.txt — изменённый файл конфигурации для загрузки
Raspberry Pi. Содержит подключение overlay dwc. Это
необходимо, чтобы USB-контроллер мог работать в device
mode;
• fistboot.sh — скрипт, который запускается службой systemd
firstboot.service;
• userconf.txt — файл, который необходим, чтобы установить
пароль для пользователя pi. В последних версиях Raspberry
Pi OS пользователь pi не активирован по умолчанию,
поэтому необходимо наличие этого файла;
• ssh — файл необходим, чтобы активировать ssh, который
отключён по умолчанию;
• wpa_supplicant.conf — файл, необходимый, если вы хотите
настроить Raspberry Pi на работу с вашей точкой доступа.

Листинги файлов не привожу, так как это ещё больше раздует и так
большую статью. 
Ознакомиться вы с ними можете здесь.
Как пользоваться эмулятором
1. Собираем Docker-образ.
2. Собираем образ RaspberryPi OS.
3. Записываем образ на SD-карту. Вставляем её в Raspberry Pi.
4. Подключаем Rapsberry Pi Zero 2 W к компьютеру.
5. Через некоторое время у вас появится съёмный накопитель.
6. На этот съёмный накопитель, содержащий файл Readme.txt,
копируем образы, которые хотим эмулировать.
7. Находим виртуальный COM-порт, созданный после подключения
Raspberry Pi к компьютеру.
8. Подключаемся к Raspberry Pi через с помощью Putty через
виртуальный COM-порт.
9. Запускаем интерактивное приложение для управления
эмулятором.
10. Если хотим сделать управление с телефона, то выполняем
сопряжение телефона и Raspberry Pi. Для чего вводим в эмуляторе
терминала команду:
docker build -t raspi-image .
docker run --privileged -v c:\temp:/build --name raspi-image
$ sudo cdemu-cmd
$ sudo bluetoothctl

11. Делаем Raspberry Pi доступным для обнаружения:
12. Находим его на телефоне и выполняем полключение. После чего
соглашаемся с PIN-кодом на телефоне и Raspberry Pi.
13. Выходим из bluetoothctl.
14. Запускаем на телефоне Serial Bluetooth Terminal и выполняем
подключение к Raspberry Pi из него. Теперь можно посылать
команды созданному эмулятору CD-ROM.
Команды, которые можно посылать эмулятору:
1. hdd — переключение в режим эмуляции внешних жёстких
дисков.
2. cdrom — переключение в режим эмуляции внешних приводов
оптических дисков.
3. list — вывести список доступных ISO-образов, которые можно
эмулировать.
4. insert <порядковый номер> — поместить ISO-образ для
эмуляции.
5. eject — извлечь ISO-образ из эмулятора.
6. help — показать список доступных команд в текущем режиме.
Особенности моего эмулятора
discoverable on
yes
exit

Интересно, но в Linux по умолчанию нельзя эмулировать ISO-образы
размером больше 2 Gib. Я просмотрел исходный код драйвера в
файле drivers/usb/gadget/function/storage_common.c и предположил,
что нет оснований не применять патч к ядру Linux от Adam Bambuch,
который просто удаляет одно условие. Образы эмулировались
нормально и при снятии ISO-образа с эмулируемого CD-ROM он был
идентичен исходному. Поверял по хеш-коду для файла ISO-образа.
Не пойму, почему есть это ограничение в Linux и почему его до сих
пор не убрали? Если вы знаете ответ, ответьте в комментариях.
Моя реализация не требует никаких дополнительных деталей. Нужен
только Raspberry Pi Zero 2 W, один или два кабеля USB и адаптер
питания, если будете использовать два кабеля USB. Один для
питания, второй для передачи данных. Хоть и использование
дополнительного кабеля и адаптера добавляет громоздкости, это
решает проблему перезагрузки Raspberry Pi, если компьютер или
ноутбук отключает ненадолго питание при перезагрузке.
Кроме того, я не использую Python, только bash.
Выводы
Полученное программно-аппаратное решение, хоть и обладает
рядом недостатков по сравнению с карманом Zalman (не
поддерживается USB 3.0, нет интерактивного меню на самом
устройстве), позволит вам установить практически любую
операционную систему на широкий спектр компьютеров путём
простого копирования ISO-образа. 
Решение является прототипом, но вместе с тем позволяет углубить
знания по многим темам, или получить, если вы были с ними не
знакомы.
Так как основной целью была разработка прототипа, я запускал
bluetoothd в режиме совместимости, и почти всю логику написал на

bash.
Я хотел показать возможность превратить встраиваемое устройство
с операционной системой Linux в аппаратный эмулятор флеш-
накопителя или привода оптических дисков, приложив минимум
усилий. Надеюсь, что это удалось.
Чтобы уместить всё в одной статье, я лишь поверхностно коснулся
тех тем, которые необходимы для понимания. Если вас
заинтересовало, вы можете самостоятельно изучить их углублённо.
Объём статьи не позволяет осветить все интересности, с которыми я
столкнулся при разработке эмулятора, и решения, которые применял
и проверял. Приведу лишь несколько из них.
Например, я долго боролся с зависанием при удалении составного
устройства. Помогло использование службы serial-getty вместо getty,
хотя во многих статьях упоминалась getty.
Я долго разбирался, как можно сделать сопряжение через Bluetooth
между Raspberry и телефоном, использовал команду bt-agent, но
потом всё-таки отказался от неё в пользу bluetoothctl. 
При переключении эмулятора в режим HDD для записи ISO-образов
изначально я открывал для доступа всю SD-карту и хранил ISO-
образы в отдельном разделе, но потом посчитал, что для
безопасности лучше хранить образ диска с ISO-образами в
отдельном файле и открывать доступ только к нему, хоть это и
снизило скорость записи, но пользователя не обескураживают
появляющиеся несколько дисков.
Разработанный прототип есть куда улучшать. Можно, например,
создать более минималистичный дистрибутив Linux, который будет
содержать только то, что реально используется для эмуляции, или
создать более удобное графическое приложение для Android для
работы с эмулятором. А можно упростить работу с Bluetooth,
напрямую работая с драйверами bluetooth или используя интерфейс

D-Bus для работы с Bluetooth-устройствами. Или вообще всё-таки
взяться за паяльник и сделать устройство, более похожее по
функционалу на карман Zalman. Но главное, вы увидели, что это
реально сделать, а когда видишь положительный результат, это
вдохновляет на большее творчество.
В процессе тестирования и отладки программного кода было
замечено, что на Lenovo X1 Extreme Gen 2 эмулятор CD-ROM дисков
великолепно определялся в Windows 10, но отказывался
определяться в BIOS. Эмпирически было определено, что помогает
отключение режима экономии энергии процессора в BIOS. Также
ноутбук отключал питание на usb при перезагрузке, поэтому
понадобилось дополнительное питание Raspberry Pi.
Интересно, но на ASUS K53E и Gigabyte BRIX всё работает без
проблем.
Решение с небольшими модификациями можно реализовать на
Raspberry Pi 4. Но если вы поняли суть решения, вы его сможете
повторить и на других одноплатных компьютерах, которые имеют
выведенные USB-порты для OTG или USB-контроллеры
периферийных устройств.
Dockerfile на данный момент только выполняется в Docker Desktop
для Windows. В Linux он работать не будет.
В заключение хочу сказать, что существует ещё один способ
эмулировать оптические диски, который я не пробовал, но знаю о его
существовании из ваших комментариев к одной из моих статей —
это программа DriveDroid для Android. Я ей не пользовался, так как
для её работы нужно получать права root на телефоне. Но, скорее
всего, из-за ограничений в ядре Linux программа поддерживает ISO-
образы до 2 Gib и/или работает только с гибридными ISO-образами.
Если я не прав, буду рад увидеть ваши опровержения в
комментариях.

RUVDS.com
VDS/VPS-хостинг. Скидка 15% по коду HABR15
Telegram
ВКонтакте
Twitter
84
Карма
82.1
Рейтинг
@artyomsoft
Пользователь
Комментарии 17
Публикации
Telegram-канал с розыгрышами призов, новостями IT и
постами о ретроиграх 
️
Теги:  
linux kernel
,
usb
,
bluetooth
,
bluez
,
linux modules
,
эмуляция
,
iso
,
cd-rom
,
systemd
,
agetty
,
ruvds_статьи
Хабы:  
Блог компании RUVDS.com
,
Системное администрирование
,
Разработка под Linux
,
Разработка на Raspberry Pi
,
DIY или Сделай сам
+84
98
17

ЛУЧШИЕ ЗА СУТКИ 
ПОХОЖИЕ

 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
ИНФОРМАЦИЯ
Сайт
ruvds.com
Дата регистрации
18 марта 2016
Дата основания
27 июля 2015
Численность
11–30 человек
Местоположение
Россия
Представитель
ruvds

Ваш
аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
КАК СТАТЬ АВТОРОМ,6.0,04.05.2025,Лучшие ИТ-работодатели России 2023,"Нидерландская компания Yandex N.V. по итогам реструктуризации не сможет создавать и
развивать сервисы, аналогичные бизнесам «Яндекса» в течение пяти лет по всему миру.
Об этом говорится в документах по реструктуризации бизнеса.
Отмечается, что исключением будут выделяемые зарубежные стартапы Avride, Toloka, Nebius и
TripleTen, которые можно будет развивать везде, кроме России и Беларуси. «При этом
независимо от рынка, им запрещено развиваться так, чтобы создавать конкуренцию сервисам
„Яндекса“. По этому соглашению „Яндекс“ сможет развивать свои сервисы без каких‑либо
ограничений», — добавляется в документах.
Ранее стало известно, что расположенная в Нидерландах публичная компания с ограниченной
ответственностью «Яндекс Н.В.» (Yandex N.V. — материнская компания «Яндекса») заключила
сделку по продаже «Яндекса» за 475 млрд рублей консорциуму инвесторов и перестанет быть
головной компанией. В заявлении компании говорится, что «Яндекс» останется частной,
независимой и публичной организацией после реструктуризации.
Разделение компании произойдёт в первом полугодии 2024 года и пройдёт в два этапа.
После разделения российской компании «Яндекс» отойдут все сервисы и активы
за исключением Nebius, Toloka, Avride и TripleTen. При этом основным владельцем компании
российской компании станет фонд паевых инвестиций «Консорциум Первый». В Фонд войдут
менеджмент «Яндекса», частные инвесторы и «Лукойл», при этом контрольного пакета ни у кого
из акционеров не будет.
После завершения разделения компании Yandex N.V. проведет делистинг, а российская
структура «Яндекса» выйдет на Московскую биржу.
Теги:  яндекс, yandex n.v., разделение бизнеса
Хабы:  Управление проектами, Бизнес-модели, Финансы в IT, IT-компании
Yandex N.V. запретили в течение пяти лет создавать
аналогичные «Яндексу» сервисы
2 мин
13K
Управление проектами*, Бизнес-модели*, Финансы в IT, IT-компании
+11
Войти
Моя
лента
Все
потоки Разработка Администрирование Дизайн Менеджмент Маркетинг Научпоп"
Все потоки,2393.91,,IT-инфраструктура для бизнеса,"RUVDS.com
VDS/VPS-хостинг. Скидка 15% по коду HABR15
Пишет в хабы:  Читальный зал, DIY или Сделай сам, Научно-популярное, Электроника для начинающих, Системное администрирование
1935.27
40K
Timeweb Cloud
Облачная платформа для разработчиков и бизнеса
Пишет в хабы:  Читальный зал, Научно-популярное, JavaScript, DIY или Сделай сам, История IT
1542.55
1.1K
OTUS
Цифровые навыки от ведущих экспертов
Пишет в хабы:  Программирование, Java, Машинное обучение, Тестирование веб-сервисов, Python
832.56
103K
Яндекс
Как мы делаем Яндекс
СТАТЬИ
+64
НОВОСТИ
+50
ХАБЫ
АВТОРЫ
КОМПАНИИ
Название 
Рейтинг 
Подписчики
КАК СТАТЬ АВТОРОМ

Пишет в хабы:  Машинное обучение, Open source, Высокая производительность, Программирование, Интерфейсы
721.53
164K
Open Data Science
Крупнейшее русскоязычное Data Science сообщество
Пишет в хабы:  Машинное обучение, Искусственный интеллект, Natural Language Processing, Open source, Big Data
612.13
9.6K
ГК ЛАНИТ
Ведущая многопрофильная группа ИТ-компаний в РФ
Пишет в хабы:  Управление проектами, Карьера в IT-индустрии, Управление персоналом, Машинное обучение, Программирование
569.92
54K
VK
Технологии, которые объединяют
Пишет в хабы:  Big Data, Машинное обучение, DevOps, Tarantool, Облачные сервисы
536.95
167K
getmatch
Рассказываем о том, как строить карьеру в IT
Пишет в хабы:  Карьера в IT-индустрии, Лайфхаки для гиков, Читальный зал, IT-эмиграция, Урбанизм
436.91
953
Wiren Board
Оборудование для автоматизации и мониторинга
Пишет в хабы:  Умный дом, Интернет вещей, Инженерные системы, DIY или Сделай сам, Компьютерное железо
411.66
353
FirstVDS
Виртуальные и выделенные серверы в ДЦ в Москве
Пишет в хабы:  Научно-популярное, Системное администрирование, Читальный зал, Информационная безопасность, IT-инфраструктура
398.02
24K

Конференции Олега Бунина (Онтико)
Профессиональные конференции для IT-разработчиков
Пишет в хабы:  Управление разработкой, Конференции, DevOps, Управление проектами, Карьера в IT-индустрии
360.51
58K
AGIMA
Крупнейший интегратор digital-решений
Пишет в хабы:  Карьера в IT-индустрии, Управление проектами, Конференции, Управление персоналом, Управление продуктом
336.45
519
Альфа-Банк
Лучший мобильный банк по версии Markswebb
Пишет в хабы:  Конференции, Анализ и проектирование систем, Машинное обучение, JavaScript, Карьера в IT-индустрии
311.6
24K
Postgres Professional
Разработчик СУБД Postgres Pro
Пишет в хабы:  PostgreSQL, SQL, Администрирование баз данных, Open source, Хранение данных
305.42
76K
Ozon Tech
Стремимся делать лучший e-commerce в России
Пишет в хабы:  Конференции, Высокая производительность, Go, Тестирование веб-сервисов, Программирование
282.75
28K
TINKOFF
IT’s Tinkoff — просто о сложном
Пишет в хабы:  Разработка под Android, Машинное обучение, Тестирование IT-систем, Разработка мобильных приложений, Open source
282.47
40K
Хабр Карьера
Помогаем строить карьеру в IT
Пишет в хабы:  Карьера в IT-индустрии, Управление персоналом, Исследования и прогнозы в IT, Блог компании Хабр, Финансы в IT
280.33
14K

JUG Ru Group
Конференции для Senior-разработчиков
Пишет в хабы:  Конференции, Java, Тестирование IT-систем, Разработка мобильных приложений, JavaScript
276.72
41K
Southbridge
Обеспечиваем стабильную работу highload-проектов
Пишет в хабы:  IT-инфраструктура, DevOps, Системное администрирование, Карьера в IT-индустрии, Программирование
272.35
47K
1
2
3
..

Ваш
аккаунт
Разделы
Информация
Услуги
ФИЛЬТР
Все
323
Web-development
98
Software
180
Hardware
40
Design and usability
22
Advertisement and marketing
9
Mass media
5
Consulting and support
49
HR
9
E-commerce
41
Non-profit organizations
5
Optimization
9
Producing multimedia content
9
Telecommunications
54
Domains and hosting
17
Search Engines
9
Mobile technologies
72
Web-services
97
Games and entertainment
11
Information Security
47

Войти
Регистрация
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
КАК СТАТЬ АВТОРОМ,85.0,04.05.2025,Зарплаты айтишников,"Привет! Меня зовут Денис, я занимаюсь коммерческим программированием уже более 15 лет,
управляю командами с 2017 года, работал в Яндексе, TradingView, Skillbox, Arcadia. В статье вы
узнаете историю, как написать целый проект на Kotlin Multiplatform, сколько это стоит и сколько
обойдется интеграция с точки зрения цифр.
Этот доклад - текстовая версия моего выступления с осеннего Мобиуса 2024 года. Обязательно
приложу видео с выступлением после выхода.
О чем поговорим в статье:
Пройдем путь от идеи Kotlin Multiplatform до её реализации в цифрах.
Обсудим, сколько стоило внедрить Kotlin Multiplatform в продукты и к чему это привело.
Заезжаем в Kotlin Multiplatform. Но какой ценой?
14 мин

Проведём ретроспективу: стоило ли это делать вообще и стоит ли инвестировать в эту
технологию дальше. А также разберём, сколько это будет стоить в перспективе.
Разбираемся с KMP и CMP: ключевые термины перед стартом
Сначала немного вводных: разберемся с сокращениями, которые часто буду использовать в
статье.
KMP (Kotlin Multiplatform) – это технология, которая позволяет шарить код, написанный на Kotlin,
между разными платформами (Android, iOS, JVM, Desktop, Web, etc.)
CMP (Compose Multiplatform) — UI, который можно рисовать с помощью Jetpack Compose и
портировать на разные устройства. Сейчас официально поддерживаются две платформы:
Android и Desktop. iOS находится в стадии публичной беты, а Web – в альфе.
Мы сконцентрируемся на трёх таргетах – Compose Multiplatform для Android, Desktop и iOS.
Остальные в статье рассматривать не будем, так как они достаточно редкие или имеют далекий
от стабильности статус разработки.
Запуск проекта на KMP + Compose/SwiftUI: архитектура, паттерны и подходы
В апреле 2024 мы начали разработку нового проекта. В качестве базового стека выбрали KMP в
связке с Compose Multiplatform и SwiftUI.
Основной подход – использование паттерна MVVM для шаринга кода между экранами разных
платформ. В мультиплатформенной части находятся DI, бизнес-логика и переводы, которые
поставляются в виде SDK. Каждому экрану доступна своя ViewModel.
Для Android и iOS мы реализовали следующий подход:
Android: активити выступает хостом для Composable-функции из библиотеки, а также
предоставляет доступ к нативным компонентам.
iOS: нативный UI на SwiftUI и платформенные связки (например, пуш-уведомления,
интеграция с библиотекой авторизации) реализованы отдельно, но используют общее SDK.
Выбор Compose Multiplatform позволил нам легко адаптировать UI для новых таргетов в будущем.
Архитектура проекта: зонтик-модуль, Shared-логика и работа с Compose SDK
Наша схема работы следующая: серыми блоками обозначены элементы, которые мы написали
один раз и практически не изменяем, а зелеными — те, к которым мы обращаемся и вносим
изменения довольно часто.

У нас есть зонтик-модуль под названием Shared. По сути, это вся логика, написанная на Kotlin
Multiplatform, собранная в одном месте, к этому модулю подключаются другие. Например,
ModuleShared (какая то отдельная функциональность, например, профиль), который может
ссылаться на стандартные решения: API, ViewModel, различные вспомогательные инструменты
— переводы, логирование, аналитику и прочее.
Зонтик-модуль мы подключаем к ComposeSdk для того, чтобы получить мультиплатформенный
таргет, который хостится в Android-приложении. Compose Sdk также делится на отдельные
модули, где имплементированы UI отдельных бизнес фич. А iOS, соответственно, берет просто
бизнес-логику Shared целиком и у себя уже имплементирует UI.
Эксперимент 1. Про интеграцию KMP в цифрах
Первое, о чем хочу рассказать, — это сколько стоит интеграция библиотеки Kotlin Multiplatform в
мегабайтах и секундах. Мегабайты показывают, насколько ваше приложение увеличится в
размере после добавления зависимости. Секунды отражают время, необходимое для горячего
перезапуска. Про холодный запуск я тоже упомяну, но в первую очередь нас интересует именно
горячий — то, сколько секунд будет уходить на повторную сборку. Это важный параметр,
поскольку он влияет на комфорт работы разработчиков. Мы будем часто сталкиваться с этим
процессом в работе, поэтому важно заранее понять, насколько это критично.
У нас есть таблица с данными. Мы будем постепенно добавлять зависимости в наш проект,
тестировать его на трех платформах и сравнивать размеры и время, затрачиваемое на горячую
сборку. Давайте начнем с разбора структуры таблицы.

Начнем с чистого проекта. Ну, он не совсем чистый, потому что в Android там добавлен Compose
и Kotlin — ведь вы вряд ли будете писать новое Android-приложение без них. То же самое
добавлено сразу в JVM Target.
Получаем следующие цифры:
Горячая пересборка (Hot Reload) везде примерно по одной секунде. Размеры нативного iOS-
приложения — 0,2 мегабайта (200 килобайт). Android — 5.25, десктоп — 67.85 МБ.
По умолчанию Compose тянет в десктоп-приложение довольно много всего, потому что там
внутри JVM (я рассматриваю сейчас таргет под MacOS). Это JVM, которая запускается на Mac OS
и тянет за собой немало. Но в целом 67 МБ для нативного приложения, на мой взгляд, — вполне
адекватный размер. Предположу, что на этом этапе мы не скажем: ""всё, хватит, эксперимент
окончен, это слишком много для приложения, и мы не будем его разрабатывать"". По моему
мнению, для десктопа это разумная цифра для старта. 
Теперь посмотрим, как будут расти зависимости.

· Добавляем Kotlin
Очевидно, он уже есть у нас в Android и также в десктопе. Добавление в iOS весит 2,5 мегабайта.
Эти замеры сделаны на версии 2.0.20, но в зависимости от версии языка они могут отличаться.
Я наблюдаю за этим начиная с Kotlin 1.6 — тогда он весил около 1.7 МБ, а сейчас вырос до 2.5, в
целом, 2 мегабайта — это все еще немного.
·  Добавляем Coroutines
На Android получается 7,5 мегабайт, а десктоп почему-то не вырос. Там вообще будут разные
нюансы, связанные с размером десктопа, — он не всегда растет пропорционально с другими
платформами.
Вот такие цифры у меня получились: iOS вырос на 400 килобайт. На мой взгляд, это отличный
результат, потому что Coroutines — это мощный инструмент для асинхронной работы, в том числе
и в iOS. Под капотом там целый комбайн для работы с асинхронщиной.

·  Добавляем DateTime
Android практически не растет, потому что использует под капотом нативный DateTime. Десктоп
незначительно увеличивается на несколько килобайт. А iOS — внимание — 7.6 мегабайта!
Почему так? Вероятно, пока библиотека не находится в стабильной версии и “тянет” что-то
лишнее. Coroutines добавляют 400 килобайт, а DateTime — 5 мегабайт.
В этот момент горячая сборка всех трёх проектов у меня на M1 занимала примерно 20 секунд с
нуля. Повторная сборка — по одной секунде.
·  Добавляем View-Model
В Android она практически ничего не добавляет. Десктоп почему-то стал меньше (помним про
возможные ошибки в измерении), iOS тоже не вырос. Были небольшие изменения на уровне
байтов и килобайтов, но общий размер в 7.6 мегабайта пока выглядит компактным.
·   Добавляем Ktor
Войти
Моя
лента
Все
потоки Разработка Администрирование Дизайн Менеджмент Маркетинг Научпоп

Это сетевой слой, который умеет ходить в сеть и работает с Coroutines. Android вырастает на 1
мегабайт, десктоп — на 3 мегабайта, а iOS — на 5.3 мегабайта. Здесь я использовал версию Ktor
3.0.0 RC1.
·  Добавляем SqlDelight для базы данных
В Android добавляется совсем немного, так как используется нативный драйвер. В iOS прирост
минимален по той же причине — применяется нативный SQL-драйвер. А вот в десктопе
добавляется заметно больше, поскольку там отсутствует встроенное решение для SQL. Вместо
этого подтягивается драйвер JDBC, что добавляет 14 мегабайт. Размер итогового приложения
для десктопа — 85 мегабайт, что по-прежнему укладывается в разумные пределы. Мой
субъективный психологический барьер в 100 мегабайт пока не достигнут.
·  Добавляем Koin

Для организации DI-сборки приложение увеличивается на 100 килобайт — как в Android, так и
примерно столько же в iOS. В десктопе прирост больше — около 400 килобайт.
Compose 
В Android и десктопе не добавляет ничего, потому что он был включен с самого начала. В iOS
добавляет 45 мегабайт. Если просто загрузить коробочное решение, то Compose занимает около
30 мегабайт, в наших приложениях это все еще далеко не самая крупная библиотека.
Какие выводы здесь можно сделать?
1. Собирается все очень быстро
Десктоп компилируется примерно в два раза медленнее, но это по-прежнему укладывается в
рамки секунд. На этапе сборки проблем не возникает.
2. На KMP можно разрабатывать библиотеки

Подключая стандартный набор инструментов Android, мы получаем итоговый вес около 10
мегабайт.
3. Если использовать только стандартный Kotlin, можно уложиться в пару мегабайт
Этот размер включает в себя очень много кода. Если добавить свой код — то прирост будет
минимальным и может уложиться всего в пару мегабайт. На практике это практически незаметно.
4. На CMP писать библиотеки сложнее, но тоже можно (около 47 мб)
Считаю, что 47 мегабайт для iOS на сегодняшний день не являются критическим барьером для
создания библиотеки. Современные телефоны редко имеют объем памяти меньше 128 гигабайт,
так что 47 мегабайт вряд ли создадут проблемы.
Если же разрабатывается простой экран, возможно, стоит задуматься, нужно ли это. Но для
более сложных решений, например, платежных систем или систем интеграции заметок, такой
подход вполне оправдан.
5. Десктоп весит и собирается больше остальных, но числа — адекватные
Он немного тяжелее из-за отсутствия нативного UI и необходимости добавления драйвера JDBC.
Однако в целом показатели остаются в пределах нормы.
Эксперимент 2. Сколько стоит написание модуля в байтах
Теперь измерим, сколько добавляет нам написание одного модуля в проекте. Для примера я
написал модуль логина. Хотел запустить десктоп с авторизацией — как раз такого модуля для
десктопа мне и не хватает, для iOS и Android библиотеки уже есть.
Модуль содержит:
Три API — ручки на Ktor
Проперти в SharedPreferences. Замечу, что класть токены туда нельзя, но в данном случае
это использовано для примера.
MVVM и Coroutines под капотом.
Экран на Compose Multiplatform
Также я продублировал его на SwiftUI для сравнения размеров.
Результаты

Добавляя зависимости, получаем прирост:
Android — 12 мегабайт.
iOS — 50 мегабайт, второй вариант — 51 мегабайт из-за отличий в версиях библиотек.
Размеры сборок иногда бывают разными, что стоит учитывать. Лично у меня это поведение
встречалось, и лучше все перепроверить у себя.
Какие выводы тут можно сделать?
1. Размер приложения растет равномерно и линейно
Исходя из этого, можно долго писать код, не опасаясь, что он превратится в «монстра» на сотни
мегабайт.
2. Все приложения растут равномерно (можно ориентироваться на размер Android)
Понимание линейного роста важно для перспективы. Например, если команда из 10 человек
разрабатывает приложение в течение двух лет, итоговый размер на iOS можно легко
спрогнозировать, добавив небольшую дельту к текущим показателям.
3. Артефакт со сборкой iOS нужно изучить (плавающий инкремент)
4. На время сборки новые модули практически не влияют
5. Модульная архитектура не влияет на размер итогового приложения
> Это подтверждает, что можно создавать гибкие мультимодульные решения, не опасаясь
значительного роста веса программы.
Эксперимент 3. Перенос Android Compose на CMP
Теперь посмотрим на то, сколько стоит перенести фичу с Андроида на CMP. Я занимался этим в
рамках запуска десктопа — переносил дизайн-систему с Android на Compose Multiplatform.

1) В дизайн-системе у нас было 400 картинок, написанных в формате SVG. Все это мы вытащили
в Kotlin-код в Android-библиотеку и прикрутили к Composable теме.
Задача заключалась в том, чтобы из Android-таргета получить мультиплатформенный.
Для этого нам понадобилось
1) Первое изменение — это changelog при перегенерации картинок. Я перегонял их из SVG в код
на Kotlin. На это в реальности ушло около 30 минут. Но на код-ревью можно получить 36 тысяч
строк changelog’a, просто перенеся картинки из SVG в Kotlin.
2) Я переработал примерно 2000 строк кода — 2000 удалил и 2000 добавил. Суммарно потратил
где-то 3 человека-дня.
Я делал это не в первый раз, поэтому без опыта вы потратите немного больше, стоит
закладывать в два раза больше времени.
Что было:
·  Была довольно понятная логика, ничего такого, что нельзя было бы отревьюить с помощью
двух пул-реквестов.
·  Один хотфикс — сломались шрифты. Мы использовали Compose 1.6.11. В Compose 1.7.0 этой
проблемы уже нет.
·  Постоянная, но легкая боль, так как превью в CMP + Android Studio не работает. Решение есть:
можно написать превью в Android-части. Оно будет ссылаться на Compose Multiplatform и
отображать его, придётся держать два экрана, но это работает.
Нам помогали:
·  Самопальный генератор верстки из Figma в Kotlin.
·  Плагин для переноса Svg to Compose.
·  Бесконечная вера в то, что нам это пригодится.
Мы реально поверили в то, что нам это надо, и сделали. И нам это действительно пригодилось.
Результаты
1. У нас получилась дизайн-система на десктопе.
Можно запускать ее без эмулятора, сравнивать поведение, с помощью мышки, менять размер
экрана, смотреть на поведение компонентов и так далее. Это действительно используют сейчас,
и мы можем экспериментировать с версткой уже в десктопе.
2. С точки зрения ресурсов — это три человеко-дня.

В дальнейшем поддержка и написание на Compose Multiplatform или Jetpack Compose — для
меня и команды особой разницы нет. 
3. Дизайнеры благодарны.
Они теперь могут запускать дизайн-систему у себя на макбуке и сразу видеть результат своей
работы.
Производительность KMP: тестируем запуск на Android, iOS и Desktop
Теперь мы попробуем измерить загрузку первоначального экрана, запуска кода и оценим,
сколько это будет стоить.
Запуск в попугаях
Меряем в ""попугаях"", потому что реальные цифры будут зависеть от эмулятора и реального
устройства — объема памяти, процессора и прочих характеристик. Но даже в таком формате мы
сможем получить ориентировочные данные.
1. Запускаем пустой проект с добавленным Kotlin Multiplatform.
2. Запускаем в нем Coroutines. Запустим одну джобу и смотрим, когда она будет выполнена.
3. Затем запускаем то же самое, но с экраном на Compose Multiplatform и фиксируем, сколько
миллисекунд уходит с момента запуска приложения до первого показа экрана.
Это не перформанс-ревью, а тестирование того, сколько времени займет старт, и можно ли
интегрировать это в приложение так, чтобы процесс оставался комфортным.
Результаты
·  Пустой проект в Android запускается за 165 миллисекунд на эмуляторе. Десктоп на старте
занял 257 мс, а iOS — внезапно 101 мс. На симуляторе он запускается быстрее всего.
Конечно, iOS здесь немного ""читерит"", предоставляя симулятор, который фактически работает на
macOS без дополнительных прослоек. В то время как десктоп использует JVM, а Android
работает через стандартный эмулятор, что влияет на результаты. Числа получены на M1
MacBook с 50 вкладками в браузере и четырьмя мессенджерами — классическая ситуация для
разработчика.
·  Добавляем вызов корутины.
Число становится чуть меньше. На самом деле Android в начале показывает некоторые
колебания, но главное, что разница в конечном счете несущественная.
Десктоп ведет себя так же, потому что там JVM под капотом. Собственно, он дает примерно те же
результаты. И внезапно симулятор на iOS выдает меньше времени, чем на старте. Наверное,

потому что я закрыл вкладку с любимым видео у себя на макбуке, поэтому он стал работать
немного быстрее.
·  Добавляем Compose экран.
Получаем 163 мс в Android, 280 мс в десктопе и 73 мс в симуляторе iOS.
Какие выводы тут можно сделать?
1. Kotlin на iOS не влияет вообще.
А еще работает быстрее, чем в нативном Android. Шутка, потому что размер был в попугаях.
Берите сами, замеряйте, сравнивайте, принимайте для себя решения.
2. Compose/Coroutines тоже не влияют на запуск приложения.
Вы видели сами цифры — они никак не повлияли на запуск пустого проекта или последнего со
всем стафом внутри.
Эксперимент 4. Запуск Desktop на основе Android
Есть приложение, написанное на Android, и я хочу его запустить у себя на макбуке.
1. Имеем андроид, написанный на технологиях выше.
2. Используем собирающийся десктоп проект.
Он у нас компилировался и собирался для прохождения проверок целостности кода, но при
запуске сразу падал с ошибкой в рантайме. В некоторых местах мы использовали expect-actual
функции, оставляя заглушки в десктоп-версии. Например, не подключили драйвер для базы
данных и не добавили поддержку Ktor. В общем, реальной работоспособности у него не было.
3. Надо прикрутить авторизацию (нет библиотеки).
Мы используем нативные библиотеки авторизации в Android и iOS, а для десктопов такого
решения нет (раньше мы разбирали пример написания такой либы).
В итоге на разработку я потратил четыре человека-дня, сделал пять пул-реквестов и долго
буксовал, потому что писать свою авторизацию на нативном API — задача, мягко говоря, не
самая увлекательная.
Кроме того, кейс сам по себе редкий — в основном используется в ТВ-станциях и подобных
устройствах. Например, когда нужно отсканировать QR-код, перейти в браузер для авторизации и
затем вернуться в приложение.
Из-за редкости кейса пришлось разбираться и копаться в деталях. В результате проект я
запустил за три часа, а на прикручивание авторизации потратил еще три дня.

Какие выводы тут можно сделать?
1. Многие штуки можно переиспользовать с Android. 
Например, у нас работает Ktor + OkHTTP, можно взять его прямо из Android и подключить в
десктоп.
2. Секьюрных преференсов нет.
Поэтому хранить данные аккаунта и токен там не стоит.
3. Библиотек немного, а те, что есть, не всегда и не во всем поддерживают десктоп.
Но, тем не менее, SqlDelight, Room и Ktor доступны и работают хорошо.
4. UX надо адаптировать, но это решаемая проблема.
Если вы захотите поддержать планшетную верстку, так или иначе придется это сделать.
5. В целом, все работает так же, как и на других платформах.
Compose на десктопе — ничего сверхъестественного.
Экономия времени и ресурсов: плюсы и минусы мультиплатформенного подхода
1. Мы пишем одно ядро приложения один раз.
2. UI пока пишется дважды, но UX адаптирован.
Единая ViewModel позволяет сократить работу. Например, показы тостов и разрешений
вызываются одинаково.
3. Преимущество CMP с ненативным UI пока не очевидно ни по скорости запуска, ни по
времени работы.
Тем более это все еще бета-версия, поэтому поддержка может быть сложной. JetBrains
постепенно подтягивает недостающие компоненты, Material 3 уже есть в Compose 1.7.0.
4. Баги исправляются сразу на двух платформах, что экономит время.
На тестах тоже экономим, потому что бизнес-логику можно проверить на одной платформе, а она
будет работать и на второй. Но тестировать UI все равно придется отдельно, так как приложения
хоть и похожи, но разные.
5. Экономия времени
Я оцениваю экономию в 30%. Мы делим 100% времени пополам на Android и iOS. Android делим
на 30% для бизнес-логики и 20% на UI. С iOS забираем те же 30% логики, оставляя 70%.

Экономия — 30%.
Конечно, все зависит от того, как вы пишете код, и сколько времени уходит на бизнес-логику или
UI. 50% сэкономить невозможно, так как Android-приложение не запустится на iOS без доработок.
Тестирование в мультиплатформе: где экономим, а где — нет
·  Дешевле писать тесты
Тесты на KMP можно запускать везде, сравнивать результаты и хостить.
·  Из-за разных UI тестировать их придется отдельно.
Проверять баги на промежуточной платформе тоже необходимо. Если мы не уверены на 100%,
что проблема в бизнес-логике, а тестировщики тоже не могут это подтвердить, баг все равно
придется проверять на обеих платформах.
·  Экономия на половине тестов может составить примерно 10% от общего объема работ по
тестированию.
Но это расчет в условных единицах — «в попугаях». Здесь каждый может для себя
визуализировать цифры по-своему.
·  Багов в целом получается объективно меньше.
Кодовая база сокращается, у нас один источник истины, и изменения вносятся в одном месте.
Это снижает количество точек, где могут возникнуть баги.
Конечно, с увеличением числа поддерживаемых платформ нагрузка возрастает, но общая выгода
от подхода дает профит.
Сборка мультиплатформенного проекта: ожидания vs реальность
·  Сборка проектов у нас идет параллельно.
Это важно, так как позволяет проверять работу кода одновременно на Android и iOS. Общее
время сборки при этом определяется самым долгим пайплайном.
В нашем случае это обычно iOS, хотя проблема связана не столько с самой платформой, сколько
с виртуальными машинами, которые мы используем.
·  Работа с единым источником истины.
Когда в core-компоненте вносятся изменения, сборка триггерится сразу на обоих таргетах. После
этого проверяем, работают ли изменения и подтянулись ли они корректно.
·  Сборка для iOS может быть довольно проблемной.

Интеграция с KMP в Xcode оставляет желать лучшего (впрочем, вряд ли можно рассчитывать на
это со стороны Apple), и добавление зависимостей на этапе pull request может превратиться в
квест “угадай, почему xcode это не видит”.
Затаскивание новых файлов в iOS-проект — отдельная боль. Добавьте сюда еще использование
сторонних систем сборки, которые только усложняют процесс.
По факту мультиплатформенный подход не всегда упрощает процесс сборки, а часто наоборот —
добавляет сложности.
·  Можно начинать разработку с Android.
Это позволяет не тратить время на постоянные сборки и проверки iOS на ранних этапах. Логику и
UI тестируем сначала в Android. После этого переносим в iOS, минимизируя доработки и отладку.
Этот подход экономит время, хотя иногда приходится возвращаться назад для внесения
изменений. Android собирается быстрее, так как для него это нативный процесс.
·  Для iOS сборка идет медленнее Android (хотя это все еще измерение в попугаях).
Если говорить в цифрах:
Android — 1 минута 15 секунд против iOS — 2,5 минуты.
Суммарно весь пайплайн у нас работает примерно в 2 раза дольше для iOS, чем для Android.
Почему с iOS все не просто
В iOS есть свои особенности сборки и дополнительные сложности.
Некоторые из них связаны с интеграцией библиотек и зависимостей, другие — с особенностями
взаимодействия с системами сборки и пайплайнами.
Транзитивные зависимости не работают. Нужен модуль-зонтик для подключения и мержа
зависимостей. Отсюда все недостатки зонтичной системы наследования.
Все не так драматично (в числах все равно получается довольно быстро). Мы получаем
незначительные изменения в разных платформах. Но сам подход написания большого
зонтичного модуля, хотелось бы видеть только на этапе сборки конечной программы, а не
промежуточного модуля.
Что в итоге
Использование Kotlin Multiplatform в разработке оказалось не таким болезненным, как может
показаться на первый взгляд. Общая бизнес-логика действительно позволяет сократить затраты
на разработку примерно на 30%, а аналогичную экономию можно получить и на тестировании.
При этом использование Jetpack Compose уже сейчас выглядит оправданным шагом, особенно
если закладывать возможность перехода на Compose Multiplatform в будущем — это бесплатно и
может дать преимущества. Однако полностью переходить на CMP пока рискованно, поскольку"
353.18,4.58,04.05.2025,Рейтинг,"Экосистема для развития людей, вовлеченных в IT
8 февраля — день российской науки. Этот праздник отмечается в Академии Наук, в НИИ,
вузах, исследовательских лабораториях по всей стране. Судьба российской науки непростая,
всегда переплетённая с историей страны и ею же обусловленная: непростой путь к открытию
МГУ, талантливые кулибины (и И.Кулибин) из глубинки, учёные в изгнании, Туполевская шарага,
достижения института Гамалеи… Всё смешано, переплетено и влияло и влияет на весь мир.
Величие российской науки прежде всего в людях, которые её создают, которые разрабатывают,
изобретают, экспериментирую и точно знают, что делают. 
В этот день всегда спорят медики, биологи, инженеры, программисты, филологи, физики, химики
— чьи учёные научнее и главнее, кто определял и создавал будущее? Ответ простой: все,
каждый — в своей сфере. Предлагаем сегодня собрать российские  открытия и учёных, которые
вас вдохновляют, впечатляют, будоражат воображение и влияют (или повлияли) на вас.
Напишем эту статью вместе?
История российской науки: напишем вместе?
5 мин
1.3K
Блог компании Хабр, Научно-популярное
Ретроспектива
КАК СТАТЬ АВТОРОМ
Технотекст
Добавь свой раздел в статью про российскую науку
Войти
Моя
лента
Все
потоки Разработка Администрирование Дизайн Менеджмент Маркетинг Научпоп

Правила создания статьи
Вы в комментариях рассказываете о том самом учёном и его изобретении, которые важны
именно для вас, а мы добавляем ваши истории в общую статью и формируем самый крутой
лонгрид об истории российской науки.
Формат свободный, желательно (не обязательно!) отразить:
ФИО учёного, его годы жизни
основные изобретения
краткая биография
наиболее значимое изобретение (на ваш взгляд)
чем вас вдохновил учёный, как повлиял на вас
изображения приветствуются.
Комментарии будут сохраняться и вы сможете их обсуждать — так, как и всегда. Автор
самого заплюсованного описания получит приятный сюрприз от команды Хабра.
Чур, википедию не копировать!
Итак, поехали. 
Николай Иванович Пирогов (1810 — 1881)
великий российский врач, хирург

Николай Пирогов в 14 лет поступил на первый курс медицинского факультета МГУ (тогда
Московского университета). По окончании вуза он в числе семи лучших студентов отправился
в Депт (Тарту) заниматься анатомическими исследованиями и готовиться к профессорской
деятельности. Считается одним из лучших анатомов мира, родоначальник топографической
анатомии. Именно он разрезал замороженное человеческое тело в четырёх плоскостях и создал
атлас топографической анатомии, который стал незаменимым пособием для хирургов. Это был
не просто учебный материал, но прежде всего возможность оперировать с минимальным
травматизмом для пациента.
Пирогов брался за любые операции, от ампутаций и извлечения камней до глазных
манипуляций и сосудистых вмешательств. Именно он провёл в 1847 году первую свою операцию
под наркозом, тщательно изучив свойства эфира и хлороформа. Затем в течение года прошло
300 подобных операций.
Николай Пирогов — автор алгоритма сортировки раненных на поле брани, благодаря чему
удалось спасти огромное количество жизней, а сам алгоритм до сих пор служит организации
военной медицины.
Именно он ввёл в практику российской медицины обеззараживание хлорной водой и настойкой
йода. До сих пор хлорка, йодопирон, йодинол и йод служат хирургам и всем медикам верную
службу.
Николай Пирогов был первым учёным от медицины, о котором я узнала в возрасте 7 или 8 лет,
уже будучи немного горящей «стать доктором». Жизнь повернулась самым причудливым
образом, но изучение истории медицины сделало моё мышление структурным, комплексным и

навсегда привило любовь к людям. Какие бы они ни были, они — люди, с болью, со стрессом,
с заболеваниями и радостью выздоровления. Совершенно особенное ощущение.
Художественный фильм «Пирогов»
Гааз и Пирогов — лекторий «Достоевский». Хотя конкретно в этом фильме история Гааза
потрясает гораздо больше.
Семён Николаевич Корсаков (1787-1853)
создатель первой в мире перфокарточной машины (табулятора) «для сравнения идей»
Рассказывает @Motanto
Его история меня когда-то поразила: только подумайте, кто-то что-то делал в программировании
до Бэббиджа, да ещё и в Российской Империи. Ещё больше поразил тот факт, что Корсаков был
обвинён современниками в пустой трате времени на изобретения, а его славные дела дошли до
мирового научного сообщества и до нас с вами благодаря ""раскопкам"" учёных XX века, в
частности благодаря математику и кибернетику Г.Н. Поварову.
Потомственный дворянин, Семён Корсаков стал прародителем отечественной кибернетики. Он
всегда видел своей задачей усиление работы разума с помочью различных механических
устройств (чем вам не первобытное программирование?!). Кроме изобретённых им гомеоскопов
и идеоскопа, он подарил миру идею перфокарт. Именно гомеоскопические перфорированные
таблицы стали прототипом тех самых картонных карт. Устройства Корсакова помогали
сравнивать таблицы и обрабатывать большие массивы данных, с помощью его устройств можно
было решать задачи классификации. Корсаков видел бытовое применение своим изобретениям
(реестры, каталоги, регистрации), ничего не патентовал и просто представил машины
общественности.

С.Н.Корсаков и машина для сравнения идей
Однако комиссия из пяти ученых, возглавляемая молодым математиком академиком М. В.
Остроградским, вынесла вердикт: «Господин Корсаков потратил чересчур много своих
интеллектуальных сил, пытаясь научить других, как вовсе без оного интеллекта прожить».
Кажется, это лучшее определение ИТ-сферы целиком ;-)
Такая вот биг дата доэлектрической эры.
Павел Петрович Аносов (10 июля 1796 — 25 мая 1851)
горный инженер, учёный-металлург
Рассказывает @Mimizavr
Талантами Русь богата
И вот, старики говорят,
Что сталь дамасских булатов
Рассек уральский булат.
Павел Петрович Аносов - на мой взгляд, совершенно фантастическая фигура, благодаря
которой в 19 веке очень сильно развилась металлургия на Урале.
Будучи горным инженером по специальности, он занимался научной работой в сфере
металлургии, стал крупным организатором горнозаводской промышленности на Урале,
исследовал природу Южного Урала, вел геологическую разведку месторождений россыпного
золота и железных руд, изобрел ряд устройств и механизмов (в том числе и эффективную
золотопромывную машину), разработал технологию производства огнеупорных тиглей (первый в
России), стал десятым губернатором Томской губернии.

Павел Петрович известен, в первую очередь, как создатель русского булата. Булат — особый
вид стали, очень прочный и упругий, с узором на поверхности, который является не украшением,
а показателем качества металла. Впервые оружие из такой стали начали использовать воины
Древней Индии. Такими мечами разрубали камни и легкие воздушные ткани. Несколько веков
спустя центром по изготовлению булатных клинков стал Дамаск. Как мастера 12-15 веков могли
варить такую удивительную сталь, оставалось загадкой, разгадать которую сумел лишь Павел
Аносов. До Павла Аносова создать булат пытались многие, но никому это не удавалось. За
несколько лет работы мастер испробовал 189 способов сталеварения, но ни один из них не не
дал булат. И лишь в 190-ый раз смешивая компоненты, создавая необходимые температурные
условия мастер открыл тайну.
Игорь Васильевич Курчатов (1903–1960)
физик, «отец» атомной бомбы СССР
Говорит и показывает @Boomburum

Игорь Васильевич Курчатов (1903–1960) — один из первопроходцев в области ядерной
физики, «отец» атомной бомбы СССР. В числе его заслуг — создание первого в Европе атомного
реактора, первой в СССР атомной бомбы и первой в мире термоядерной бомбы. Но были
заслуги и в развитии мирного атома — под его руководством была сооружена первая в мире
атомная электростанция (Обнинская АЭС). 
Самый засекреченный ученый
Самый засекреченный ученый
Теги:  российская наука, российские учёные
Хабы:  Блог компании Хабр, Научно-популярное
Редакторский дайджест
Присылаем лучшие статьи раз в месяц

Хабр
Экосистема для развития людей, вовлеченных в IT
Хабр Карьера
Facebook
Twitter
ВКонтакте
Instagram
244
Карма
128.3
Рейтинг
@Exosphere
модератор «Хабра», куратор-эксперт
ОПРОС
Вы знаете, что такое IT-менторство и как оно работает?
Знаю, я — ментор или у меня была консультация с ментором
Знаю и хочу попробовать, но пока опыта нет
Знаю и не хочу пробовать, менторство не решает мой запрос
Не знаю, но мне интересно
Не знаю и мне неинтересно
Голосовать
Воздержаться
Проголосовал 1061 пользователь. Воздержались 219 пользователей.
Электропочта
Комментарии 8
ИНФОРМАЦИЯ
Сайт
habr.com
Дата регистрации
9 августа 2008
Дата основания
26 мая 2006
Ваш аккаунт
Войти
Регистрация
Разделы
Статьи
Новости
Информация
Устройство сайта
Для авторов
Услуги
Корпоративный блог
Медийная реклама

Численность
51–100 человек
Местоположение
Россия
Представитель
Алексей
ССЫЛКИ
Хабр Карьера
career.habr.com
Хабр Q&A
qna.habr.com
Хабр Фриланс
freelance.habr.com
ВИДЖЕТ
ВКОНТАКТЕ
Хабы
Компании
Авторы
Песочница
Для компаний
Документы
Соглашение
Конфиденциальность
Нативные проекты
Образовательные
программы
Стартапам
Настройка языка
Техническая поддержка
© 2006–2024, Habr

Хабр
Подписан 1 друг
Подписаться на новости
БЛОГ НА ХАБРЕ
10 часов назад
История российской науки: напишем вместе?
31 янв в 15:03
10 «золотых» советов авторам любых текстов
28 янв в 12:22
Истории, достойные экранизации, или День защиты персональных данных
31 дек 2023 в 02:19
Поздравление-загадка от Хабра
29 дек 2023 в 18:31
Анонимный Дед Мороз на Хабре: хвастаемся подарками
1.3K
8
8.5K
41 +41
7.6K
16 +16
4K
44 +44
4.1K
97 +97"
red_mad_robot,117.94,04.05.2025,№1 в разработке цифровых решений для бизнеса,"Средний18 мин
redmadrobot
Cocoapods, Carthage, SPM: как выбрать
менеджер зависимостей в iOS
179
Блог компании red_mad_robot
, 
Разработка под iOS*
FAQ
КАК СТАТЬ АВТОРОМ

Старший iOS-разработчик red_mad_robot Аня Кочешкова
рассказывает, чем отличаются три менеджера зависимостей, в каких
случаях и для каких задач подойдёт тот или иной. Материал будет
полезен джун-специалистам, которые только начали погружаться
в разработку: специально для них подробно объясняем, что такое
семантическое версионирование, как устроены модули кода и в чём
разница между динамическими и статическими библиотеками.
Что такое менеджер зависимостей и зачем он нужен
В современной разработке зависимость — это написанный кем-то
другим код, который используется в вашей программе. Добавление
зависимости позволяет воспользоваться уже сделанной кем-то
хорошей работой и избежать «изобретения велосипеда», а также
лишних действий: проектирования, написания, тестирования,
отладки и поддержки определённой логики. Такие «куски логики»
называют пакетами, библиотеками или модулями.
Чем сложнее проект, тем больше сторонних библиотек (правда,
некоторые приложения могут вообще отказываться
от их использования), а у этих библиотек много разных версий. Они
могут ссылаться друг на друга и накладывать ограничения на эти
версии.
Эту работу можно проиллюстрировать таким бытовым примером.
Чтобы телефон показал погоду на улице, не нужно встраивать
в него термометр и вытаскивать за окно. В нём уже зашита
специальная технология, которая позволяет ему связаться
с «библиотекой», где хранятся данные гидрометцентра, которые,
как и погода, всё время обновляются. Иногда с новой версией
добавляется какая-нибудь новая функциональность. В примере
с термометром библиотека с новой версией умеет ещё
и выдавать карту дождей, а до этого могла показывать только

температуру.
Менеджеры зависимостей позволяют избежать долгого и муторного
решения такого набора «уравнений» — то есть берут на себя часть
работы, которую без них разработчик делал бы руками. Это система,
которая позволяет управлять зависимостями в вашем проекте.
А ещё у сторонних библиотек часто могут выходить новые версии
с исправленными ошибками, и благодаря менеджеру зависимостей
вам не нужно следить за их выходом — он всё обновит за вас.
Предположим, вы решили подключить в ваш проект Firebase
Crashlytics и GoogleUtilities. Обе эти библиотеки ссылаются
на библиотеку PromisesObjC. Firebase хочет, чтобы она была
любой версии, начинающейся с 2.1, а GoogleUtilities — чтобы она
была от 1.2 до 3.0. Такое уравнение, конечно, можно решить
вручную, но что делать, когда этих уравнений несколько
десятков, а уровней зависимостей — два, три или больше?
Для таких задач в распоряжении iOS-разработчика существуют три
основных менеджера зависимостей:
1. Cocoapods. Пожалуй, самый распространённый сегодня,
он требует лишь указывать список зависимостей
в определённом формате в текстовом файле.
2. Carthage. Менее удобен в этом плане: вы также указываете
список зависимостей в текстовом файле, но помимо этого нужно
ещё немного «самостоятельной работы», о которой расскажем
ниже.
3. SPM, или Swift Package Manager. Официальный менеджер
зависимостей от Apple. Появился недавно, и многие команды
переходят на него с Cocoapods. Позволяет управлять
зависимостями как через графический, так и через текстовый
интерфейс прямо из Xcode.
Случается, что нужная библиотека не поддерживает
необходимый менеджер зависимостей, потому что разработчики

каждой библиотеки сами выбирают, какой менеджер поддержать.
Поддержка каждого менеджера — это работа, которая занимает
определённое время, поэтому часто выбирают работать только
с самым популярным менеджером, Сocoapods. А если в проекте,
например, SPM, а библиотека есть только в Cocoapods или
просто нужна в одной конкретной версии, приходится добавлять
вручную как framework / xcframework, о чём мы также
поговорим позже.
Но прежде чем начать говорить об управлении зависимостями,
нужно разобрать несколько связанных с ним терминов.
Фантастическое Semantic Versioning, и где оно обитает
Semantic Versioning (SemVer) — это стандарт, который говорит о том,
как работать с версиями пакетов/библиотек/приложений, — как
их указывать и накладывать на них ограничения.
Зачем накладывать ограничения? Возьмём такой пример.
Разработчик создаёт приложение и использует некоторый набор
библиотек для упрощения работы — например, библиотек для
работы с сетью Alamofire. Допустим, начиная с определённой
версии в библиотеке появляется поддержка какой-то новой
функциональности, например Modern Concurrency. Эта
функциональность доступна только начиная с определенной
версии библиотеки. В таком случае от разработчика потребуется
всего лишь поднять версию Alamofire в манифесте, где
он описывает используемые библиотеки. Если начиная с какой-то
версии библиотеки исправляется некий важный баг, но не сильно
меняется функциональность самой библиотеки, то обновление
до свежей исправленной версии произойдёт без лишнего
вмешательства разработчика, в следующий раз при обновлении

текущих библиотек проекта.
Разберём, что такое SemVer, чтобы понимать формат версий,
с которыми придётся работать, а также узнаем, как можно указать
версию зависимости и наложить на неё ограничения.
Этот набор правил — глобальный стандарт, который используется
повсеместно, начиная от пакетов Node.js и заканчивая версиями
приложений в App Store.
По этому стандарту номер версии — это строка, которая состоит
из чисел, разделённых точкой, и имеет формат A.B.C, где A —
мажорная версия, B — минорная версия и C — патч-версия. Версии
сравниваются слева направо, например: 1.0.0 < 2.0.0 < 2.1.0 < 2.1.1.
Но зачастую мажорная версия увеличивается или при выпуске каких-
либо масштабных фич, или при редизайне приложения, или просто
при желании обозначить принципиальное обновление
приложения/библиотеки.
Синтаксис SemVer в Cocoapods, Carthage и SPM
Cocoapods
В Cocoapods можно указать одну из стратегий выбора версии:
1. Если необходима конкретная версия, просто укажите её без
дополнительных символов, как есть: '5.0.0'.

2. Если необходима точная версия, но при этом вы также хотите
обновляться, если придут исправления багов в патч-версии,
используйте операнд ~>: '~> 5.0.0'.
3. Можно указывать неравенства: '> 5.0.0', '≥ 5.0.0' или '< 5.0.0', '≤
5.0.0'.
В этом случае Cocoapods обновит библиотеку до 5.0.1, 5.0.2 и т. д.,
но не возьмёт обновление 5.1.0, так как в нём уже повышена
минорная, а не патч-версия. Если вы также хотите завязаться
на минорную версию, достаточно просто указать '~> 5.0'.
Carthage
В Carthage используется тот же формат, что и в Cocoapods, с тем
только исключением, что точная версия указывается через
равенство: == 5.0.0.
SPM
SPM позволяет указать стратегию выбора версии прямо
в интерфейсе, доступны следующие:
Аналогичный синтаксис и у Package.swift файла.
Модули — что к чему: библиотеки, фреймворки,
XCFramework и Swift-пакеты
Организация кода в iOS построена на понятии модулей. Модуль —
это отдельный кусок кода или функциональности, который можно
распространять разными способами и переиспользовать.

Существует четыре вида модулей. Разберёмся, в чём разница:
1. Библиотека — это исполняемый код, скомпилированный под
конкретную архитектуру.
2. Фреймворк — папка, содержащая в себе библиотеку
и вспомогательные файлы.
3. XCFramework — набор фреймворков под разные архитектуры.
4. Swift-пакет — фреймворк, который используется для работы
со Swift Package Manager.
Если говорить на языке бытовых примеров, то код — это
комната, а модули — разные предметы в ней. Торшер, например,
позволяет включать и выключать свет, но как он работает внутри,
мы не знаем. И этим торшером могут пользоваться в разных
квартирах и комнатах разные люди.
Библиотеки
Библиотека — это исполняемый код, скомпилированный под
конкретную архитектуру, например arm64.
Архитектуры могут различаться для разных типов устройств
и симуляторов:
• iOS-устройства — архитектуры armv7, armv7s, arm64,
• iOS-симулятор — архитектуры i386 и x86_64.
Исходный код — текст программы, который написал
разработчик. Исполняемый код — код, который получился
в результате компиляции. Компилятор переводит исходный код
в машинный, который сможет исполнить операционная
система, — на выходе получается исполняемый код.

Библиотеки бывают статическими и динамическими (об этом позже),
и представляют собой один бинарный файл.
Если представить, что библиотека — это настоящая библиотека
со стеллажами, в которых хранятся книги, то эти книги —
справочники о том, как что-то сделать (методы для выполнения
разных задач). По сути, это скомпилированный набор объектных
файлов, которые программа может использовать для выполнения
любой задачи. То есть все файлы, которые библиотека собирается
использовать, были скомпилированы до этапа компоновки.
Фреймворки
Фреймворк (.framework) представляет собой папку с файлами,
в которой лежит сама библиотека, хедеры и ресурсы. Эта папка
должна иметь определённую структуру, но нет нужды запоминать её,
так как фреймворки, как правило, собираются самим Xcode.
Поддержка фреймворков добавилась в iOS 8.
Фреймворки служат той же цели, что и библиотеки, но могут
включать в себя различные ресурсы — картинки, документацию,
строковые файлы.
Они также могут быть статическими или динамическими.

Что использовать: фреймворк или библиотеку
В чём же разница между фреймворком и библиотекой? И когда
их использовать? Принципиальное различие — в архитектуре.
XCFrameworks
Для начала стоит рассказать, что такое fat-фреймворки. Это такие
фреймворки, которые содержат библиотеки для разных архитектур
и платформ, соединённые в одну. С появлением Xcode 11 на замену
им пришли XCFrameworks, которые ввели структуру, позволяющую
разнести библиотеки для разных платформ и архитектур по папкам.
XCFramework — это, по сути, такой усовершенствованный fat-
фреймворк. Он также содержит различные библиотеки для разных
архитектур и платформ, но теперь нет необходимости трудиться над
тем, чтобы объединить их в одну. В одном XCFramework может
лежать несколько разных фреймворков — для iOS, macOS, tvOS,
watchOS, а также для разных архитектур — armv7, x86_64 и т. д.,
каждый в своей папке.
В каком-то смысле фреймворк — тоже разновидность
библиотеки, а XCFramework — разновидность фреймворка,
но всё же эти понятия принято разделять. Создатель
зависимости сам выбирает, в каком виде её распространять. Нам
важно понимать различие между этими видами, выбор можно
сделать, только создавая свою библиотеку.

Swift Package
Swift-пакет используется для распространения только через SPM.
Содержит исходный код, а также Package.swift файл, который
описывает его конфигурацию. Доступен начиная со Swift 3.
Static vs Dynamic
Прежде чем начать, наконец, говорить об управлении
зависимостями, важно разобраться, в чём различие между
статическими и динамическими библиотеками и фреймворками.
Первое, что здесь важно понимать: системные iOS- и macOS-
библиотеки — динамические. Приложения могут хранить ссылку
на библиотеку. Например, системная библиотека Foundation —
динамическая. Она лежит на айфоне в единственном экземпляре,
а все приложения лишь ссылаются на неё.
Фреймворки, как и библиотеки, бывают динамические и статические
и представляют собой обёртку библиотеки. Так, динамические
библиотеки вне фреймворков не поддерживаются на iOS, watchOS
и tvOS, и здесь важно отметить, что во всех дальнейших
сравнениях, говоря «динамическая библиотека», мы будем
иметь в виду её использование в рамках динамического
фреймворка.

Фреймворки в Cocoapods и Carthage
Зависимости, распространяемые через Cocoapods, называются
кокоаподами, или подами. До iOS 8 под представлял собой fat-
статическую библиотеку.
Есть специальная инструкция — по ней Cocoapods использует
фреймворки вместо статичных библиотек, которые
не поддерживались Swift до Xcode 9 и CocoaPods 1.5.0.
Так что раньше эта директива была обязательна, сейчас —
опциональна. Если нужно более быстрое время запуска, можно
её убрать (см. предыдущий раздел).
Carthage поддерживает только фреймворки.
target 'TargetName' do
  use_frameworks!
end

Три менеджера зависимостей: Cocoapods, Carthage,
SPM
Наконец, то, ради чего мы тут собрались, — менеджеры
зависимостей. Посмотрим, какие они бывают, чем отличаются и как
выбрать между ними.
Cocoapods
Это один из самых популярных сегодня менеджеров зависимостей.
Позволяет указать список зависимостей в текстовом файле, а затем
генерирует на основе его .xcworkspace, который будет содержать
два проекта — ваш проект и проект с подами.
Как правило, почти все библиотеки поддерживают Cocoapods,
хотя с развитием SPM стали появляться и такие, которые
поддерживают исключительно SPM (в основном это библиотеки
Apple). В таком случае, если ваш менеджер зависимостей
Cocoapods, единственный вариант воспользоваться
библиотекой — вручную её собрать и прилинковать к проекту.
Чтобы понять, поддерживает ли библиотека Cocoapods, достаточно
заглянуть в readme, либо обратить внимание на наличие .podspec-
файла в корне репозитория.
Все библиотеки, опубликованные в Cocoapods, можно посмотреть
на их официальном сайте.
Cocoapods в вашем проекте
Для понимания работы Cocoapods важны два термина — подфайл
и спека. Подфайл описывает все зависимости приложения,
а спека — библиотеку (её название и набор её зависимостей) для
Cocoapods. Спеки хранятся в общем репозитории спек Cocoapods.
Ещё их можно хранить в приватных репозиториях.

Для описания конфигурации зависимостей используется подфайл.
Этот файл написан на языке Ruby.
1. В файле опционально укажите источник спек. Источников может
быть несколько, даже приватные.
source 'https://github.com/CocoaPods/Specs.git' —
официальный источник спек, который указан по умолчанию.
source 'https://github.com/Artsy/Specs.gi — можно указать свои
источники спек, в том числе приватные.
2. Укажите минимальную версию iOS: platform: ios, '9.0'.
3. Укажите таргет и набор зависимостей для него. Если таргетов
несколько, укажите все, так как зависимости для них могут
различаться.
4. Декларируйте зависимость. Первым идёт её официальное
название (то самое, которое указано в спеке), затем версия.
Используйте в названии правила из блока про SemVer.
Есть и другие способы указать зависимости.
Это может понадобиться в случаях, когда нужно использовать
какую-то конкретную версию библиотеки. Например,
из определённой ветки репозитория, где она хранится, или даже
из определённого коммита. Либо указать путь локально, если
есть только её файл.
    target 'MyApp' do
    pod 'GoogleAnalytics', '~> 3.1'
    ...
    end

1. Можно указать ресурс репозитория, с которого будем загружать
библиотеку:
pod 'CRToast', :git =>
'https://github.com/akhatmullin/CRToast.git'
2. Можно указать нужную ветку в репозитории:
pod 'CRToast', :git =>
'https://github.com/akhatmullin/CRToast.git', :branch => 'dev'
3. Или тег:
pod 'CRToast', :git =>
'https://github.com/akhatmullin/CRToast.git', :tag => '0.7.0'
4. Или коммит:
pod 'CRToast', :git =>
'https://github.com/akhatmullin/CRToast.git', :commit =>
'082f8310af'
5. Можно указать на локальный под (путь должен вести на папку,
где лежит .podspec):
pod 'AFNetworking', :path => '~/Documents/AFNetworking'
Рядом с подфайлом обычно лежит Podfile.lock. Этот файл
описывает конечные версии зависимостей после их установки.
Он обычно так же заливается в GitHub, как и сам Podfile, чтобы
избежать ошибок и рассинхрона при установке зависимостей
у разных разработчиков. Ещё он ускоряет выполнение pod install.
Чтобы приступить к работе, запустите pod install. Можно выполнить
pod update, если вы хотите обновить все библиотеки в проекте,
иначе же будут использоваться фиксированные версии
зависимостей из Podfile.lock.
Как Cocoapods работает под капотом
Pod install генерирует workspace — файл .xcworkspace, состоящий
из двух проектов — проекта с вашим приложением и отдельного
проекта, в котором хранятся зависимости (поды).

Чтобы всё работало корректно, всегда открывайте workspace-файл.
Если внимательнее посмотреть, что происходит, можно увидеть, что
продукт этого проекта линкуется в основной проект:
Также Cocoapods добавляет пару скриптов в Build Phases:
Поддержка Cocoapods в вашей библиотеке

Чтобы библиотека была доступна через Cocoapods, нужно сначала
описать библиотеку или под при помощи спеки, собрать
её и отправить спеку в приватный либо глобальный репозиторий
Cocoapods.
Разберёмся, как это сделать.
1. Создайте спеку и файл лицензии.
Лицензию нужно добавлять для любой библиотеки, и чаще всего
используется лицензия MIT — самая популярная лицензия для
программ с открытым исходным кодом. Её текст можно найти
в интернете. Здесь нужно описать вашу библиотеку. Файл принято
форматировать так, чтобы вторая часть строки была выровнена.
    Pod::Spec.new do |spec|
    # Название библиотеки. Именно его будут указывать разраб
    spec.name                    = 'NAME' 
    # Версия
    spec.version                 = '1.2.1' 
    # Описание
    spec.summary                 = 'Describe your framework.
    # Здесь можно указать путь на вебсайт или просто GitHub-
    spec.homepage                = 'https://xxx' 
    # Путь к лицензии. Да, её тоже нужно создать
    spec.license                 = { type: 'MIT', file: 'LIC
    # Автор библиотеки
    spec.author                  = { ""Your Name"" => 'your-em
    # Путь к исходным файлам (чаще всего это ваш репозитоий)
    spec.source                  = { :git => 'https://github
    # Минимальная поддерживаемая версия iOS и Swift
    spec.ios.deployment_target   = '13.0' 
    spec.swift_version           = '5.0'
    # Если библиотека использует локальный фреймворк, его ну
    spec.vendored_frameworks     = 'Path/To/Files/NameOfVend

2. Проверьте, что всё корректно.
Следующая команда валидирует спеку — проверяет, что она
не имеет ошибок, а проект билдится — pod lib lint.
3. Отправьте спеку в репозиторий спек.
Как правило, это делается уже на финальном этапе разработки —
после того, как прошла проверка и вы готовы публиковать работу, —
pod trunk push NAME.podspec.
Carthage
    # Указываем вайлдкард-пути к файлам, которые необходимо 
    spec.source_files            = 'Path/To/Files/**/*.{swif
    # Путь к ресурсам
    spec.resources               = 'Path/To/Files/Resources/
    # Укажите здесь все ассеты, которые вам нужны, включая .
    spec.resource_bundles        = {'BundleName' => ['Path/T
    # Указываем зависимости
    spec.dependency           ""Alamofire"", ""~> 5.0.0"" 
    # И системные зависимости
    spec.frameworks           = 'Foundation' 
    spec.ios.frameworks       = 'UIKit'
    end

Carthagе — это децентрализованный менеджер зависимостей,
которые не нужно «поддерживать» разработчику. Carthage сам
выкачивает библиотеку из репозитория, компилирует
её и предоставляет в готовом виде. Поэтому, если хотите
использовать Carthage, не нужно искать в репозитории
с библиотекой определённые инструкции или слова о том, что
он поддерживается, — просто попробуйте.
Нет у Carthage и централизованного источника, как у Cocoapods.
Этим источником, по сути, является сам GitHub.
Конечно, этого не всегда бывает достаточно. Некоторые
библиотеки Carthage просто не может «переварить» — что-то
не собирается, а что-то отваливается. Задача разработчика —
проверить, всё ли работает корректно.
Наконец, Carthage может автоматически подхватить уже собранный
фреймворк, если он прикреплён к соответствующему релизу
на GitHub.
Carthage в вашем проекте
Зависимости в Carthage описываются в текстовом файле Cartfile.
Он очень похож на Podfile, только гораздо проще по структуре.
Мы указываем источник, имя зависимости и версию.
1. Источник зависимости. Как правило, GitHub, либо git для
универсальных репозиториев Git, размещённых в другом месте.
Ключевое слово git сопровождается путём к репозиторию, будь
то удалённый URL-адрес, используя git://, http://, или ssh://, или
локальный — путём к репозиторию git на компьютере
разработчика.
2. Название. Через слеш указывается владелец и название
репозитория, которые можно подсмотреть в ссылке
на репозиторий.

3. Версия. Особенности указания версий мы уже рассмотрели
в блоке про семантическое версионирование, но можно также
указывать и ветки.
Примеры:
1. Версия — github ""Alamofire/Alamofire"" == 2.0
2. Ветка — github ""username/project"" ""branch""
3. Локальный проект — git ""file:///directory/to/project"" ""branch""
4. Бинарник (путь указывается в json) — binary
""https://my.domain.com/release/MyFramework.json"" ~> 2.3
После описания зависимостей потребуется ещё несколько
дополнительных шагов.
1. Вызовите carthage update. Carthage склонирует репозитории
с указанных в Cartfile путей и затем сбилдит для каждой
зависимости фреймворк. После окончания работы вы увидите
несколько файлов и каталогов:
2. Полученные фреймворки затем вручную перетащите из папки
Build в проект в секцию Frameworks, Libraries и Embedded
Content.
3. Carthage требует добавления нового скрипта в Build Phases
в качестве workaround бага Apple. Это позволяет dSYM-
файлам корректно подтягиваться при архивации.

4. Перейдите в Build Phases и добавьте новый Run Script.
Добавьте следующую команду: /usr/local/bin/carthage copy-
frameworks.
5. Нажмите на плюс под Input Files и добавьте запись для каждой
платформы:
$(SRCROOT)/Carthage/Build/iOS/Alamofire.framework.
Как Carthage работает под капотом
Как и в случае с Cocoapods, создаётся лок-файл Cartfile.resolved,
который фиксирует конечные версии зависимостей.
Каталог Carthage содержит два подкаталога:
1. Build. Содержит собранный фреймворк для каждой
зависимости.
2. Checkouts. Содержит клонированные исходники, которые
Carthage потом компилирует. Это своего рода кэш, который
ускоряет работу.
Поддержка Carthage в вашей библиотеке
Для поддержки Carthage достаточно сделать релиз на GitHub.
Но никогда не помешает проверить, всё ли билдится корректно
в вашем случае и, если есть какие-то проблемы, решить их.
Для этого, выполните carthage build --no-skip-current. Carthage
попытается сбилдить ваш проект и создаст в нём папку Carthage.
Также стоит обратить внимание, что он видит только те схемы,
которые помечены в проекте как Shared.

SPM
Или Swift Package Manager — официальный менеджер
зависимостей от Apple.
Работа с ним происходит прямо в Xcode, а .Xcodeproj файлы
больше не нужны (хотя при желании есть возможность
сгенерировать файл проекта из SPM-пакета). Если заглянуть
в репозиторий библиотеки, то первое, что будет говорить
о поддержке SPM, — это наличие Package.swift-файла.
SPM в вашем проекте
Добавление зависимостей в проект происходит в секции Package
Dependencies.
1. Для начала выберите File > Swift Packages > Add package
dependecy.
2. Найдите модуль по поиску, либо введите URL репозитория.
3. Укажите версию:

Как и во всех предыдущих случаях, SPM создает Package.resolved,
назначение которого то же, что и у других менеджеров зависимостей.
В меню File > Swift Packages доступно несколько действий:
• Reset Package Caches удаляет кэши из Derived Data.
• Resolve Package Versions резолвит версии зависимостей.
Создаёт Package.resolved, если его не существует, но не меняет
его, если он уже есть. Может потребоваться, если
Package.resolved был, например, обновлён извне.
• Update to Latest Packages Versions обновляет версии пакетов,
может модифицировать Package.resolved.
Поддержка SPM в вашей библиотеке
Если вы разрабатываете библиотеку и хотите распространять
её через SPM, нужно будет создать Package.swift файл. Таким
образом может быть сконфигурирован и обычный проект, что
позволяет отойти от использования project-файлов. Конфигурация

через SPM выглядит чище и более проста для понимания
и редактирования, чем стандартные project-файлы, которые
зачастую нечитаемы.
Если вы пишете библиотеку и хотите распространять её через
SPM, обязательно убедитесь, что потенциальные потребители
библиотеки не используют Cocoapods. Одновременная
поддержка Cocoapods и SPM — часто непростая задача.
import PackageDescription
 
let package = Package(
    // Название нашего пакета
    name: ""Resources"",
    // Платформы, которые поддерживаются нашим пакетом
    platforms: [
        .iOS(.v11),
    ],
    // То, что будут использовать сторонние приложения
    products: [
        .library(
            name: ""Resources"",
            // Динамический или статический продукт
            // по дефолту значение nil - SPM сам будет поним
            // преференция, скорее всего, будет отдаваться .
            type: .dynamic,
            targets: [""Resources""]),
    ],
        // Зависимости, необходимые для работы нашего пакета
  // здесь они просто загружаются, добавляются они в target
    dependencies: [
        // Название пакета, путь к нему и источник (ветка, в
        .package(
            name: ""R.swift.Library"", 
            url: ""https://github.com/mac-cain13/R.swift.Libr
            branch: ""master""),
        .package(
            name: ""SVGKit"",
            url: ""https://github.com/SVGKit/SVGKit.git"",

И как выбрать подходящий менеджер
            .upToNextMajor(from: ""3.0.0"")),
        .package(
            name: ""PhoneNumberKit"",
            url: ""https://github.com/marmelroy/PhoneNumberKi
            from: ""3.3.4""),
        // Пример подключения локального пакета
        .package(path: ""../Core"")
    ],
    targets: [
        // Это то, из чего мы будем складывать наш продукт
        .target(
            name: ""Resources"",
            dependencies: [
                // Здесь мы указываем зависимости, которые м
                .product(name: ""RswiftDynamic"", package: ""R.
            ],
            resources: [
                // Все ресурсы, которые мы хотим использоват
                // Путь к ним относительный от Sources/имя_п
                .process(""Resources"")
            ])
    ]
)

Универсального ответа нет — выбор менеджера зависимостей
зависит исключительно от нужд и особенностей вашего проекта.
SPM чаще всего не будут поддерживать старые библиотеки,
в то время как Cocoapods вполне могут не поддерживать новые
(хотя это и большая редкость, чем первое). Carthage в этом плане
может показаться универсальнее. Хоть он более громоздкий
и сложный во взаимодействии, но он единственный разделяет шаги
управления зависимостями и добавления их в проект. Это даёт
контроль над ситуацией и ускоряет разработку — не будет лишних
пересборок или заморозки интерфейса, потому что нужно
зарезолвить зависимости.
Над материалом работали:
• текст — Аня Кочешкова, Ника Черникова,
• редактура — Виталик Балашов,
• иллюстрации — Юля Ефимова.
Делимся железной экспертизой от практик в нашем телеграм-канале
red_mad_dev. А полезные видео складываем на одноимённом
YouTube-канале. Присоединяйся!
Теги:  
red_mad_robot
,
ios
,
cocoapods
,
carthage
,
spm
,
swift package manager
,
зависимости
,
управление зависимостями
Хабы:  
Блог компании red_mad_robot
,
Разработка под iOS
+1
3
1

red_mad_robot
№1 в разработке цифровых решений для бизнеса
57
Карма
13
Рейтинг
@redmadrobot
Пользователь
Комментарии 1
Публикации
ЛУЧШИЕ ЗА СУТКИ 
ПОХОЖИЕ

 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 

Ваш
аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
ИНФОРМАЦИЯ
Сайт
redmadrobot.ru
Дата регистрации
16 августа 2009
Дата основания
16 ноября 2008
Численность
1 001–5 000 человек
Местоположение
Россия

Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
RUVDS.com,2394.92,,IT-инфраструктура для бизнеса,"Все потоки
VDS/VPS-хостинг. Скидка 15% по коду HABR15
Пишет в хабы:  Читальный зал, DIY или Сделай сам, Научно-популярное, Электроника для начинающих, 
Системное администрирование
Производство и разработка электроники
1935.27
40K
Timeweb Cloud
Облачная платформа для разработчиков и бизнеса
Пишет в хабы:  Читальный зал, Научно-популярное, JavaScript, DIY или Сделай сам, История IT
1538.54
1.1K
OTUS
Цифровые навыки от ведущих экспертов
Пишет в хабы:  Программирование, Java, Машинное обучение, Тестирование веб-сервисов, Python
830.05
103K
Яндекс
Как мы делаем Яндекс
Пишет в хабы:  Машинное обучение, Open source, Высокая производительность, Программирование, 
Интерфейсы
721.54
164K
Open Data Science
Крупнейшее русскоязычное Data Science сообщество
Пишет в хабы:  Машинное обучение, Искусственный интеллект, Natural Language Processing, Open source, 
Big Data
СТАТЬИ +63
НОВОСТИ +51
ХАБЫ
АВТОРЫ
КОМПАНИИ
Поиск
Название 
Рейтинг 
Подписчики
КАК СТАТЬ АВТОРОМ
Исследуем Духов Машин в новом Сезоне на Хабре

610.1
9.6K
ГК ЛАНИТ
Ведущая многопрофильная группа ИТ-компаний в РФ
Пишет в хабы:  Управление проектами, Карьера в IT-индустрии, Управление персоналом, 
Машинное обучение, Программирование
569.92
54K
VK
Технологии, которые объединяют
Пишет в хабы:  Big Data, Машинное обучение, DevOps, Tarantool, Облачные сервисы
536.94
167K
getmatch
Рассказываем о том, как строить карьеру в IT
Пишет в хабы:  Карьера в IT-индустрии, Лайфхаки для гиков, Читальный зал, IT-эмиграция, Урбанизм
436.91
953
Wiren Board
Оборудование для автоматизации и мониторинга
Пишет в хабы:  Умный дом, Интернет вещей, Инженерные системы, DIY или Сделай сам, 
Компьютерное железо
411.66
353
FirstVDS
Виртуальные и выделенные серверы в ДЦ в Москве
Пишет в хабы:  Научно-популярное, Системное администрирование, Читальный зал, 
Информационная безопасность, IT-инфраструктура
398.02
24K
Конференции Олега Бунина (Онтико)
Профессиональные конференции для IT-разработчиков
Пишет в хабы:  Управление разработкой, Конференции, DevOps, Управление проектами, 
Карьера в IT-индустрии
360.51
58K
AGIMA
Крупнейший интегратор digital-решений
Пишет в хабы:  Карьера в IT-индустрии, Управление проектами, Конференции, Управление персоналом, 
Управление продуктом
336.45
519
Альфа-Банк
Лучший мобильный банк по версии Markswebb
Пишет в хабы:  Конференции, Анализ и проектирование систем, Машинное обучение, JavaScript, 
Карьера в IT-индустрии

311.59
24K
Postgres Professional
Разработчик СУБД Postgres Pro
Пишет в хабы:  PostgreSQL, SQL, Администрирование баз данных, Open source, Хранение данных
305.42
76K
Ozon Tech
Стремимся делать лучший e-commerce в России
Пишет в хабы:  Конференции, Высокая производительность, Go, Тестирование веб-сервисов, 
Программирование
282.75
28K
TINKOFF
IT’s Tinkoff — просто о сложном
Пишет в хабы:  Разработка под Android, Машинное обучение, Тестирование IT-систем, 
Разработка мобильных приложений, Open source
282.47
40K
Хабр Карьера
Помогаем строить карьеру в IT
Пишет в хабы:  Карьера в IT-индустрии, Управление персоналом, Исследования и прогнозы в IT, 
Блог компании Хабр, Финансы в IT
280.35
14K
JUG Ru Group
Конференции для Senior-разработчиков
Пишет в хабы:  Конференции, Java, Тестирование IT-систем, Разработка мобильных приложений, JavaScript
276.72
41K
Southbridge
Обеспечиваем стабильную работу highload-проектов
Пишет в хабы:  IT-инфраструктура, DevOps, Системное администрирование, Карьера в IT-индустрии, 
Программирование
273.3
47K
1
2
3
... 16
17
ФИЛЬТР
Все
323
Веб-разработка
98
Программное обеспечение
180

Аппаратное обеспечение
40
Дизайн и юзабилити
22
Реклама и маркетинг
9
СМИ
5
Консалтинг и поддержка
49
Рекрутинг и HR
9
Электронная коммерция
41
Некоммерческие организации
5
Оптимизация
9
Производство мультимедиа-контента
9
Связь и телекоммуникации
54
Домены и хостинг
17
Поисковые технологии
9
Мобильные технологии
72
Веб-сервисы
97
Игры и развлечения
11
Информационная безопасность
47
Ваш аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты

Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
КАК СТАТЬ АВТОРОМ,107.0,04.05.2025,Зарплаты IT-специалистов,"Митчелл Бейкер, гендиректор Mozilla с 2020 года, объявила, что покидает свой пост и
возвращается на должность председателя совета директоров Mozilla Corporation, которую она
занимала ранее. Временным генеральным директором компании станет член правления Лора
Чемберс.
«За 25 лет работы в Mozilla я побывала на многих должностях. Мой теперешний шаг вызван
желанием сосредоточить внимание на предстоящих задачах. Я руководила бизнесом Mozilla в
период преобразований, а также курировала миссию Mozilla в более широком смысле. Стало
очевидно, что оба направления требуют преданного и постоянного руководства», — заявила
Бейкер в сообщении в блоге Mozilla.
Митчелл работает в Mozilla с эпохи Netscape Communications. Она основала Mozilla Foundation и
учредила лицензию Mozilla Public License.
Генеральный директор Mozilla покинула свой пост
1 мин
Войти
Моя
лента
Все
потоки Разработка Администрирование Дизайн Менеджмент Маркетинг Научпоп

141
Карма
145.1
Рейтинг
@AnnieBronson
Информационная служба Хабра
Реклама
Комментарии
Здесь пока нет ни одного комментария, вы можете стать первым!
Другие новости
AnnieBronson 59 минут назад
Лора Чемберс в должность генерального директора до конца этого года. Она входила в состав
совета директоров Mozilla в течение трёх последних лет, а до этого работала в Airbnb, PayPal,
eBay и Willow Innovations. По словам Бейкер, внимание Лоры « будет сосредоточено на
предоставлении успешных продуктов, продвигающих миссию компании, и создании платформ,
ускоряющих её развитие». 
«Мы находимся на критическом этапе, когда общественное доверие к институтам,
правительствам и Интернету достигло беспрецедентно низкого уровня. Происходит
тектонический сдвиг: каждый борется за будущее ИИ. Это возможность и необходимость для
Mozilla создать лучшее будущее», — заключила Бейкер.
Теги:  mozilla, mozilla foundation
Хабы:  IT-компании, Управление персоналом, Карьера в IT-индустрии
Редакторский дайджест
Присылаем лучшие статьи раз в месяц
Электропочта
Только полноправные пользователи могут оставлять комментарии. Войдите, пожалуйста.
ai.sbergraduate.ru РЕКЛАМА
Вакансии для студентов без опыта работы
Sberseasons: подай заявку на стажировку по IT и другим специальностям

SpaceX планирует использовать беспилотные баржи в качестве
морских интернет-станций для Starlink
2 мин
SLY_G 3 часа назад
Биологи научились регулировать кислотность клеток человека при
помощи света
3 мин
CloudMTS 3 часа назад
Облачный дайджест: затраты на VDI растут, SAP закрывает доступ,
дата-центр строят на 3D-принтере
2 мин
Cloud4Y 4 часа назад
Что делает тихоходок настолько живучими? Новое исследование
указывает на свободные радикалы
6 мин
IgnatChuker 5 часов назад
В Австралии приняли в первом чтении закон о праве работника
игнорировать рабочие звонки и сообщения в нерабочее время
2 мин
AnnieBronson 5 часов назад
Microsoft изменила интерфейс Copilot для Windows, чтобы сервис по
умолчанию запускался с большим окном чата
1 мин
301
+5
0
0
448
+6
0
0
633
+1
0
0
2.8K
+5
4
3 +3
3.2K
+23
8
29 +29
1.6K

avouner 5 часов назад
Российские банки выступили против оборотных штрафов до 500 млн
рублей за утечки данных
2 мин
LizzieSimpson 5 часов назад
Disney за $1,5 млрд купит долю в Epic Games
1 мин
daniilshat 5 часов назад
Безопасность конфигураций веб-сервера Angie PRO теперь
контролирует X-Config
1 мин
Travis_Macrif 5 часов назад
Министерство внутренней безопасности США создало новое
подразделение под названием AI Corps
2 мин
Показать еще
МИНУТОЧКУ ВНИМАНИЯ
0
0
7 +7
2.2K
+5
1
7 +7
874
+5
0
3 +3
183
+4
0
0
490
+3
0
2 +2
Интересно
Интересно 
Турбо

ВОПРОСЫ И ОТВЕТЫ
Есть ли плагин-""мусорка"" закладок для браузера Огнелис?
Mozilla · Простой · 1 ответ
Где скачать русскоязычную модель для TTS от Mozilla?
Mozilla · Простой · 1 ответ
Что делать, если сайт некорректно отображается в Mozilla FireFox?
Mozilla · Простой · 1 ответ
Огромные лаги в интерфейсе Firefox. Как исправить?
Mozilla · 2 ответа
Почему не работает слайдер jquery.jcarousel.js в браузерах Фаерфокс и ИЕ?
Mozilla · 0 ответов
Больше вопросов на Хабр Q&A
Зарплаты IT-специалистов во
второй половине 2023
Ах, этот скидочный снегопад:
поймай свою снежинку
Хабракалендарь, отворись! Какие
IT-ивенты ждут нас в 2024
Реклама

ЧИТАЮТ СЕЙЧАС
Тинькофф банк вернул 200 тысяч. Это был не дипфейк
Люди не понимают ООП
В России госведомства начали объявлять тендеры на уничтожение техники Apple
Yandex N.V. запретили в течение пяти лет создавать аналогичные «Яндексу» сервисы
«МегаФон» повысил цены на связь для некоторых абонентов, так как они от этого не отказались
5.8K
26 +26
50K
247 +247
45K
218 +218
13K
25 +25
8.8K
52 +52
sberbank.com
Кешбэк до 10%
бонусами
СберСпасибо —
сервис СберПремьер
4,6
Рейтинг организации
Акция для владельцев. Оформите
онлайн пакет услуг и получайте
выгоду от покупок
Оформить
Выделенная линия
Узнать больше
РЕКЛАМА

Знаете, что поменять в обучении ИБ? Рассказывайте!
Спецпроект
ИСТОРИИ
БЛИЖАЙШИЕ СОБЫТИЯ
Реклама
Хорошие статьи из
блогов компаний
Зарплаты в IT во
второй половине
2023
Учим английский
Не работай через
силу
Позовите автора!
Конк
Хабр
Как использовать
облачные платформы
Сloud.ru: серия демо-
встреч по четвергам
 1 – 29 февраля
 11:00
Онлайн
Подробнее в календаре
Конкурс грантов на
обучение IT-профессиям
от Хекслета
 5 – 29 февраля
Онлайн
Подробнее в календаре
Открытый урок
«Behaviour Tree в 
 8 февраля
 19
Онлайн
Подробнее в календаре

ADRIVER
Ваш аккаунт
Войти
Регистрация
Разделы
Статьи
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Настройка языка
Техническая поддержка
© 2006–2024, Habr"
22,0.0,20.03.2025,КАК СТАТЬ АВТОРОМ,"look, use the source!
1. Указывайте количественно и качественно выраженные достижения
Это самый главный и мощный пункт.
Большинство людей пишут какие-то беспомощные аморфные функции и фразы про
обязанности и участие — «состоял, привлекался, принимал участие». Это выглядит, как
свидетель из Фрязино, а не мощный проектный специалист, который будет двигать проект
вперёд.
Systems_Education
Как системному аналитику написать хорошее резюме — 11
рекомендаций
3 мин
1.8K
Анализ и проектирование систем*, Карьера в IT-индустрии
Туториал

Нанимающий руководитель смотрит прежде всего на результаты, а не на процесс. Если вы
пишете только про поток, это в глазах читающего создаёт риски того, что вы цените
процесс, а не результаты. (Процесс тоже важен, но про него отдельно).
Освойте язык результатов, важных для команды, бизнеса нанимателя, бизнеса клиента.
Как обычно пишут
Функции и задачи:
разрабатывал требования, общался с клиентами, командой, отвечал на вопросы,
рисовал схемы…
Как надо
Достижения:
разработал требования для 5 проектов в области X, Y, Z;
помог клиентам найти более выгодное решение;
сократил время на создание пакета требований в 2 раза относительно планового;
сократил количество обсуждений по требованиям в разработке в 3 раза;
уменьшил и удерживал количество циклов согласования с 4-х до 2-х;
внедрил в команде практику использования таких-то диаграмм, что сократило
длительность переписок и встреч;
выстроил доверительные отношения с ключевыми клиентами.
2. Не допускайте ошибок
Будьте предельно внимательны ко всем словам, типографике, аббревиатурам.
Кадровикам-рекрутёрам будет пофиг, но вот ваши будущие коллеги будут очень
пристально смотреть на ваш текст и всё, что будет резать глаз. Если вы допускаете
опечатки, ошибки в документе, который представляет вас всему рынку труда, то в рабочих
документах будете тем более. Никто не хочет бесплатно работать корректором.
Отдельный вопрос — логика построения предложений. В резюме для этого мало места, но
и тут некоторые умудряются нагородить странный порядок слов. Помните как мантру —
«Мама мыла раму», Субъект-Действие-Объект. Никто не хочет бесплатно работать
редактором. Писать понятные тексты — это одна из важнейших компетенций аналитика.

3. Только актуальный и релевантный опыт
Не указывайте места работы старше 8 лет, если только не хотите зачем-то подчеркнуть
разносторонность своего опыта — например, почему-то считаете, что то, что вы работали
таксистом полезно для конкретных вакансий, которые вы ищете.
4. Указывайте в местах работы основную трудовую функцию, а не
должность по трудовой
Запись в трудовой никого не интересует. Слова «старший специалист отдела
ВРИОКОМУНО» никому ни о чём не говорят, ну разве что вы точно были не младшим.
Пишите суть деятельности — «аналитик», «проектировщик», «координатор»,
«конструктор». Лучше, если там будет фигурировать как минимум слово «инженер».
5. Указывайте область деятельности компании / подразделения
Название компании тоже зачастую ничего не говорит читателю. Сразу после названия
позиции первой строчкой укажите, чем занимается компания — «разработка рудных
месторождений», «направление занимается кредитами для малого бизнеса» и т.д.
6. Указывайте объём управления
Иногда бывает, что человек работал ведущим аналитиком или руководителем группы и не
указывает, сколькими людьми управлял. Поверьте, между 2-мя людьми в подчинении и 7
есть разница, по крайней мере, при прочих равных.
7. Подкрепляйте софт-скиллы фактами
Лучше не писать «обучаемость», «креативность», «коммуникативность», это всем набило
оскомину и ничего не значит, кроме вашего желания, чтобы вас так воспринимали.
Пишите с примерами:
Высокая обучаемость: за 3 месяца досрочно освоила Enterprise Architect.
Креативность: придумала несколько концепций решений, которые мы с командой
смогли продать клиенту и они дали ему существенный эффект в бизнесе.

8. Указывайте, если готовы предоставить образцы документов по
запросу
Документы не обязательно должны быть рабочими, это могут быть и документы,
созданные вами на учебном курсе (Но такая фраза сразу приятно выделит вас на фоне
других кандидатов). А сейчас так и вообще, пример портфолио можно нагенерить и
оформить за пару-тройку часов!
9. Не забывайте про ключевые слова
Если у вас в резюме нет слов SQL, XML, UML, JSON, API, то совершенно неудивительно,
что вас невозможно найти (до трудно забыть дело даже не дойдет).
10. Покажите масштаб личности
Вполную вы сможете развернуться на встрече, но даже на уровне резюме люди хотят
работать с интересными людьми, а не роботами, которые выполняют трудовые функции
по договору.
Дайте представление читателю о вашем жизненном кругозоре и интересах, какими
вещами вы увлекаетесь. Причём желательно не просто «философия, психология», а
более предметно «изучаю аналитическую философию и гештальт-психологию». Одно
ключевое слово здесь может заставить нанимающего менеджера позвать вас на интервью.
11. Создавайте копии резюме с профильным позиционированием
Это совершенно бесплатно.
Если вы знаете, работа в каких сферах/темах проектов вам более интересна, создайте
копии резюме с соответствующими названиями:
Системный аналитик в интеграции;
Системный аналитик IoT;
и т.д.
Если хотите получить более предметную помощь по своему резюме и поиску работы —
идите к менторам.
Теги:  резюме, системный аналитик, трудоустройство, поиск работы

32
Карма
0
Рейтинг
@Systems_Education
Пользователь
Сайт
Сайт
Facebook
Telegram
Telegram
Реклама
Комментарии 22
Публикации
RationalAnswer
9 часов назад
Как обнулялся Credit Suisse: разбираем траекторию погружения
на дно швейцарского гига-банка
12 мин
kesn
10 часов назад
Хабы:  Анализ и проектирование систем, Карьера в IT-индустрии
Редакторский дайджест
Присылаем лучшие статьи раз в месяц
Электропочта
ЛУЧШИЕ ЗА СУТКИ
ПОХОЖИЕ
12K
Обзор
+75
26
49
АМА

Байки погромиста. Если кто-то скажет, что программирование —
это скучно
Простой
12 мин
Tutelka
9 часов назад
Обещания — настоящие и не очень
Простой
7 мин
alizar
9 часов назад
Удивительное рядом. Как устроен буфер обмена в Windows и Linux
Простой
6 мин
unxed
3 часа назад
Linux-порт Far Manager: новости весны 2023
Средний
4 мин
Робот Марвин ждёт тех, кто его удивит в Сезон ML на Хабре
Событие
Показать еще
МИНУТОЧКУ ВНИМАНИЯ
Разместить
11K
Мнение
+75
33
9
2.7K
Мнение
+34
24
10
4.6K
+31
46
10
1.7K
Дайджест
+29
14
7

ВАКАНСИИ
Системный аналитик
от 150 000 до 200 000 ₽ · SpectrumData · Екатеринбург
Системный аналитик
от 150 000 до 200 000 ₽ · Сбер · Екатеринбург
Системный аналитик\ бизнес-аналитик
до 250 000 ₽ · Главный радиочастотный центр · Москва
Системный аналитик (senior)
от 200 000 до 300 000 ₽ · Heaven 11 · Можно удаленно
Системный аналитик (внутренняя безопасность)
от 200 000 до 250 000 ₽ · Сбер · Москва
Больше вакансий на Хабр Карьере
Летопись data-driven-подхода, от статистики до
ML
Спецпроект
Kubernetes без хайпа: полезные на практике
посты о кубе
Турбо
Реклама

ЧИТАЮТ СЕЙЧАС
На LinkedIn обнаружили резюме человека, которому катастрофически не везёт с работодателями
Как обнулялся Credit Suisse: разбираем траекторию погружения на дно швейцарского гига-банка
«Призрачные вакансии» как новый HR-инструмент: растёт количество объявлений, по которым не
ищут сотрудников
Как получить доступ к chatGPT в России
2.4K
7
12K
48
4.1K
3
903K
233
РЕКЛАМА

Байки погромиста. Если кто-то скажет, что программирование — это скучно
Робот Марвин ждёт тех, кто его удивит в Сезон ML на Хабре
Событие
ИСТОРИИ
РАБОТА
Cистемный аналитик
528 вакансий
Все вакансии
Реклама
11K
9
Пункты сбора
вторсырья на
картах
Электровел с ИИ от
Acer
Кейсы ML в бизнесе
Полезная подборка
о зрении
Публичная
консультация с
экспертом:
рекрутеры

Реклама
Реклама
Ваш аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
Конкурс рассказов,466.0,04.05.2025,Открываем сезон футурологии с крутыми призами,"Для привлечения внимания расскажу историю. Уже много лет живу далеко за пределами
нашей всеми любимой родины. И на днях, понадобилось мне войти в старую почту gmail...
Логин и пароль надежно сохранены. Однако Google не торопится впускать нас в
собственную почту.
— Нам кажется что это не вы, подтвердите что это вы. Введите номер телефона
когда-то использовавшийся при регистрации.
Что ж, и это можно. Ввожу номер.
— Увы, мы не можем отправить СМС на этот номер. Хотите завести другой аккаунт?
Итак, все данные есть, однако подтвердить что это вы по техническим проблемам самого
сервиса невозможно. Связанные аккаунты, старая переписка, и файлы в облаке утрачены
навсегда. Какое-то знакомое чувство, не так ли? Другой аккаунт Google, прикрепленного
номера телефона нет и не было. Подтвердите что это вы. Выберите способ
подтверждения, Увы, доступных способов подтверждения нету. Завести новый
аккаунт?
Если вы уже начали понимать к чему клоню, то следующая история вам понравится еще
больше. Находясь в путешествии в дальних заморских странах, понадобилось три тысячи
долларов снять для оплаты жилья. Из приложения банка делаю перевод на свое
собственное имя... и вуаля, вы заблокированы! Войти в приложение нельзя для вашей
собственной безопасности!
Пишу в поддержку.
— Нам кажется что вы это не вы, надо подтвердить что это вы. Укажите кодовое
слово, номер того-и-сего.
Указываю. Прошу разблокировать банк и сделать транзакцию.
В поддержку сейчас пишет много людей. Ответ может занять неопределенное время.
Подождите пожалуйста подольше. Мы делаем все для клиентов!
Так проходит еще час. И поверьте, имена брендов в этой истории совершенно не важны.
Не потому, что хабр не жалобная книга, а потому что раком безопасности заражена вся
индустрия, не осталось ни одного захудалого приложения для заказа пиццы, не
построившего бы пароноидально-шизофреническую систему входов-подтверждений.
manul
За что безопасники будут гореть в аду?
4 мин
КАК СТАТЬ АВТОРОМ
Зарплаты айтишников
Huawei Mate 70 Pro: тест нови…
07.03.2025, 08:20
За что безопасники будут гореть в аду? / Хабр
https://habr.com/ru/articles/888708/
1/11

Из опыта, на посошок. Еще одна страна, еще один банк, еще одна сим-карта для
подтверждений, ведь других вариантов подтверждений банки сейчас не предлагают.
Дальнейшее путешествие. И вот сим-карта превращается в тыкву в роуминге. А следом за
ней и банк. Поддержка банка говорит что в целях безопасности без подтверждений по
СМС никак нельзя. Небезопасно. Достучаться до поддержки оператора в свою очередь
невозможно. Надо проходить безумный квест ""нажмите цифру"", а затем победить
электронного помощника-дебила. После этого услышать ответ по скрипту от человека, у
нас проблем не зафиксировано. Все для безопасности! Божок безопасности доволен!
Итак, это новая болезнь нашего мира, и она охватывает все сферы жизни. Она страшнее,
ближе, и опаснее, чем государственные регуляции. Из хозяев своих данных, под
благовидным предлогом, мы превратились в рабов безопасности всевозможных сервисов,
в том числе частных. Теперь не безопасность служит нам, а мы ей. А придумали, создали
и внедрили эту безумную систему подтверждений, вторых, пятых и десятых факторов,
настрочив об этом тонны статей, получив множество придуманных самостоятельно ачивок,
никто иные, как наши прибившиеся ""коллеги"" по IT-индустрии, так называемые
безопасники.
Напомню, самые страшные болезни заходят через системы безопасности организма. Рак,
СПИД, и аутоиммунные заболевания. И это произошло с нашей IT-индустрией, со всеми
веб-сервисами и мобильными приложениями. Мы заражены. Мы больше не хозяева своих
денег и данных. Все может накрыться медным тазом в произвольный момент.
Логин и пароль были слишком простым способом входа? Кто-то ставит слабые пароли! И
ради защиты детей тупых придумали второй фактор. Что может быть надежнее для этого,
чем кусочек пластика который выходит из строя, невозможно восстановить в другой
стране, и находится в зависимости от дополнительной, по сути, левой компании-
оператора? Разве что e-sim, которые помимо такой же зависимости от глючных операторов
в роуминге, так еще и превращаются в тыкву с поломкой телефона. Разбился экран в
другой стране, добро пожаловать в бомжи!
Но и этого религиозным фанатикам показалось мало, и они добавили алгоритмы
определения входа из необычных мест, устройств и так далее... А что, сидите дома,
холопы, это безопаснее!
Эталонный клиент современных мер безопасности, это слабоумный, пускающий слюни, с
трясущимися руками старик, забывающий все на свете, не помнящий как его зовут, и
никогда не выходящий на прогулку дальше пяти метров от дома.
Индустрия безопасности и безопасников, которая якобы должна спасать нас, сама
превратилась в гигантский источник опасности, который ввергает нас в рабство,
настоящую зависимость от странных и ненадежных факторов, технических проблем
третьих компаний, прихоти ""умных"" алгоритмов, лени техподдержки, фазы луны.
Конкурс рассказов
Открываем сезон футурологии с крутыми призами
07.03.2025, 08:20
За что безопасники будут гореть в аду? / Хабр
https://habr.com/ru/articles/888708/
2/11

Где-то мы это уже слышали, не правда ли? Безопасники частных компаний просто
повторили путь своих старших государственных братишек менее чем за пару десятилетий.
Логин и пароль это лучшее что было. Логин и пароль надежно и удобно хранятся в
специализированных БД, приложениях вроде KeePass, и так далее. Безопаснее с
дополнительными факторами не стало. Стало страшнее и опаснее за хрупкие и
ненадежные дополнительные факторы, которые периодически запрашивают. Вспомним,
вторым фактором может выступать ключевая фраза, ответ на вопрос про любимое блюдо
и так далее, практика, которую злобные гиганты намеренно ввергли в забытье.
Я призываю здравомыслящих людей разбить оковы рабства. Давайте будем создавать
приложения ради свободы, а не безопасности.
Свобода или безопасность?
61.54% Свобода
8
38.46% Безопасность
5
Проголосовали 13 пользователей. Воздержались 4 пользователя.
Теги: свобода, разработка, разработка приложений, 
разработка программного обеспечения, разработка сайтов, облачные сервисы, 
облачная инфраструктура
Хабы: Разработка мобильных приложений, Разработка облачных платформ, 
Исследования и прогнозы в IT, Программирование, IT-компании
Только зарегистрированные пользователи могут участвовать в опросе. Войдите,
пожалуйста.
Редакторский дайджест
Присылаем лучшие статьи раз в месяц
+7
0
1
Конкурс рассказов
Открываем сезон футурологии с крутыми призами
07.03.2025, 08:20
За что безопасники будут гореть в аду? / Хабр
https://habr.com/ru/articles/888708/
3/11"
Моя,5.0,04.05.2025,лента,"Идея написания этой статьи вдруг возниĸла у меня в начале 2025
года, ĸогда я проснулся 2 января с тяжелой головой и вдруг понял
что нужно сделать что хорошее, что то хорошее для вас, ĸаĸ
говорит моя дочь Маргарита «для тех ĸто в Интернете». Каĸ
минимум мне нужен ĸомпьютерный ĸласс на Raspberry Pi4, ну или
хотя бы ферма docker(ов).
Я обожаю Visual Studio Code, но мне всегда не хватает времени
чтобы более детально разобраться в его огромной
фунĸциональности, в различных ĸонфигурациях, тасĸах и
launch(ах) описанных в формате json и я решил это обойти. По
сути мне всегда не доставало несĸольĸих пунĸтов меню, ĸоторые
выполняют очень специфичесĸие фунĸции, нужные мне в
процессе сборĸи дистрибутива в системе Yocto Project для
Причесываем VSCode до неприличной Yocto
IDE или история одной кнопки
Средний
44 мин
1.5K
Open source*, Разработĸа на Raspberry Pi*, Программирование*, 
Системы сборĸи*, Операционные системы
Туториал
ЧИТАЮТ СЕЙЧАС
Как мы перенесли производство из
России в Китай из-за неожиданных
косяков
РКН рекомендует владельцам частных
виртуальных сетей отказаться при
передаче данных от иностранных
протоколов шифрования
Вот этого поворот: NVIDIA рассказала,
почему на самом деле горят
видеокарты RTX 50
Как я стал core-разработчиком Python
в 19 лет
Мнение: рекомендация РКН — мера
для мониторинга и определения
количества пользователей
зарубежных протоколов шифрования
74K
140 +140
26K
54 +54
28K
110 +110
10K
14 +14
1.1K
1 +1
+1
потоĸи
Разработĸа
Администрирование
Дизайн
Менеджмент
Марĸетинг
Научпоп
КАК СТАТЬ АВТОРОМ

формирования встраиваемых (Embedded) прошивоĸ.
Началось все с того, что нужное мне меню должно быть всегда
под руĸой, а лучшего места чем панель Status Bar в VSCode даже
не придумать, ближе неĸуда и я начал исĸать ĸаĸой нибудь плагин
предоставляющий эту возможность. Статья из серии DockerFace.
Кратĸое содержание статьи:
Выбор и настройĸа плагина для VSCode
Запись Yocto образа на SD ĸарту памяти
Сборĸа Yocto образа в Docker(е)
Прием Барона Мюнхгаузена для доĸументирования bash
Запусĸ Yocto образа RPi под виртуальной машиной Qemu
Развертывание DemoMinimal образа из Yocto ĸоробĸи
Выписываем Buster Slim(а) для ĸрутой разборĸе в Доĸере
Настройĸа DHCP, TFTP и NFS сервера
Загрузĸа core-image-minimal (wic) образа на rpi4 по сети
Сетевая загрузĸа Raspbian для платы Raspberry Pi4
Побочный эффеĸт сборĸи, загрузĸа ISO дистрибутива Ubuntu
по сети
Автоматичесĸий анализ Yocto логов с помощью Deepseek
самая ĸрасивая ĸнопĸа для друзей Элвиса
встраиваем ĸнопĸи в VSCode паровозиĸом
Выбор плагина для VSCode
Плагин называется ""VsCode Action Buttons"" (seunlanlege.action-
buttons), он делает именно то что мне и было нужно, позволяет
приĸрутить любой bash ĸод по нажатию ĸнопĸи.
Первым делом необходимо установить ĸаĸ сам VSCode (если он у
вас еще не установлен), таĸ и сам плагин:
sudo apt install -y snap
sudo snap install --classic code
code --install-extension seunlanlege.action-buttons
Настройĸи плагина добавляются в .vscode/settings.json  и

вызов shell сĸрипта, выглядит таĸ:
...
""actionButtons"": {
    ""reloadButton"": null,
    ""loadNpmCommands"": false,
    ""commands"": [
        {
            ""name"": ""Button-1"",
            ""singleInstance"": true,
            ""color"": ""#007fff"",
            ""command"": "".vscode/script1.sh"",
        },
        {
            ""name"": ""Button-N"",
            ""singleInstance"": true,
            ""color"": ""#ff007f"",
            ""command"": "".vscode/scriptN.sh"",
        }
    ]
}
Примечание: в моем случае это bash ĸод, но запусĸаемый ĸод
может быть и на любом другом языĸе, можно и просто
исполняемый бинарный файл запустить, ĸому ĸаĸ нравиться.
Запись Yocto образа на карту памяти
Первым делом в Yocto мне нужно было записать результат сборĸи
на ĸарту памяти microSDHC подĸлюченную с помощью
ĸартридера. Эта SD ĸарта в дальнейшем вставляется в
одноплатный ĸомпьютер, например Raspberry Pi 4, и плата с нее
загружается.
Вся необходимая мне фунĸциональность находится в одном
общем файле .vscode/yo/func.sh
и запусĸать фунĸции я буду оттуда.
Итаĸ вначале мне нужно найти списоĸ возможных файлов
образов, для записи на ĸарту SD, название целевой платформы
YO_M берется из основного ĸонфигурационного файла
""build/conf/local.conf"", расширение файла для записи ĸомандой dd
содержится в переменной YO_EXT .
YO_EXT="".wic .rootfs.wic .rootfs.wic.bz2 .rpi-sdimg .wic.bz

Результат работы фунĸции find_name_image  будет
содержаться в строĸовой переменной YO_IMAGE_NAME , названия
найденных образов разделены пробелами.
Далее мне необходимо найти SD ĸарту подĸлюченную через usb
или ĸартридер, формируется очень удобный табличный формат
вывода, ĸоторый позволяет убедиться что выбрано именно то
устройство, ĸоторое нужно, таĸ ĸаĸ после записи ĸомандой dd все
теĸущие данные удаляются и тут главное не ошибиться.
find_name_image() {
  IFS=$' '
  YO_IMAGE_NAME=""""
  if [ -z ""$YO_M"" ]; then echo ""MACHINE variable not found""
  for ext in ${YO_EXT}; do
      local find_str=$(ls -1 ${YO_DIR_IMAGE}/${YO_M} | grep
      if [ -z ""$find_str"" ]; then
          echo ""NAME IMAGE ${YO_M}${ext} is not found => ${
      else
          YO_IMAGE_NAME=""$YO_IMAGE_NAME $find_str""
          echo ""find: YO_IMAGE_NAME=$YO_IMAGE_NAME""
      fi
  done
  [[ -z ""${YO_IMAGE_NAME}"" ]] && return 1
  YO_IMAGE_NAME=$(echo ""$YO_IMAGE_NAME"" | tr '\n' ' ')
  return 0
}
find_sd_card() {
  IFS=$'\n'
  LI_DISK=""""
  echo ""Disk devices in the system:""
  echo ""┌────┬──────┬──────┬──────────────────────────────┐
  echo ""Name | Type | Size | Model                        |
  echo ""├────┴──────┴──────┴──────────────────────────────┘
  lsblk -o NAME,TYPE,SIZE,MODEL | grep -E 'disk|mmcblk|sd.*
  echo ""└─────────────────────────────────────────────────┘
  local bn;
  local list=$(ls -l /dev/disk/by-id/usb* 2>/dev/null)
  if [ $? -eq 0 ]; then
      for i in $list; do
          bn=$(basename $i)
          if ! echo ""$bn"" | grep -q ""[0-9]""; then LI_DISK+=
      done
  fi
  list=$(ls -l /dev/disk/by-id/mmc* 2>/dev/null)

Все найденные возможные носители содержаться в переменной
LI_DISK  и в фунĸции select_dd_info  предлагается списоĸ
пунĸтов от 1 до N, возможная ĸомбинация варианта ĸоманды dd
для образа и дисĸа.
Для записи нужно выбрать то что вы хотите записать, ввести
номер и нажать ввод, запись осуществляется с помощью ĸоманды
sudo, таĸ что у вас есть еще одна возможность убедиться в
правильности выбора устройства.
Если файл образа содержится в архиве bz2, то перед записью
образ будет распаĸован.
  if [ $? -eq 0 ]; then
      for i in $list; do
          bn=$(basename $i)
          if ! echo ""$bn"" | grep -q ""p[0-9]""; then LI_DISK+
      done
  fi
  if [ -n ""$LI_DISK"" ]; then echo ""LIST SD card => $LI_DISK
  else echo ""SD card not found => exiting ...""; return 1; f
}
select_dd_info() {
  local j=1
  IFS=$' '
  for i in $LI_DISK; do
      for image in $YO_IMAGE_NAME; do
          if echo ""$image"" | grep -q ""\.wic\.bz2""; then
              echo ""$j) bzip2 -dc $image | sudo dd of=/dev/
          else
              echo ""$j) dd if=$image of=/dev/$i bs=1M""
          fi
          j=$((j+1))
      done
  done
  echo -n ""=> Select the option. WARNING: the data on the d
  read SEL
  j=1
  for i in $LI_DISK; do
      for image in $YO_IMAGE_NAME; do
          if [ $SEL == ""$j"" ]; then
              mount | grep ""^/dev/$i"" | awk '{print $1}' | 
              if echo ""$image"" | grep -q ""\.wic\.bz2""; then
                  echo ""bzip2 -dc $image | sudo dd of=/dev/
                  bzip2 -dc $image | sudo dd of=/dev/$i bs=

Если на выбранном дисĸе уже есть подмонтированные разделы,
то перед записью они должны быть размонтированы. Для записи
дистрибутива на ĸарту памяти используется фунĸция
sdcard_deploy :
sdcard_deploy() {
  if find_sd_card && find_name_image; then
      cd ""${YO_DIR_IMAGE}/${YO_M}""
      select_dd_info
  fi
}
Фунĸциональность из сĸрипта .vscode/yo/func.sh лучше разделять,
таĸ ĸаĸ фунĸций можно наĸолотить множество и со временем, они
перемешиваются:
то работающие, то устаревшие, то еще ĸаĸие нибудь и то что
проверено можно выносить в отдельный сĸрипт, поĸажу на
примере .vscode/yo/sdcard_deploy.sh :
#!/bin/bash
this_f=$(readlink -f ""$0"")
this_d=$(dirname ""$this_f"")
source $this_d/func.sh
sdcard_deploy
Особенно это хорошо подходит для разделения
фунĸциональности, один работающий сĸрипт, ĸоторый выполняет
по возможности одну и тольĸо одну фунĸцию верхнего уровня.
Команды readlink и dirname используются для формирования
абсолютных путей до запусĸаемого файла и ĸаталога, а то с
путями всегда возниĸает путаница, а таĸ путь абсолютный и
              else
                  echo ""sudo dd if=$image of=/dev/$i bs=1M""
                  sudo dd if=$image of=/dev/$i bs=1M; sync
              fi
          fi
          j=$((j+1))
      done
  done
}

проблем меньше.
Итаĸ нажал ĸнопĸу в строĸе состояния VSCode, выбрал образ и
дисĸ для записи, и дистрибутив записался
.vscode/settings.json :
{
    ""name"": ""SDcardDeploy"",
    ""singleInstance"": true,
    ""color"": ""#007fff"",
    ""command"": ""cd .vscode/yo; ./sdcard_deploy.sh"",
}
Для плагина ""seunlanlege.action-buttons"" теĸущим является
ĸаталог, в ĸотором находиться ĸонфигурация .vscode, поэтому
перед вызовом фунĸции записи меняю теĸущий ĸаталог, это
сĸорее соглашение вызова, чтобы ĸоманды для ĸнопоĸ добавлять
похожим образом, для переменной ""YO_R""
у меня есть дополнительная проверĸа, ĸоторая срабатывает если
изначальный относительный путь для этой переменной уĸазан
неправильно:
Этот ĸод находиться в самом начале сĸрипта func.sh , здесь
ĸорневой ĸаталог определяется по наличию файла setup-
environment , ĸоторый отвечает за формирование
первоначальной струĸтуры дерева ĸаталогов сборĸи, таĸого ĸаĸ:
# корневой каталог yocto, где будет располагаться каталог b
YO_R=""../..""
find_setup_env() {
    if [ -f ""${YO_R}/setup-environment"" ]; then return 0; f
    local tmp_path=""..""
    for i in {1..7}; do
        if [ -f ""${tmp_path}/setup-environment"" ]; then
            export YO_R=$(realpath ""${tmp_path}"")
            return 0;
        fi
        tmp_path=""${tmp_path}/..""
    done
    echo ""error: 'setup-environment' not found in parent di
}
find_setup_env

 корневой каталог Yocto
    ├── build
    ├── downloads
    ├── setup-environment
    ├── shell.sh
    └── sources
Сборка Yocto образа в Docker
Следующая фунĸция для VSCode, ĸоторая мне нужна, это фунĸция
позволяющая собирать дистрибутив Yocto разными тулчейнами.
Для старых Yocto ветоĸ, на новых хост системах, например в
Ubuntu 24.04 все ну постоянно отваливается, то gcc не той версии,
то линĸовщиĸ, а то и вообще cmake ну совсем старый нужен.
Каĸ то всегда возниĸает полная несовместимость инструментов
сборĸи и того, что я хочу собрать, сейчас без Docker(а) в старые
сборĸи лучше и не соваться, прямо беда, беда.
Да и в новые тоже, реĸомендую сборĸу осуществлять всегда
тольĸо в доĸере.
Конфигурацию доĸера(ов) располагается в ĸаталоге
.vscode/yo/docker , например => ubuntu_22_04
    yo
    ├── build_image.sh
    ├── docker
    │   └── ubuntu_22_04
    │       ├── Dockerfile
    │       └── Makefile
    ├── func.sh
    └── sdcard_deploy.sh
Содержание Dockerfile следующее:
FROM ubuntu:22.04
# Переключаю Ubuntu в неинтерактивный режим — чтобы избежат
ENV DEBIAN_FRONTEND noninteractive
# WARNING PUB = ""/mnt/data""
#
RUN mkdir -p ""/mnt/data""
# Устанавливаю mc и перенастраиваю locales
RUN apt update && \

Контейнер запусĸается под пользователем user, но в случае ĸаĸих
либо непредвиденных проблем, добавляется пароль ""docker"" для
пользователя root и вы можете подĸлючиться работающему ĸ
ĸонтейнеру под root(ом), и например установить ĸаĸой нибудь
паĸет, с использованием ĸоманды apt.
После устранения проблемы зависимостей, можно название этих
недостающих паĸетов добавить в Dockerfile напрямую, а ĸаĸ
отладили образ для ĸонтейнера, строĸу можно заĸомментировать.
Для работы с доĸером служит Makefile:
    apt -y install \
    mc language-pack-ru \
    && locale-gen ru_RU.UTF-8 en_US.UTF-8 \
    && dpkg-reconfigure locales
RUN echo ""LANG=ru_RU.UTF-8"" >> /etc/default/locale \
    && echo ""LANGUAGE=ru_RU.UTF-8"" >> /etc/default/locale
ENV LANG ru_RU.UTF-8
ENV LANGUAGE ru_RU.UTF-8
# Устанавливаю зависимости Yocto Project
RUN apt -y install \
    gawk wget git-core diffstat unzip texinfo gcc-multilib 
    build-essential chrpath socat libsdl1.2-dev xterm cpio 
RUN echo 'root:docker' | chpasswd
# Создание пользователя докера
RUN groupadd -f --gid 1000 user \
    && useradd --uid 1000 --gid user --shell /bin/bash --cr
# Примечание: для подключения к работающему контейнеру под 
# docker exec -u 0 -it hash_container bash
USER user
WORKDIR /mnt/data
ENTRYPOINT [""./shell.sh""]
IMAGE = ubuntu_22_04
# каталог для сборки образа внутри контейнера, такой же пут
PUB   = ""/mnt/data""
# путь до корневого каталога сборки, в котором находится фа
YO_R ?= $(shell dirname $(shell pwd))
run:
    docker run --rm \
    --network=host \

Здесь доĸер запусĸается следующим образом:
docker run --rm \
  --network=host \
  -v ${HOME}/.ssh:/home/user/.ssh:z \
  -v $(shell readlink -f ${SSH_AUTH_SOCK}):/ssh-agent \
  -e SSH_AUTH_SOCK=/ssh-agent \
  --cap-add=cap_sys_admin \
  --cap-add=cap_net_admin \
  --cap-add=cap_net_raw \
  --mount type=bind,source=${YO_R},target=${PUB} \
  -d -t ${IMAGE}
где
rm — автоматичесĸое удаление ĸонтейнера после завершения
его работы;
    -v ${HOME}/.ssh:/home/user/.ssh:z \
    -v $(shell readlink -f ${SSH_AUTH_SOCK}):/ssh-agent -e 
    --cap-add=cap_sys_admin --cap-add=cap_net_admin --cap-a
    --mount type=bind,source=${YO_R},target=${PUB} -ti ${IM
run_detach:
    docker run --rm \
    --network=host \
    -v ${HOME}/.ssh:/home/user/.ssh:z \
    -v $(shell readlink -f ${SSH_AUTH_SOCK}):/ssh-agent -e 
    --cap-add=cap_sys_admin --cap-add=cap_net_admin --cap-a
    --mount type=bind,source=${YO_R},target=${PUB} -d -t ${
build:
    docker build -f Dockerfile --tag ${IMAGE} .
rebuild:
    docker build -f Dockerfile --no-cache --tag ${IMAGE} .
install:
    sudo apt-get update
    sudo apt-get install -y docker.io
# удаление всех остановленных контейнеров,
clean-all-container:
    sudo docker rm $(docker ps -qa)
.PHONY: run build clean-all-container

network=host — c этим параметром устраняется сетевая
изолированность; между ĸонтейнером и хостом Docker и
напрямую используются сетевые ресурсы хоста, это
небезопасно для хоста, и может применяться тольĸо в том
случае, если вы знаете, что данный ĸонтейнер предназначен
для внутренней заĸрытой извне сети;
v (или --volume) используется docker(ом) для создания
пространства хранения внутри ĸонтейнера, ĸоторое отделено
от остальной части файловой системы ĸонтейнера, том не
увеличивает размер ĸонтейнера, в данном случае
пробрасывается соĸет c ssh-agent(ом) запущенном на хосте
для работы ssh авторизации внутри ĸонтейнера;
cap-add=cap_net_admin привилегия, ĸоторая позволяет
монтировать и размонтировать файловые системы;
cap-add=cap_sys_admin предоставляет ĸонтейнеру набор
системных привилегий, но не делает его полностью
привилегированным;
cap-add=cap_net_raw привилегия дающая право на создание
RAW и PACKET соĸетов в ĸонтейнере, в частности эта
привилегия необходима для получения и отправĸи ICMP
паĸетов в ĸонтейнере;
mount опция монтирования, ĸоторая пробрасывает ĸорневой
yocto ĸаталог, в ĸотором таĸже располагается ĸаталог build, он
содержит все артефаĸты сборĸи, таĸим образом весь
результат работы ĸонтейнера сохраняется в хост системе,
этим я обеспечиваю то, что можно беспрепятственно
останавливать и удалять ĸонтейнер, а в новом запусĸе можно
продолжить работу на тех же артефаĸтах. После первого
запусĸа переменных среды yocto (setup-environment),
сборочный путь жестĸо прописывается в ĸонфигурационных
сĸриптах и при изменении точĸи монтирования PUB /mnt/data
на другую сборĸа внутри ĸонтейнера не будет работать, при
проверĸе путей сборĸи в bitbake вы получите сообщение об
ошибĸе (но это особенность системы сборĸи yocto);
d запусĸ ĸонтейнера в фоне;
t обеспечение ĸонтейнеру запусĸ псевдотерминала tty,
ĸонтейнер не завершит свою работу, поĸа сеанс терминала не
заĸончиться.
Переменная IMAGE  уĸазывает основное имя с ĸоторым
ĸонтейнер будет запущен.
Таĸ же если вы хотите запустить доĸер не в фоне, а на переднем
плане, нужно убрать опцию ""-d"" и добавить опцию ""-i"", чтобы
ĸонтейнер запусĸался в интераĸтивном режиме, ĸогда можно

напрямую вводить ĸоманды в работающей оболочĸе ĸонтейнера, в
Makefile я разделяю эти режимы:
make run - интераĸтивный режим с инициализацией yocto
(выполнение setup-environment);
make run_detatch - фоновый запусĸ ĸонтейнера, для того,
чтобы подĸлючиться ĸ уже запущенному ĸонтейнеру, для
выполнения одной ĸоманды bitbake, при ĸаждом запусĸе
создается shell сеанс с инициализацией setup-environment и
последующим выполнением в нем пользовательсĸой
ĸоманды.
Далее для работы с этим Makefile(лом) мне нужно в
.vscode/yo/func.sh  добавить фунĸцию поисĸа
идентифиĸатора запущенного Docker ĸонтейнера:
результат поисĸа сохраняется в переменой CONTAINER_ID
и используется в фунĸции запусĸа ĸоманд внутри ĸонтейнера
start_cmd_docker():
CONTAINER_ID=""""
CONTAINER_NAME=""""
DOCKER_DIR=""""
find_docker_id() {
    local id=$(docker ps | grep -m1 $CONTAINER_NAME | cut -
    if [ -z ""$id"" ]; then CONTAINER_ID=""""; return 1;
    else CONTAINER_ID=$id; return 0; fi
}
start_cmd_docker() {
  if [ -z ""$1"" ]; then
      echo ""error: start_cmd_docker(), arg1 command name em
      return 1;
  fi
  local cmd_args=$1
  check_build_dir_exist
  [[ $? -eq 2 ]] && return 2
  cd ""${DOCKER_DIR}"" && make build
  if ! find_docker_id; then
      make run_detach
      if ! find_docker_id; then
          echo ""failed to start container => make run_detac
          cd ""${CURDIR}""
          return 3;

где первым аргументом можно передать ĸоманду или списоĸ
ĸоманд, ĸоторые разделяются символом "";""
Здесь главное, чтобы переменная DOCKER_DIR  содержала
правильный путь до ĸаталога с Makefile для Docker(a).
Фунĸция start_cmd_docker  вначале ищет hash идентифиĸатор
ĸонтейнера по имени, ĸоторое можно посмотреть в Makefile, см.
IMAGE=ubuntu_22_04, и если ĸонтейнер не запущен, то он
запусĸается в фоновом режиме (make run_detach) и далее через
ĸоманду docker exec идет подĸлючение и запусĸ нового bash
процесса, в ĸотором и происходит выполнение переданных
первым аргументом ĸоманд см. $cmd_args
Есть еще дополнительная проверĸа, на наличие ĸаталога сборĸи
build, и если его нет, то ĸоманды в ĸонтейнере запущены не будут.
Работа с этой фунĸцией описана в shell сĸрипте
.vscode/yo/build_image.sh
Процесс запусĸа разделяется на две части:
статичесĸую: cmd_init и динамичесĸую cmd_run, со списĸом
ĸоманд, ĸоторые вы хотите запустить внутри Yocto среды,
например:
bitbake имя_образа_для_сборĸи;
      fi
  fi
  echo ""docker exec -it ${CONTAINER_ID} bash -c \""$cmd_args
  docker exec -it ${CONTAINER_ID} bash -c ""$cmd_args""
  cd ""${CURDIR}""
}
  #!/bin/bash
  this_f=$(readlink -f ""$0"")
  this_d=$(dirname ""$this_f"")
  source $this_d/func.sh
  cmd_runs=""$1""
  DOCKER_DIR=""docker/ubuntu_22_04""
  CONTAINER_NAME=""ubuntu_22_04""
  cmd_init=""cd /mnt/data; MACHINE=$YO_M source ./setup-envi
  start_cmd_docker ""${cmd_init}; ${cmd_runs}""

bibbake имя_отдельного_рецепта_для_сборĸи;
и т.д.
cmd_init осуществляет запусĸ Yocto среды сборĸи под уĸазанную
целевую платформу, сĸрипту setup-environment
передается название платформы (берется из build/conf/local.conf).
Запусĸ сĸрипта build_image.sh, по нажатию ĸнопĸи в status bar
прописывается в .vscode/settings.json  таĸ:
таĸже по нажатию ĸнопĸи Build можно запустить интераĸтивный
сеанс работы с bitbake, за это отвечает фунĸция
start_session_docker , описанная в .vscode/yo/func.sh:
  start_session_docker() {
      cd ""${DOCKER_DIR}""
      make build && make run
      cd ""${CURDIR}""
  }
Здесь сам запусĸ shell процесса описан в последней строĸе:
Dockerfile: ENTRYPOINT [""./shell.sh""]
В этом случае остается запущенным терминал в VSCode, ĸ
ĸоторому вы всегда сможете обращаться для работы с вашей
...
""actionButtons"": {
  ""reloadButton"": null,
  ""loadNpmCommands"": false,
  ""commands"": [
    {
      ""name"": ""Build"",
      ""singleInstance"": true,
      ""color"": ""#007fff"",
      ""command"": ""cd .vscode/yo; source func.sh; DOCKER_DIR
    },
    {
      ""name"": ""BuildImage"",
      ""singleInstance"": true,
      ""color"": ""#007fff"",
      ""command"": ""cd .vscode/yo; ./build_image.sh 'bitbake 
    }
  ]
}

Yocto сборĸой.
Запуск Yocto сборки для Raspberry Pi под виртуальной
машиной Qemu
Следующей фунĸцией ĸоторую я захотел добавить для VSCode
является фунĸция запусĸа и отладĸи Yocto дистрибутива без
наличия платы Raspberry Pi, иногда ĸогда платы нет под руĸой не
получается посмотреть вновь собранный Yocto образ, пример
поĸажу для платы Raspberry Pi 3, таĸ можно запустить тольĸо 64
битный образ.
где:
qemu-system-aarch64  - запусĸ Qemu для 64 битных сбороĸ,
если вдруг вы захотите запустить дистрибутив собранный под 32
битную разрядность, то вас может ждать пустой терминал, совсем
пустой, ядро даже не пиĸнет, и в этом случае сильно помогает
start_qemu_rpi3_64() {
  local curdir=$(pwd)
  local kernel=""Image""
  local dtb=""${IMAGE_DTB}""
  local image=""${IMAGE_NAME}""
  cd ""${YO_R}/${YO_M}""
  [[ -f ""${kernel}"" || -f ""${dtb}"" || -f ""${image}"" ]] && r
  size_mb=$(( ($(stat -c %s ""$image"") + 1048575) / 1048576 
  thresholds=(64 128 256 512)
  for threshold in ""${thresholds[@]}""; do
      if [ ""$size_mb"" -lt ""$threshold"" ]; then
          qemu-img resize ""${image}"" ""${threshold}M""
      fi
  done
  qemu-system-aarch64 \
      -m 1G \
      -M raspi3b \
      -dtb ${dtb} \
      -kernel ${kernel} \
      -serial mon:stdio \
      -drive file=${image},format=raw,if=sd,readonly=off \
      -append ""console=ttyAMA0,115200 root=/dev/mmcblk0p2 r
      -nographic
  cd ${CURDIR}
}

опция:
-d in_asm -D QEMU_log.txt  для записи всех ассемблерных
инструĸций в отдельный файл, это медленно, но если вы
перепутали процессорные инструĸции, то вы должны об этом
узнать.
Параметры:
m 1G  - ĸоличество оперативной памяти;
M raspi3b  - тип запусĸаемой машины Raspberry Pi 3;
dtb bcm2837-rpi-3-b.dtb  - уĸазание правильного дерева
устройств для нашей платы, без него ядро не сможет
запуститься и инициализировать устройства RPI3, DTB (Device
Tree Blob) описывает все ĸомпоненты платы: CPU, периферия,
адреса памяти и прерывания для устройств;
kernel Image  - название файла с ядром, ĸоторое
запусĸается;
serial mon:stdio  в qemu позволяет вам перенаправить
выходные данные последовательного порта на стандартный
ввод-вывод (stdout) вашей терминальной сессии, таĸим
образом всё, что отправляется на последовательный порт
виртуальной машины, будет выводиться в терминал, из
ĸоторого вы запустили Qemu, и вы сможете вводить данные в
виртуальную машину через тот же терминал;
drive file=${image},format=raw,if=sd,readonly=off - подĸлючает
виртуальный дисĸ ĸаĸ SD ĸарту в raw (сыром) формате, при
этом в самом файле содержится таблица разделов и два
логичесĸих дисĸа (см. fdisk -l $image ), на втором дисĸе
находится ĸорневая файловая система rootfs, дисĸ будет
доступен для записи;
append ""console=ttyAMA0,115200 root=/dev/mmcblk0p2 rw
earlycon=pl011,0x3f201000"" здесь настраивается системная
ĸонсоль:
console=ttyAMA0,115200  это основной ĸанал связи
между ядром Linux и пользователем;
root=/dev/mmcblk0p2 rw  подĸлючает второй
логичесĸий раздел блочного устройства ĸаĸ ĸорневую
файловую систему в режиме чтение/запись;
earlycon=<драйвер>,<опции>,<адрес>  выводить
сообщения на этапе загрузĸи до инициализации основных
драйверов, формат ввода:

pl011  — это тип UART-ĸонтроллера, используемого
в Raspberry Pi;
адрес 0x3f201000  уĸазывает на регистры этого
ĸонтроллера в памяти, хочу отметить, что этот адрес
специфичен для реального железа Raspberry Pi, в
плате Raspberry Pi ttyAMA0 всегда связан с
ĸонтроллером UART pl011;
nographic  - отĸлючение графичесĸого вывода, при этом
виртуальная машина будет работать в теĸстовом режиме, без
использования стандартного графичесĸого интерфейса Qemu,
все выводимые сообщения (вĸлючая вывод из гостевой ОС)
отображаются в терминале, из ĸоторого была запущена
виртуальная машина, это позволяет вести мониторинг работы
системы и взаимодействовать с ней тольĸо через теĸстовые
ĸоманды.
Для Qemu raspi3b используется DTB, более совместимый с
эмуляцией: dtb=""bcm2837-rpi-3-b.dtb"".
Еще можно использовать дополнительные опции для отладĸи:
""-d guest_errors,unimp,cpu_reset -D QEMU.log"":
Опции вĸлючают разные ĸатегории отладочной информации,
информация сохраняется в отдельном файле:
guest_errors : фиĸсирует ошибĸи, возниĸающие у гостевой
операционной системы;
unimp : записывает попытĸи использования недоступных
инструĸций или фунĸциональности в эмулируемом
устройстве;
cpu_reset : фиĸсирует информацию, связанную с сбросом
процессора.
На реальной плате Raspberry Pi 3 управляющим является GPU, он
там вообще главный, а CPU полностью находится в этой
зависимости. Проприетарный загрузчиĸ bootcode.bin обычно
находится на первом загрузочном разделе SD ĸарты, и первым
делом он грузит прошивĸу для GPU => start.elf и fixup.dat (или в
зависимости от версии платы start4.elf), и передает ей
управление, прошивĸа для GPU разбирает файл ĸонфигурации
config.txt
формируя загрузочные параметры ядра и передает управление
CPU для запусĸа ядра.
Представленная выше ĸоманда ""qemu-system-aarch64 ...""

работает немного иначе:
Во первых мы с вами убираем GPU из этой цепочĸи, мы его
игнорируем, осуществляя прямую загрузĸу ядра через параметр -
kernel, таĸ быстрее и меньше ошибоĸ, у нас ĸонечно есть все
загрузочные файлы на первом загрузочном разделе SD ĸарты см
-drive file=${image}  (в системе это /dev/mmcblk0p1), но
именно проверять сам механизм вторичных и третичных
загрузчиĸов ĸаĸ то не хочется.
Да и не понятно, на ĸаĸом уровне работает эмуляция GPU в QEmu
для -M raspi3b , здесь главное передать ядру аĸтуальный
dtb=""bcm2837-rpi-3-b.dtb"", без него то же ничего работать не
будет.
Ядро запусĸается, инициализирует оборудование, подĸлючает
ĸорневую файловую систему, ОС переходит на нужный уровень
исполнения, запусĸает виртуальные терминалы tty  через getty
процессы, ĸоторые создают сессии для ввода/вывода
пользователя и если мы правильно ассоциировали getty  c
нашим эмулируемым ĸонтроллером UART pl011 => 
/dev/ttyAMA0  то мы увидим пользовательсĸое приглашение
login: и далее можно вводить пароль и работать.
Здесь есть еще один нюанс:
Если ничего не менять в образе, то getty  не будет
ассоциировать с /dev/ttyAMA0 , и
для того, чтобы это произошло нужно еще дополнительно собрать
образ с использованием:
Вообщем то, получается ĸаĸ то совсем не удобно, специально
пересобирать тот же core-image-minimal для запусĸа под
виртуальную машину Qemu, но можно /etc/inittab  менять на
лету в core-image-minimal.wic , вначале смонтировать его c
  # это с учетом того, что система запускается через SysVin
  # под Systemd это не проверялось (там по другому)
  SERIAL_CONSOLES = ""115200;ttyAMA0""
  SERIAL_CONSOLES_CHECK = ""ttyAMA0:ttyS0""
  # эти параметры повлияют на изменения
  # системного файла /etc/inittab в образе
  # и ассоциируют getty с последовательным портом
  # Параметры добавляются в
  # конфигурационный файл слоя в `local.conf`

помощью mount_raw_image  (см. ниже), сĸорреĸтировать,
сохранить изменения и вызвать umount_raw_image  (будет
время я это проверю).
Использование приема Барона Мюнхгаузена для
документирования bash
Здесь я хотел бы привести следующий пример, простого само
доĸументирования bash ĸода:
Это удобно тем, что если работать со сĸриптом через:
source name_script.sh
то можно сразу увидеть названия всех используемых
интерфейсов сĸрипта.
Для того чтобы фунĸция попала в это описание, достаточно,
добавить ĸомментарий перед названием фунĸции, ĸомментарий
должен быть в начале строĸи и за ним должен следовать пробел,
а если вы хотите убрать фунĸцию из описания, то достаточно
убрать этот пробел.
Комментарии внутри bash фунĸций уже в help не попадут по
определению, таĸ ĸаĸ они идут не вначале строĸи, а сдвинуты хотя
бы на 4 пробела, таĸ ĸаĸ форматирование в сĸриптах я надеюсь
#!/bin/bash
help() {
    local script_path=$(realpath ""${BASH_SOURCE[0]}"")
    grep -A 1 ""^# "" ""${script_path}"" | sed 's/--//g'
}
# Пример bash функции 1 (входит в описание интерфейсов)
example_bash_function1() {
    echo ""example_bash_function1""
}
# Пример bash функции 2 (входит в описание интерфейсов)
example_bash_function2() {
    echo ""example_bash_function2""
}
#Пример bash функции 3, которая исключается из описания инт
example_bash_function3() {
    echo ""example_bash_function3""
}
help

еще ниĸто не отменял.
Каĸ это работает:
realpath — преобразует относительный путь в абсолютный;
grep -A 1 ""^# "" — ищет строĸи, начинающиеся с ""# "" и
захватывает следующую строĸу;
sed 's/--//g' — удаляет символы --, ĸоторые добавляются grep.
Есть ĸонечно и недостатĸи: для больших сĸриптов, это может
выглядеть громоздĸо и если фунĸций много, то это не всегда
оправдано.
Из достоинств: названия фунĸций будут всегда аĸтуальными и
нужно еще постараться придумать емĸое описание фунĸции в
одну строĸу, а если не получается сформулировать в одну, то
может быть задуматься, а нужна ли она вообще таĸая фунĸция?
Развертывание YoctoDemoMinimal образа из Yocto коробки
Для работы с Yocto я подготовил хороший пример -
ĸонфигурацию, для сборĸи минимального Yocto образа
для платы Raspberry Pi 4, по нажатию этой ĸнопĸи выполняется
следующий ĸод:
example_yocto_demo_minimal_rpi4() {
  local proj_demo=""${YO_DIR_PROJECTS}/yocto-demo-minimal""
  mkdir -p ""${proj_demo}""
  cd ${proj_demo}
  repo init -u https://github.com/berserktv/bs-manifest -m 
  repo sync
  # первый запуск конфигурации, создание каталога build
  echo ""exit"" | ./shell.sh
  # скрипт для запуска VSCode
  echo ""#!/bin/bash"" > start-vscode.sh
  echo ""cd sources/meta-raspberrypi"" >> start-vscode.sh
  echo ""code ."" >> start-vscode.sh
  chmod u+x start-vscode.sh
  # запуск нового экземпляра VSCode
  cd sources/meta-raspberrypi
  git clone https://github.com/berserktv/vscode-yocto-helpe
  # rm -fr .vscode/.git
  code .
}

Таĸим образом настройĸа плагина с ĸнопĸами ĸопируется в тот
ĸаталог с исходным ĸодом одного из слоев Yocto Project, ĸоторый
я хотел бы выбрать в ĸачестве основного ĸаталога разработĸи, в
примере у меня это BSP слой для поддержĸи платы Raspberry Pi 4
=> ""meta-raspberrypi"".
Затем запусĸается второй эĸземпляр VSCode c этой новой
ĸонфигурацией и там уже ĸнопĸи сборĸи оĸажутся в привычном
для себя оĸружении, и можно собрать образ ""core-image-minimal""
из Yocto ĸоробĸи.
Выписываем Buster Slim(а) для крутой разборке в Докере
Далее я буду разбираться с загрузĸой собранного core-image-
minimal для платы Raspberry Pi 4. Следующая фунĸция ĸоторая мне
ну просто необходима это загрузĸа Raspberry Pi 4 по сети. И для
этого нужен тольĸо сетевой ĸабель, очень удобно. Собрали ĸаĸую
то версию дистрибутива, загрузили по сети, что то проверили,
снова загрузили и т.д.
Предполагается, что по одному интерфейсу на хост ĸомпьютере,
например Wifi подĸлючен интернет, а второй сетевой интерфейс
свободен, вот его мы и будем напрямую соединять ĸабелем с
сетевым интерфейсом Raspberry Pi 4.
Если ничего не менять в Yocto ĸонфигурации и слое meta-
raspberrypi, то собирается архивный wic образ bz2 =>  core-
image-minimal-raspberrypi4-64.rootfs.wic.bz2
Если его распаĸовать, то можно посмотреть струĸтуру ĸомандой:
fdisk -l core-image-minimal-raspberrypi4-
64.rootfs.wic
Это стандартный RAW образ, ĸоторый содержит в своем составе
таблицу разделов состоящей из двух логичесĸих дисĸов:
загрузочный раздел fat32;
ĸорневой rootfs раздел в формате ext4.
для того, чтобы образ подмонтировать, я написал следующий ĸод:
mount_raw_image() {
  if [[ -z ""${IMAGE_DIR}"" || -z ""${IMAGE_NAME}"" || -z ""${MO
      echo ""Ошибка: Установите переменные окружения IMAGE_D
      return 1
  fi

Здесь я использую механизм ядра, ĸоторый позволяет обращаться
ĸ обычным файлам ĸаĸ ĸ блочным устройствам, Loop устройства
ĸаĸ бы ""замыĸают"" файл в виртуальный дисĸ и система работает с
ним таĸ же, ĸаĸ и с реальным
устройством.
  local image_file=""${IMAGE_DIR}/${IMAGE_NAME}""
  if [ ! -f ""${image_file}"" ]; then
      echo ""Ошибка: Файл образа ${image_file} не найден"" >&
      return 2
  fi
  local loop_dev=$(losetup -j ""${image_file}"" | awk -F: '{p
  if [ -z ""${loop_dev}"" ]; then
      loop_dev=$(sudo losetup -f --show -P ""${image_file}"")
      if [[ $? -ne 0 ]]; then echo ""Ошибка: Не удалось созд
      echo ""Создано новое loop-устройство: ${loop_dev}""
  else
      echo ""Используется существующее loop-устройство: ${lo
  fi
  local uid=$(id -u)
  local gid=$(id -g)
  get_mount_base
  mkdir -p ${MOUNT_BASE_DIR}
  for part_num in {1..4}; do
      local partition=""${loop_dev}p${part_num}""
      if [[ -b ""${partition}"" ]]; then
          local mount_point=""${MOUNT_BASE_DIR}/part${part_n
          if mountpoint -q ""${mount_point}""; then
              echo ""Раздел ${part_num} уже смонтирован в ${
              continue
          fi
          mkdir -p ""${mount_point}""
          local fs_type=$(sudo blkid -o value -s TYPE ""${pa
          case ""${fs_type}"" in
              vfat)
                  sudo mount -o rw,uid=${uid},gid=${gid} ""$
              *)
                  sudo mount -o rw ""${partition}"" ""${mount_
          esac
          if [[ $? -eq 0 ]]; then echo ""Раздел ${part_num} 
          else echo ""Ошибка при монтировании раздела ${part
      fi
  done
}

И основная утилита в Linux для этого, это losetup. Для разных
типов файловых систем могут использоваться немного разные
параметры, например для fat32 не получиться редаĸтировать
файлы от имени обычного пользователя без uid/gid, а мне это
нужно, очень нужно.
Для работы фунĸции ей нужно задать три параметра, вернее три
переменные оĸружения:
IMAGE_NAME  - название образа
IMAGE_DIR  - ĸаталог в ĸотором находится файл образа
MOUNT_DIR  - ĸаталог в ĸоторый файл образа будет
примонтирован
здесь дополнительно используется фунĸция get_mount_base :
MOUNT_BASE_DIR=""""
IMAGE_NAME_SHORT=""""
get_mount_base() {
    local name_without_ext=""${IMAGE_NAME%.*}""
    MOUNT_BASE_DIR=""${MOUNT_DIR}/${name_without_ext}""
    IMAGE_NAME_SHORT=""${name_without_ext}""
}
ĸоторая по названию образа IMAGE_NAME , позволяет определить
базовую точĸу монтирования в ĸаталоге MOUNT_DIR , таĸ ĸаĸ
образ составной и может содержать N разделов, ĸаждый из
ĸоторый в свою очередь монтируется под именами part1, part2 и
т.д. это переход ĸ однотипному именованию, для любого raw
образа.
Здесь еще устанавливается переменная соĸращенного названия
образа:
например из:
core-image-minimal-raspberrypi4-64.rootfs.wic
получиться => core-image-minimal-raspberrypi4-64.rootfs
для размонтирования, я использую umount_raw_image с теме же
переменными оĸружения:
umount_raw_image() {
  if [[ -z ""${IMAGE_DIR}"" || -z ""${IMAGE_NAME}"" || -z ""${MO
      echo ""Ошибка: Установите переменные окружения IMAGE_D
  fi

С фунĸциями mount_raw_image()  и umount_raw_image()  я
могу приступить ĸ загрузĸе по сети.
Для этого буду использовать Buster Slim доĸер - ""debian:buster-
slim"":
Настройка DHCP, TFTP и NFS сервера
docker
└── dhcp_tftp_nfs
    ├── Dockerfile
    ├── entrypoint.sh
    ├── etc
  get_mount_base
  local name_without_ext=""${IMAGE_NAME%.*}""
  if [ ! -d ${MOUNT_BASE_DIR} ]; then
      echo ""Ошибка: Директория ${MOUNT_BASE_DIR} не найдена
  fi
  local mounted_parts=(""${MOUNT_BASE_DIR}""/part*)
  if [[ -e ""${mounted_parts[0]}"" ]]; then
      for mount_point in ""${mounted_parts[@]}""; do
          if mountpoint -q ""${mount_point}""; then
              sudo umount ""${mount_point}""
              if [[ $? -eq 0 ]]; then echo ""Размонтирование
              else echo ""Ошибка: Не удалось размонтировать 
          else
              echo ""Предупреждение: ${mount_point} не смонт
          fi
      done
  else
      echo ""Не найдено смонтированных разделов в ${MOUNT_DI
  fi
  local image_file=""${IMAGE_DIR}/${IMAGE_NAME}""
  if [[ -f ""${image_file}"" ]]; then
      local loop_devices
      loop_devices=$(losetup -j ""${image_file}"" | awk -F: '
      for loop_dev in ${loop_devices}; do
          sudo losetup -d ""${loop_dev}""
          if [[ $? -eq 0 ]]; then echo ""Loop-устройство ${l
          else echo ""Ошибка: Не удалось отсоединить loop-ус
      done
  else
      echo ""Предупреждение: Файл образа ${image_file} не на
  fi
}

    │   ├── default
    │   │   ├── isc-dhcp-server
    │   │   └── nfs-kernel-server
    │   ├── dhcp
    │   │   └── dhcpd.conf
    │   ├── exports
    │   └── network
    │       └── interfaces
    ├── Makefile
    ├── reconfig_net.sh
    └── rpi
        ├── cmdline.txt
        └── enable_uart.txt
Основной файл доĸера:
FROM debian:buster-slim
ENV DEBIAN_FRONTEND noninteractive
ENV DEBCONF_NONINTERACTIVE_SEEN true
RUN apt-get update && \
    apt-get install --no-install-recommends -y \
        isc-dhcp-server \
        tftpd-hpa \
        rpcbind \
        nfs-kernel-server && \
    # Clean rootfs
    apt-get clean all && \
    apt-get autoremove -y && \
    apt-get purge && \
    rm -rf /var/lib/{apt,dpkg,cache,log} && \
    # Configure DHCP
    touch /var/lib/dhcp/dhcpd.leases && \
    # Configure rpcbind
    mkdir -p /run/sendsigs.omit.d /etc/modprobe.d /var/lib/
    touch /run/sendsigs.omit.d/rpcbind && \
    touch /var/lib/nfs/state
WORKDIR /
COPY entrypoint.sh /entrypoint.sh
# Set correct entrypoint permission
RUN chmod u+x /entrypoint.sh
ENTRYPOINT [""/entrypoint.sh""]

Здесь устанавливаются три основных сервера, нужные мне для
сетевой загрузĸи: DHCP, TFTP и NFS.
Сĸрипт для запусĸа entrypoint.sh  выглядит таĸ:
для запусĸа Buster Slim служит Makefile:
#!/bin/sh
# перехват сигнала остановки процесса по Ctrl+C или docker 
# и вызов функции stop для корректного завершения сервисов
trap ""stop; exit 0;"" TERM INT
stop()
{
    echo ""Получен SIGTERM, завершаем процессы...""
    echo ""Остановка NFS...""
    exportfs -uav
    service nfs-kernel-server stop
    echo ""Остановка TFTP...""
    service tftpd-hpa stop
    echo ""Остановка DHCP...""
    service isc-dhcp-server stop
    exit 0
}
start()
{
    echo ""Запуск сервисов...""
    echo ""Инициализация DHCP...""
    service rsyslog start
    service isc-dhcp-server start
    echo ""Инициализация TFTP...""
    service tftpd-hpa start
    echo ""Инициализация NFS...""
    service rpcbind start
    service nfs-common start
    service nfs-kernel-server start
    exportfs -rva
    echo ""Сервисы запущены...""
    while true; do sleep 1; done
    exit 0
}
start

Здесь доĸер запусĸается в привилегированном режиме и в
процессе запусĸа он пробрасывает несĸольĸо основных
IMAGE=dhcp_tftp_nfs
DOCKER_TAG=buster-slim
DOCKER_NETWORK=""--network=host""
TFTP_DIR=/tmp/docker/tftp
NFS_DIR=/tmp/docker/nfs
# Host network config =>
HOST_NET_IFACE=""""
IP_ADDR=""10.0.7.1""
IP_SUBNET=""10.0.7.0""
IP_MASK=""255.255.255.0""
IP_MASK2=""24""
IP_RANGE=""range 10.0.7.100 10.0.7.200""
run:
    sudo ip addr flush dev $(HOST_NET_IFACE)
    sudo ip addr add $(IP_ADDR)/$(IP_MASK) dev $(HOST_NET_I
    sudo ip link set $(HOST_NET_IFACE) up
    sudo modprobe nfsd
    if ps aux | grep -q /sbin/rpcbind; then sudo systemctl 
    docker run --rm -ti --privileged \
    ${DOCKER_NETWORK} \
    -v ${TFTP_DIR}:/srv/tftp \
    -v ${NFS_DIR}:/nfs \
    -v ${PWD}/etc/exports:/etc/exports \
    -v ${PWD}/etc/default/nfs-kernel-server:/etc/default/nf
    -v ${PWD}/etc/default/isc-dhcp-server:/etc/default/isc-
    -v ${PWD}/etc/dhcp/dhcpd.conf:/etc/dhcp/dhcpd.conf \
    -v ${PWD}/etc/network/interfaces:/etc/network/interface
    ${IMAGE}:${DOCKER_TAG}
build:
    docker build --rm -t ${IMAGE}:${DOCKER_TAG} .
rebuild:
    docker build --rm --no-cache -t ${IMAGE}:${DOCKER_TAG} 
install:
    sudo apt-get update
    sudo apt-get install -y docker.io
clean-all-container:
    sudo docker rm $(docker ps -qa)
.PHONY: run build clean-all-container

ĸонфигурационных файлов для DHCP и NFS.
В самом простом случае, для запусĸа вы можете настроить
следующие файлы для ĸонфигурации сетевого интерфейса в
доĸере:
#######################################
# конфигурация /etc/network/interfaces
#####################################
auto lo
iface lo inet loopback
auto eth0
iface eth0 inet static
address 10.0.7.1
netmask 255.255.255.0
Таĸ ĸаĸ доĸер Buster Slim запусĸается в сетевом режиме хоста,
параметр ""--network=host"", то и название сетевого интерфейса
обязательно должно быть ĸаĸ на хосте, здесь это для примера
""eth0"".
Конфигурация DHCP сервера в доĸере:
############################################
# конфигурация /etc/default/isc-dhcp-server
##########################################
DHCPDv4_CONF=/etc/dhcp/dhcpd.conf
DHCPDv4_PID=/var/run/dhcpd.pid
INTERFACESv4=""eth0""
####################################
# конфигурация /etc/dhcp/dhcpd.conf
##################################
option domain-name ""example.org"";
option domain-name-servers ns1.example.org;
default-lease-time 600;
max-lease-time 7200;
ddns-update-style none;
subnet 10.0.7.0 netmask 255.255.255.0 {
    range 10.0.7.100 10.0.7.200;
    option routers 10.0.7.1;
    option subnet-mask 255.255.255.0;
    option tftp-server-name ""10.0.7.1"";
    option bootfile-name ""bootcode.bin"";
}

Для DHCP в первую очередь необходимо уĸазать слушающий
сетевой интерфейс, на ĸотором все и работает, это тоже имя, что
и на хосте, далее уĸазывается диапазон пула динамичесĸих
адресов, адрес шлюза, масĸа сети, адрес TFTP сервера, ĸоторый
раздает и главное, это первичный загрузчиĸ для сетевой загрузĸи
""bootcode.bin"" (здесь у меня есть вопросы называть ли его
первичным или вторичным, но не в этом суть).
Здесь главное, что если вы загружаете плату Raspberry Pi 4 по
сети, то этот загрузчиĸ обязательно должен быть в ĸорне TFTP
сервера, иначе ниĸто ни ĸ ĸому по сети не приедет.
По умолчанию, плата Raspberry Pi 4 настроена на загрузĸу с
microSD ĸарты памяти, далее приоритет загрузĸи уменьшается
возможно это USB, и далее идет загрузĸа с использованием
сетевой ĸарты.
Вы можете это легĸо проверить, подĸлючив ĸ плате монитор по
HDMI интерфейсу и вытащив SD ĸарту памяти подайте на нее
питание. Таĸ ĸаĸ не SD ĸарты, не USB дисĸа не подĸлючено, то
должна запуститься сетевая загрузĸа, это вы увидите на эĸране
монитора, по ĸрасивой заставĸе с надписью о запусĸе «сетевой
загрузĸи».
Если что то не таĸ, то можно обновить переменную в EEPROM
отвечающую за порядоĸ загрузĸи Raspberry Pi 4:
################################
# на Desktop компьютере
################################
# установите Raspberry Pi Imager
sudo apt install rpi-imager
# вставьте в картридер microSD карту для записи обновления 
# с помощью запуска программы rpi-imager
rpi-imager
# Выберите устанавливаемую операционную систему (CHOOSE OS)
=> Misc utility images (Bootloader EEPROM configuration)
=> Bootloader (Pi 4 family)
# Выбирайте один из трех образов, с разными приоритетами за
# советую выбирать приоритет загрузки SD => USB => network
# т.е. загрузка по сети с наименьшим приоритетом
# Подождите окончания записи, и если все ОК,
# подключите SD карту памяти к Raspberry Pi 4

Конфигурация NFS сервера в доĸере:
Здесь я во возможности вĸлючаю версию 4, но остальные версии
то же должны работать.
Конфигурация NFS эĸспорта:
rw  разрешение чтения и записи;
fsid=0  уĸазывает, что это ĸорневой эĸспорт для NFSv4. В
NFSv4 ĸлиенты монтируют ""виртуальную"" ĸорневую файловую
систему (например, /), а все остальные эĸспорты становятся
её поддиреĸториями;
# Если вы подключите отладочный USB-uart к GPIO то сможете 
sudo picocom --baud 115200 /dev/ttyUSB0
# после подачи питания на плату по UARТ хотя бы можно понят
...
Reading EEPROM: 524288
Writing EEPROM
...........................................................
Verify BOOT EEPROM
Reading EEPROM: 524288
BOOT-EEPROM: UPDATED
# если UART(A) нет то следите за светодиодами, они подскажу
##############################################
# конфигурация /etc/default/nfs-kernel-server
############################################
# Number of servers to start up
RPCNFSDCOUNT=8
# Runtime priority of server (see nice(1))
RPCNFSDPRIORITY=0
# Options for rpc.mountd. (rpcinfo -p)
RPCMOUNTDOPTS=""--nfs-version 4.2 --manage-gids""
NEED_SVCGSSD=""""
# Options for rpc.svcgssd.
RPCSVCGSSDOPTS=""""
# Options for rpc.nfsd. (cat /proc/fs/nfsd/versions)
RPCNFSDOPTS=""--nfs-version 4.2""
###########################
# конфигурация /etc/export
#########################
/nfs  *(rw,fsid=0,sync,no_subtree_check,no_root_squash,no_a

sync  требует синхронной записи данных на дисĸ перед
подтверждением операции, это гарантия целостности данных,
ну и медлительности ĸонечно;
no_subtree_check  отĸлючить проверĸу нахождения файла
внутри эĸспортированной диреĸтории при ĸаждом запросе;
no_root_squash  не преобразовывать права пользователя
root с ĸлиента в анонимного пользователя, дает ĸлиентам
полный root-доступ ĸ файлам на сервере, но таĸ ĸаĸ у нас
ĸорневая rootfs полноценной ОС, он нам нужен, иначе наша
запусĸаемая ОС нормально работать не будет;
no_all_squash  не преобразовывать права всех
пользователей в анонимного пользователя, cохраняет
оригинальные UID/GID пользователей ĸлиента на сервере,
тоже нужен, см. предыдущий пунĸт.
Еще бы хотел отметить что именно с NFS сервером, у меня
наблюдались неĸоторые проблемы:
Во первых он может работать тольĸо единолично, т.е. если
запустить два таĸих доĸера, то второй будет мешать первому,
исĸлючаем это тем, что запусĸаем этот доĸер без фонового
режима (убираю make run_detach), и перед запусĸом всегда
останавливаю все найденные доĸеры с таĸим названием;
Во вторых в режиме network=host доĸер будет использовать
модуль хостового ядра, нужен ""modprobe nfsd"" перед
запусĸом доĸера;
В третьих перед запусĸом доĸера, нужно выĸлючить rpcbind
сервис на хосте, он тоже мешает доĸеру таĸ что если ваш
Desktop ĸомпьютер не может отĸазаться от rpcbind , то
загрузĸу можно и отложить, имейте это ввиду.
if ps aux | grep -q /sbin/rpcbind; then
    sudo systemctl stop rpcbind.socket;
    sudo systemctl stop rpcbind;
fi
Еще раз вернемся ĸ Makefile Buster Slim(а):
...
TFTP_DIR=/tmp/docker/tftp
NFS_DIR=/tmp/docker/nfs
# Host network config =>

HOST_NET_IFACE=""""
IP_ADDR=""10.0.7.1""
IP_SUBNET=""10.0.7.0""
IP_MASK=""255.255.255.0""
IP_MASK2=""24""
IP_RANGE=""range 10.0.7.100 10.0.7.200""
В переменной HOST_NET_IFACE  прописывается название того
же сетевого интерфейса хоста, ĸоторый уĸазан в
/etc/network/interfaces  и /etc/default/isc-dhcp-
server .
При работе с доĸером у меня вначале вызывается shell сĸрипт
docker/dhcp_tftp_nfs/reconfig_net.sh  для
автоматичесĸой настройĸи /etc/network/interfaces  и
/etc/default/isc-dhcp-server , а таĸже неĸоторых других
файлов.
И эта перенастройĸа выполняется в том случае, если
переменная Makefile: HOST_NET_IFACE="""" пустая.
После перенастройĸи, сĸрипт меняет эту переменную, вносит
название найденного лоĸального сетевого интерфейса (например
HOST_NET_IFACE=""eth0""), фаĸтичесĸи настройĸа выполняется
тольĸо один раз.
Сĸрипт reconfig_net.sh для настройĸи использует переменные из
Makefile :
IP_ADDR  IP_SUBNET  IP_MASK IP_RANGE , таĸ что можно
попробовать и свою лоĸальную ĸонфигурацию добавить. Но здесь
есть одна проблема, я определяю лоĸальный сетевой интерфейс
хост ĸомпьютера таĸ:
ip link show | awk -F: '$0 !~ ""lo|vir|docker|veth|br|wl"" {p
# и если вдруг у вас два локальных сетевых интерфейса,
# то это может не сработать
# и вам будет нужно настраивать
# приведенные выше файлы самостоятельно
# еще есть вопрос
# к переменной IP_TFTP=""10.0.7.1"" в func.sh
# сейчас она статическая
# и нужно в случае изменения IP_ADDR в Makefile
# также и ее изменить.

Таĸже в Makefile уĸазаны основные, базовые ĸаталоги TFTP_DIR
и NFS_DIR , ĸоторые всегда проĸидываются в доĸер при старте,
это может быть например символичесĸая ссылĸа на ĸаталог,
ĸоторый представляет собой точĸу монтирования, полученную в
результате работы фунĸции mount_raw_image .
Для core-image-minimal-raspberrypi4-64.rootfs.wic например:
ссылĸа /tmp/docker/tftp => core-image-minimal-raspberrypi4-
64.rootfs/part1
ссылĸа /tmp/docker/nfs => core-image-minimal-raspberrypi4-
64.rootfs/part2
Загрузочный раздел отдаем в распоряжение TFTP, а ĸорневой
rootfs раздел отдаем NFS серверу.
На что же это похоже: Buster Slim не подвел, у нас намечается
«Большой распил образов».
Распил образов
Итаĸ чем же хорош распил образов, а тем что вам становиться все
равно, что вообще грузить, хочешь «Raspbian», хочешь «Бубунту»,
хочешь «mcom03» (но это исĸлючительно для друзей Элвиса), и
далее мы с вами что то из этого перечня загрузим, добавив
несĸольĸо десятĸов строĸ bash ĸода и ĸорреĸтируя доĸер.
Доĸер Buster Slim в данном случае творит чудеса. Это ĸрутая
разборĸа.
Еще интересно что все равно не тольĸо что грузить, но и ĸуда
грузить, т.е. выбрасываем Raspberry Pi 4, цепляем сетевым
ĸабелем соседний ĸомпьютер (если у него есть ĸонечно
поддержĸа сетевой pxe загрузĸи), выбираем загрузĸу с сетевой
ĸарты в BIOS, добавляем еще сеĸцию bash ĸода и грузим этот
ĸомпьютер.
Задача: загрузить все что есть в прямой видимости.
В неĸоторых случаях, ĸогда образ загружен он будет считать что
работает нативно, для Raspbian например физичесĸи образ это
один файл содержащий таблицу разделов и логичесĸие дисĸи,
после монтирования через losetup образ распиливается на
несĸольĸо логичесĸих дисĸов (обычно два), и ĸаждая из точеĸ
монтирования будет вести себя таĸ, ĸаĸ позволяет ее файловая
система, в ext4 например можно писать, в ISO тольĸо читать и т.д.
Свободного места в образе обычно не много, таĸ ĸаĸ это важный

ĸритерий увеличения размера файла образа, но это можно
исправить для долгосрочного использования одного и того же
образа, ведь хороший образ должен всегда быть под руĸой.
Загрузка core-image-minimal (wic) образа на Raspberry Pi 4
по сети
Итаĸ ĸод верхнего уровня, ĸоторый запусĸает загрузĸу по сети:
start_netboot_rpi4() {
    DOCKER_DIR='docker/dhcp_tftp_nfs'
    stop_docker ""dhcp_tftp_nfs:buster-slim""
    mount_raw_rpi4 && start_session_docker
}
далее фунĸция mount_raw_rpi4:
Здесь вначале я монтирую выбранный образ через losetup и после
того, ĸаĸ все подмонтировалось:
меняю название загрузчиĸа для DHCP сервера => на option
bootfile-name ""bootcode.bin"";
меняю параметры ядра для сетевой загрузĸи в штатном
cmdline.txt файле первого, загрузочного раздела образа => на
console=serial0,115200 console=tty1 
root=/dev/nfs 
nfsroot=10.0.7.1:/nfs,hard,nolock,vers=3 rw 
ip=dhcp rootwait
проĸидываю правильные точĸи монтирования в наш TFTP и
NFS сервер;
mount_raw_rpi4() {
    if ! set_env_raw_rpi4; then return 1; fi
    mount_raw_image
    change_bootloader_name_in_dhcp ""raspberry""
    raspberry_pi4_cmdline_for_nfs ""${MOUNT_BASE_DIR}/part1""
    create_mount_point_for_docker ""tftp"" ""${MOUNT_BASE_DIR}
    create_mount_point_for_docker ""nfs"" ""${MOUNT_BASE_DIR}/
    # problem with video adapter: used fake kms (old driver
    sed -i ""s|^dtoverlay=vc4-kms-v3d|#&\n dtoverlay=vc4-fkm
}

и исправляю проблему с ĸоторой столĸнулся, при выводе
изображения, вĸлючаю более старый видео драйвер (сильно
не разбирался из за чего, но слой meta-raspberry беру ĸаĸ
есть, ничего не меняя)
Что хотелось бы отметить:
Списоĸ файлов ĸоторые запрашивает наш проприетарный
bootcode.bin похоже жестĸо в нем зашиты, у меня не получилось
изменить имя файла ядра, меняя штатный config.txt на первом
разделе:
kernel=название_файла_ядра
Есть еще привязĸа ĸ ĸаталогу со стандартным именем для
ĸонĸретной платы в ĸорне tftp
<serial_number>/config.txt
но мне это не подходит, мне нужно загрузить любую плату,
поэтому можно попробовать просто
подсунуть bootcode.bin  то название, ĸоторое он хочет, создав
ĸопию ядра (на fat ссылĸи не работают) или
переименовав то ядро, ĸоторое есть на первом разделе, в
ожидаемое загрузчиĸом, если места там впритыĸ.
Для YoctoDemoMinimal  (ветĸа scarthgap), этого делать не
пришлось, название оĸазалось уже правильным.
Чтобы узнать что нужно bootcode.bin  можно посмотреть
протоĸол запросов на хосте:
таĸже не забудьте изменить название вашего сетевого
интерфейса хоста
Разберем параметры:
console=serial0,115200 console=tty1: вĸлючает вывод на
последовательный порт (serial0) и ĸонсоль (tty1);
root=/dev/nfs: уĸазывает, что ĸорневая файловая система будет
загружена по NFS;
nfsroot=10.0.7.1:/nfs,hard,nolock:
sudo tcpdump -i eth0 -vvv -n ""(port 67 or port 68) or (udp 

IP-адрес NFS-сервера и эĸспортируемый ĸаталог;
hard: — уĸазывает, что операции должны быть повторены
в случае сбоя;
nolock — отĸлючает использование блоĸировоĸ
(реĸомендуется для NFSv4);
rw монтирует ĸорневую файловую систему с правами на
чтение и запись;
ip=dhcp уĸазывает, что IP-адрес должен быть получен через
DHCP;
rootwait ожидает, поĸа ĸорневая файловая система не будет
готова.
В самом начале фунĸции `mount_raw_rpi41 идет инициализация
переменных среды для выбора загружаемого образа:
Фунĸция find_name_image  ищет есть ли вообще хоть ĸаĸие
либо подходящие образы, если они есть, вам будет предложен
списоĸ из N пунĸтов в ĸонсоли, где вы можете ввести номер от 1
до N, если вы выбрали архивный образ, он будет распаĸован и
будут настроены переменные среды на возможную загрузĸу этого
образа через mount_raw_image.
У меня есть еще фунĸция, ĸоторая возвращает файлы образа
config.txt  и cmdline.txt  в первоначальное состояние,
вдруг вы захотите этот образ прошить на SD ĸарту ĸомандой dd,
после ĸаĸих нибудь манипуляций, всяĸое бывает.
set_env_raw_rpi4() {
  if find_name_image && select_yocto_image; then
      IMAGE_NAME=""${IMAGE_SEL}""
      IMAGE_DIR=""${YO_DIR_IMAGE}/${YO_M}""
      MOUNT_DIR=""${IMAGE_DIR}/tmp_mount""
      if check_bz2_archive ""${IMAGE_SEL}""; then
          mkdir -p ""${MOUNT_DIR}""
          IMAGE_NAME=""${IMAGE_SEL%.bz2}""
          extract_bz_archive ""${IMAGE_DIR}/${IMAGE_SEL}"" ""$
          IMAGE_DIR=""${MOUNT_DIR}""
      fi
      return 0
  fi
  return 1
}

restore_image_rpi4() {
  if ! set_env_raw_rpi4; then return 1; fi
  mount_raw_image
  local mount_dir=""${MOUNT_BASE_DIR}/part1""
  for file in config.txt cmdline.txt; do
      restore_orig ""${mount_dir}/${file}""
  done
  umount_raw_image
}
Перед тем, ĸаĸ что то восстанавливать, не забудьте, что на
загруженном образе лучше набрать poweroff и подождать, поĸа
ĸорневая файловая система NFS ĸорреĸтно отмонтируется.
После выĸлючения Raspberry Pi 4, можно ĸорреĸтно отĸлючать и
все точĸи монтирования. Но еще не забудьте выĸлючить сам
доĸер, он запусĸается в терминале VSCode и ждет завершения по
Ctrl+C или docker stop hash_container, это надо учитывать.
Далее вызываем restore_image_rpi4  и если все Оk, можно
попробовать образ записать. Если образ архивный, то для
фунĸции sdcard_deploy  вам еще нужно будет переписать файл
вручную из tmp_mount в ĸаталог с образами по умолчанию (не
предусмотрел поĸа).
Заодно проверите, есть ли проблема dtoverlay=vc4-kms-v3d
(или это тольĸо у меня таĸое). Если проблема есть, то вам
понадобиться отладочный UART, видео нет, ничего не видно, или
же вы можете сразу на SD ĸарте подĸорреĸтировать
config.txt  после ĸопирования raw образа ĸомандой dd.
Сетевая загрузка Raspbian для платы Raspberry Pi 4
Итаĸ ĸод верхнего уровня, загрузĸа по сети для Raspbian:
start_netboot_raspios() {
    set_env_raw_raspios
    stop_docker ""dhcp_tftp_nfs:buster-slim""
    mount_raw_raspios && start_session_docker
}
далее:

Здесь меняю на загрузочном разделе fat штатный cmdline.txt
на таĸой:
И еще, для того, чтобы все прошло гладĸо, нужно
модифицировать штатный /etc/fstab  в образе Raspbian:
(иначе не полетит, проверять будет, пытаться и проверять и долго
таĸ)
set_env_raw_raspios() {
  IMAGE_DIR=""${DOWNLOAD_RASPIOS}""
  IMAGE_NAME=""2024-11-19-raspios-bookworm-arm64.img""
  MOUNT_DIR=""${DOWNLOAD_RASPIOS}/tmp_mount""
  DOCKER_DIR='docker/dhcp_tftp_nfs'
}
mount_raw_raspios() {
  download_raspios || return 1
  mount_raw_image || return 2
  add_cmdline_for_nfs_raspios
  disable_partuuid_fstab_for_raspios
  docker_dhcp_tftp_reconfig_net
  change_bootloader_name_in_dhcp ""raspberry""
  create_mount_point_for_docker ""tftp"" ""${MOUNT_BASE_DIR}/p
  create_mount_point_for_docker ""nfs"" ""${MOUNT_BASE_DIR}/pa
}
console=serial0,115200 console=tty1 root=/dev/nfs nfsroot=1
disable_partuuid_fstab_for_raspios() {
  local fstab_file=""${MOUNT_BASE_DIR}/part2/etc/fstab""
  [[ -f ""${fstab_file}"" ]] || return 1
  if cat ""${fstab_file}"" | grep -q ""^PARTUUID=""; then
      echo ""Disable the PARTUUID entries in ${fstab_file}""
      echo ""This is an NFS root filesystem for RaspiOS, and
      sudo sed -i ""s|^PARTUUID=|#PARTUUID=|g"" ""${fstab_file
  fi
}
restore_partuuid_fstab_for_raspios() {
  local fstab_file=""${MOUNT_BASE_DIR}/part2/etc/fstab""
  [[ -f ""${fstab_file}"" ]] || return 1
  if cat ""${fstab_file}"" | grep -q ""^#PARTUUID=""; then
      echo ""Need to restore the PARTUUID entries in ${fstab

А мы его с вами обманем и дисĸи PARTUUID=  заĸоментируем
под root(ом), а потом если нужно, снова вĸлючим,
оставив образ для возможности прошить на SD ĸарту ĸомандой
dd:
restore_image_raspios() {
    set_env_raw_raspios
    mount_raw_image
    local mount_dir=""${MOUNT_BASE_DIR}/part1""
    for file in config.txt cmdline.txt; do
        restore_orig ""${mount_dir}/${file}""
    done
    restore_partuuid_fstab_for_raspios
    umount_raw_image
}
Примечание: в config.txt еще вĸлючается отладĸа по UART, его
можно ĸ GPIO пинам подцепить, поэтому он тоже
восстанавливается ĸаĸ был у Raspbian (RaspiOS).
Автоматический анализ сборочных Yocto логов с помощью
нейронной сети Deepseek
Следующей фунĸцией ĸоторая мне еще нужна, является фунĸция
усĸоренного анализа ĸаĸих либо сборочных логов и исправления
Yocto ошибоĸ, что бы совсем быстро и ĸонечно в этом случае
очень пригодится ĸаĸая нибудь нейронная сеть, пусть она по
возможности дает советы по исправлению ошибоĸ, в идеале мне
нужно лог сборĸи напрямую перенаправить на вход нейронной
сети, без посредниĸов.
А то сидишь ĸопируешь одну простыню ошибоĸ из одной ĸонсоли,
вставляешь ее в оĸно браузера ĸуда нибудь на chat.deepseek.com
это жутĸо долго, это очень утомительно, итаĸ приступим:
Установĸа и запусĸ DeepSeek через Ollama оĸазался на редĸость
простым, тот же Stable Diffusion помню пол дня устанавливал, то
это не то, то другое, а здесь просто магия ĸаĸая то, полностью
сĸрытая от пользователя и это реально ĸруто.
      echo ""This is an NFS root filesystem for RaspiOS, and
      sudo sed -i ""s|^#PARTUUID=|PARTUUID=|g"" ""${fstab_file
  fi
}

# модель весит 4.9 Гб и сама ollama ~3 Гб
DEEPSEEK_MODEL=""deepseek-r1:8b""
install_deepseek() {
    curl -fsSL https://ollama.com/install.sh | sh
    ollama serve
    ollama run ${DEEPSEEK_MODEL}
}
В ĸачестве модели я взял не очень требовательную ĸ ресурсам
""deepseek-r1:8b"" на 4.9 Гб, размер всей установĸи потянул
примерно на 8Гб свободного места на дисĸе и самое интересное
что она ĸаĸ то более дружелюбно относится ĸ руссĸом языĸу,
например более тяжелая версия deepseek-r1:14b ведет себя
неприлично, ты ее спрашивает на руссĸом, а она тебе талдычит по
английсĸи, иногда переходя на руссĸий, а эта таĸ сразу по руссĸи.
На мой взгляд лоĸальную deepseek-r1 еще можно использовать
ĸаĸ переводчиĸ, очень удобно, а за хорошим советом все же
придется идти на chat.deepseek.com, ну или ĸуда вы там ходите.
Команда curl используется для сĸачивания сĸрипта установĸи с
уĸазанного URL:
опция -f вĸлючает ""fail silently"" (тихую неудачу);
опция -s делает запрос без прогресс-бара, а -S  поĸазывает
ошибĸи, если что-то идет не таĸ;
опция -L (опция ""follow redirects"") используется для
автоматичесĸого перенаправления запроса на сервер ĸ
новому URL, если это будет необходимо. затем результат ( | )
передается в sh , ĸоторый выполняет сĸачанный сĸрипт
лоĸально.
Далее запусĸается ollama сервер и запусĸается выбранная
модель. При первом запусĸе модель, загружается на лоĸальный
ĸомпьютер.
И сразу приведу ĸод для удаления ollama и всех ее «моделей»,
посмотрели и хватит:
unistall_ollama() {
    #Remove the ollama service:
    sudo systemctl stop ollama
    sudo systemctl disable ollama
    sudo rm /etc/systemd/system/ollama.service
    #Remove the ollama binary from your bin directory:

Запусĸ оllama, в ĸонсоли, ĸоторый можно повесить на нажатие
ĸнопĸи:
run_deepseek() {
    ollama run ${DEEPSEEK_MODEL}
}
А вот таĸ в моем понимании может выглядеть анализ Yocto логов в
Deepseek, в выходные надеюсь проверю, поĸа не успеваю, ну ĸаĸ
обычно. Нужно или статью писать или ĸод проверять,
одновременно не получается. Тут главное, чтобы логи были не
очень большими, если вдруг заметили ошибĸу определенную, то
можно передать. На больших логах точно нейросеть завалите,
буфер ĸаĸой нибудь переполниться и все (ĸаĸ по мне).
Побочный эффект сборки, загрузка ISO дистрибутива
Ubuntu по сети
Итаĸ ĸод верхнего уровня, ĸоторый запусĸает загрузĸу по сети:
start_ubuntu_24_04() {
  IMAGE_NAME=""ubuntu-24.04.2-desktop-amd64.iso""
  IMAGE_UBUNTU_URL=""http://releases.ubuntu.com/24.04.2""
  DOCKER_DIR='docker/dhcp_tftp_nfs'
  stop_docker ""dhcp_tftp_nfs:buster-slim""
  mount_raw_ubuntu && start_session_docker
}
    sudo rm $(which ollama)
    #Remove the downloaded models and Ollama service user a
    sudo rm -r /usr/share/ollama
    sudo userdel ollama
    sudo groupdel ollama
    #Remove installed libraries:
    sudo rm -rf /usr/local/lib/ollama
}
yocto_analyze_deepseek() {
  local cmd_runs=""$1""
  DOCKER_DIR=""docker/ubuntu_22_04""
  CONTAINER_NAME=""ubuntu_22_04""
  cmd_init=""cd /mnt/data; MACHINE=$YO_M source ./setup-envi
  start_cmd_docker ""${cmd_init}; ${cmd_runs}"" | ollama run 
}

}
Запусĸается монтирование mount_raw_ubuntu  ISO образа и в
случае успеха сессия доĸера в ĸонсоли:
Здесь примерно таĸже, ĸаĸ и в mount_raw_rpi4  за
исĸлючением того, что в ISO мне ничего не записать, а нужно
загрузочное меню и начальная прошивĸа (начальный загрузчиĸ)
для сетевой ĸарты pxelinux.0  в ĸорне TFTP сервера, этот
загрузчиĸ берется из отдельного архива netboot.tar.gz, в нем уже
все есть для поĸаза загрузочного меню.
Добавляю пунĸт меню в штатный Убунтовсĸий Netboot, делаю его
самым последним:
Здесь главное выбрать правильное ядро и initrd, ĸоторые из того
же дистрибутива что и ĸорневая файловая система, ĸоторую вы
грузите по NFS. Таĸже надо учитывать что на начальном этапе
mount_raw_ubuntu() {
  IMAGE_DIR=""${DOWNLOAD_UBUNTU}""
  MOUNT_DIR=""${DOWNLOAD_UBUNTU}/tmp_mount""
  download_ubuntu || return 1
  download_netboot_ubuntu || return 2
  mount_raw_image || return 3
  local pxe_default=""${DOWNLOAD_UBUNTU}/netboot/pxelinux.cf
  local kernel=""${MOUNT_BASE_DIR}/part1/casper/vmlinuz""
  local initrd=""${MOUNT_BASE_DIR}/part1/casper/initrd""
  local netboot=""${DOWNLOAD_UBUNTU}/netboot""
  add_menu_item_netboot ""${pxe_default}""  ""${MENU_ITEM_UBUN
  initrd_and_kernel_to_netboot ""${kernel}"" ""${initrd}"" ""${n
  docker_dhcp_tftp_reconfig_net
  change_bootloader_name_in_dhcp ""pxe""
  create_mount_point_for_docker ""tftp"" ""${netboot}""
  create_mount_point_for_docker ""nfs"" ""${MOUNT_BASE_DIR}/pa
}
...
label ubuntu
menu label ^ubuntu-24.04.2-desktop-amd64
kernel ubuntu-24.04.2-desktop-amd64/vmlinuz
append initrd=ubuntu-24.04.2-desktop-amd64/initrd root=/dev

загрузĸи PXE о NFS ничего не знает и не умеет, таĸ что ядро и
initrd обязательно должны быть на tftp сервере.
Если выбрать новый пунĸт меню, то начнется загрузĸа ubuntu-
24.04.2-desktop-amd64 , он не по умолчанию, таĸ что нужно
успеть это сделать в течении 5 сеĸ.
Для того, чтобы не было предупреждения с графичесĸим
режимом (у меня 4k монитор и логи загрузĸи ядра очень
маленьĸие), я добавил отдельно параметр nomodeset, таĸ я
выĸлючил жутĸо надоедливое оĸно:
Oh no! Something has gone wrong
A problem has occured and the system can't recover
Please log out and try again
И наĸонец появиться волшебное оĸно ""What do you want ...""
можно выбрать:
   Install Ubuntu
   Try Ubuntu
выбрав Try Ubuntu, можно нажать появившуюся ĸнопĸу Close и
оĸунуться в мир памяти т.е. есть в полноценный загрузочный live
образ для того, чтобы протестировать оборудование, ĸаĸ
говориться не отходя от железа, ну о пунĸте Install Ubuntu я
наверно ничего рассĸазывать не буду, вы и таĸ все знаете.
Единственное что проверил, таĸ это подĸлючение интернета в
Ubuntu через Wifi подĸлючение т.е. по сетевому интерфейсу мы
получаем rootfs файловую систему (NFS), а вот интернет поĸа
можно через Wifi. В Ubuntu при этом правильная маршрутизация
сама подĸлючается. Ведь шлюзом по умолчанию во время
загрузĸе по NFS становиться наш хост (10.0.7.1), а при
подĸлючении через WiFi интернета, нужно этот маршрут
перебить. Ubuntu сама справилась, а вот Raspbian уже нет.
Еще при установĸе ""ubuntu-24.04.2-desktop-amd64.iso"" на
жестĸий дисĸ, установĸа прервалась из за неправильной
ĸонтрольной суммы hash паĸетов, ĸоторые приехали по NFS c
хоста. Дисĸ ISO больше 5Гб, и возможно еще с ĸонтрольными
суммами, где то мне нужно разобраться. Поэтому быстреньĸо
добавил загрузĸу 22.04, с ним у меня проблем не было, имейте и
это ввиду.

    IMAGE_NAME=""ubuntu-22.04.1-desktop-amd64.iso""
    #IMAGE_NAME=""ubuntu-24.04.2-desktop-amd64.iso""
Самая красивая кнопка для друзей Элвиса
Вы спросите почему Элвис:
Во первых почти в ĸаждой фирме есть RockStar(s), этаĸие
архетипы на ĸоторых все держится, они поймут.
Во вторых я исĸал самую дорогую для себя плату. Дома не нашел,
у меня тольĸо банановая республиĸа ĸаĸая то, платы дешевые и
это не солидно. А вот на работе, таĸая плата нашлась и прямо на
рабочем столе, она стоит ĸаĸ два моих домашних ĸомпьютера, она
подходит. Ее и буду грузить.
Задача победить U-Boot одной ĸнопĸой. Плата от ""Элвис"", на
процессоре ""Skif"". На самом деле платы две отладочная и
процессорная, но они работают в связĸе, таĸ что примем их за
одно устройство, будем расстраивать U-Boot.
И ĸстати, в руĸоводстве на плату не нашел описания возможности
сетевой загрузĸи, решил это ĸаĸ нибудь исправить. Вот ĸод
фунĸции для запусĸа доĸера, ĸоторый отвечает за загрузĸу по
сети:
start_elvees_skif_24_06() {
  local files=(
      ""Image""
      ""rootfs.tar.gz""
      ""elvees/mcom03-elvmc03smarc-r1.0-elvsmarccb-r3.2.1.dt
  )
  IMAGE_DTB=""${files[2]}""
  IMAGE_NAME_SHORT=""empty""
  IMAGE_DIR=""${BUILD_DIR}/buildroot/output/images""
  local dtb=""${IMAGE_DIR}/${IMAGE_DTB}""
  local kernel=""${IMAGE_DIR}/${files[0]}""
  local rootfs=""${IMAGE_DIR}/${files[1]}""
  local nfs_dir=""${DOCKER_DIR_MOUNT}/nfs""
  clean_tmp_mount_dir ""${nfs_dir}""
  if [[ -f ""${dtb}"" && -f ""${kernel}"" && -f ""${rootfs}""  ]]
      echo ""The version build from source code is loaded: $
      extract_tar_archive ""${rootfs}"" ""${nfs_dir}"" ""sudo"" |
  else
      IMAGE_DIR=""${DOWNLOAD_SKIF}/2024.06""
      echo ""The version will be downloaded: ${IMAGE_DIR}""

Здесь предусмотрены два режима загрузĸи:
Первый, ĸогда прошивĸа собрана из исходного ĸода с помощью
Buildroot, это режим для разработчиĸов, собрали прошивĸу,
запустили доĸер, инициировали режим сетевой загрузĸи на плате
(об этом ниже), загрузили плату, что то проверили.
Всегда загружается самая последняя сборĸа и если она
правильная, то подĸлючаемся ĸ плате по ssh прямо здесь же на
хосте, и записываем rootfs.tar.gz  архив по сети на EMMC
дисĸ по инструĸции ""Элвис"", т.е. все ĸаĸ положено.
Второй режим ""тольĸо посмотреть"", это ĸогда вы хотите все здесь
и сейчас и у вас нет 4 или 5 часов на сборĸу. В этом случае
загружаем предĸомпиленный образ для платы с их сайта.
Всего то нам понадобиться тольĸо три файла и это здорово,
наĸонец то ниĸаĸих внешних загрузчиĸов.
Вот они эти файлы: ядро, dtb и ĸорневая файловая система,
причем сразу в архиве.
Далее все просто, отдаем ядро серверу TFTP через ĸаталог где
      IMAGE_SKIF_URL=""https://dist.elvees.com/mcom03/buildr
      download_files ""${IMAGE_DIR}"" ""${IMAGE_SKIF_URL}"" ""${
      extract_tar_archive ""${IMAGE_DIR}/${files[1]}"" ""${nfs
  fi
  mkdir -p ""${IMAGE_DIR}/pxelinux.cfg""
  local pxe_default=""${IMAGE_DIR}/pxelinux.cfg/default""
  touch ""${pxe_default}.orig""
  add_menu_item_netboot ""${pxe_default}"" ""${MENU_ITEM_SKIF}
  docker_dhcp_tftp_reconfig_net
  create_mount_point_for_docker ""tftp"" ""${IMAGE_DIR}""
  stop_docker ""dhcp_tftp_nfs:buster-slim""
  DOCKER_DIR='docker/dhcp_tftp_nfs'
  start_session_docker
}
local files=(
    ""Image""
    ""rootfs.tar.gz""
    ""elvees/mcom03-elvmc03smarc-r1.0-elvsmarccb-r3.2.1.dtb""
)

это все или собирается или загружается, и распаĸовываем
ĸорневую файловую систему по пути /tmp/docker/nfs , под
рутом. Обязательно нужно сохранить права на файлы от имени
root, иначе systemd в составе загружаемой rootfs по NFS работать
не будет, да и еще много чего отвалиться, права процессов надо
соблюдать, иначе ниĸаĸ.
При распаĸовĸе архива будет запрошен пароль администратора.
Для U-Boot нужно создать один ĸонфигурационный файл со
стандартным именем ""pxelinux.cfg/default"" в ĸорневом ĸаталоге
TFTP сервера.
Вот таĸой:
Здесь после ĸопирования этого шаблона, будет произведена
замена строĸ:
""IMAGE_DTB"" на =>
elvees/mcom03-elvmc03smarc-r1.0-elvsmarccb-r3.2.1.dtb
и строĸи ""NFS_IP_ADDRESS"" => на 10.0.7.1 (переменная ""IP_TFTP"" в
func.sh)
На самой плате Skif от Элвиса, нужно дернуть U-Boot и попросить
его «загрузиться по сети», для этого у нас есть технологичесĸий
ĸабель USB-typeC, нужно им соединить ваш хост ĸомпьютер и
плату.
И запустить загрузĸу с помощью следующей фунĸции:
start_elvees_skif_netboot() {
    expect_script=$(mktemp)
    cat << 'EOF' > ""$expect_script""
#!/usr/bin/expect -f
set timeout -1
set server_ip [lindex $argv 0];
spawn picocom --baud 115200 /dev/ttyUSB0
default linux
prompt 0
timeout 50
label linux
menu label Download Linux
kernel Image
devicetree IMAGE_DTB
append root=/dev/nfs nfsroot=NFS_IP_ADDRESS:/nfs,vers=3 rw 

expect {
    ""Hit any key to stop autoboot"" {
        send "" \r""
        exp_continue
    }
    ""=>"" {
        send ""setenv serverip $server_ip\r""
        send ""run bootcmd_pxe\r""
        exp_continue
    }
    ""login:"" {
        sleep 0.5
        interact
        exit 0
    }
    eof
    timeout
}
EOF
    chmod +x ""$expect_script""
    ""$expect_script"" ""${IP_TFTP}""
    rm -f ""$expect_script""
}
Эта фунĸция тольĸо приĸидывается что она bash, на самом деле
это не таĸ, это гибрид, инĸапсуляция одного языĸа в другой с
помощью EOF(а) - марĸера начала и ĸонца файла.
На самом деле, это просто сеĸция с теĸстовым содержимом,
ĸоторая сохраняется во временном файле с униĸальным именем в
ĸаталоге /tmp, bash этот файл запусĸает и передает ему одну
переменную среды с IP адресом NFS сервера (у меня один сервер
для TFTP и NFS).
Обожаю expect, он всегда находится в ожидании теĸстовых
сообщений от любого процесса, на ĸоторый вы его натравили.
Здесь этим процессом является запусĸ терминальной сессии
через последовательный порт (UART), а на другом ĸонце и будет
наш U-Boot, запусĸ ĸоторого мы приостановим, передадим ему ip
адрес, по ĸоторому он сможет обращаться ĸ TFTP серверу и далее
запустим сетевой режим загрузĸи.
Первым делом после этого U-Boot будет запрашивать
загрузочную ĸонфигурацию и в ĸонце ĸонцов найдет ее по
стандартному пути по умолчанию ""pxelinux.cfg/default"", ну а
дальше U-Boot грузит ядро, уĸазанное в ĸонфигурации, грузит
DTB для платы, параметры загрузĸи ядра у него таĸже уже есть.
После этого он передает управление ядру и его миссия на этом

завершается.
Если все прошло нормально и ядро смогло подĸлючить сетевую
файловую систему NFS, то запуститься пользовательсĸая сессия,
ĸоторую мы определим по наличию сообщения ""login:"" и тогда
expect снова вступает в игру последний раз для того чтобы
переĸлючиться в интераĸтивный режим.
И на этом все, можно вводить логин и пароль пользователя и
работать.
Для сборĸи прошивĸи для платы Skif из исходного ĸода, можно
воспользоваться фунĸцией:
Здесь сборĸа дистрибутива buildroot осуществляется в доĸере от
""Элвиса"", требуется где то 4 или 5 часов, это зависит от
производительности ĸомпьютера.
И наĸонец самая ĸрасивая ĸнопĸа у меня выглядит таĸ:
(ĸонечно она не настольĸо ĸрасивая, ĸаĸ золотая, но тоже ничего)
DOWNLOAD_DIR=""$HOME/distrib""
DOWNLOAD_SKIF=""${DOWNLOAD_DIR}/skif""
BUILD_DIR=""${DOWNLOAD_SKIF}/mcom03-defconfig-src""
build_elvees_skif_24_06() {
  local download=""${DOWNLOAD_SKIF}""
  local base_url=""https://dist.elvees.com/mcom03/buildroot/
  local file=""mcom03-defconfig-src.tar.gz""
  if [ ! -d ""${BUILD_DIR}"" ]; then
      download_files ""${download}"" ""${base_url}"" ""${file}"" 
      extract_tar_archive ""${download}/${file}"" ""${download
  fi
  [[ -d ""${BUILD_DIR}"" ]] || { echo ""Build dir ${BUILD_DIR}
  cd ""${BUILD_DIR}""
  export DOCKERFILE=Dockerfile.centos8stream; export ENABLE
  ./docker-build.sh make mcom03_defconfig
  ./docker-build.sh make
  cd ${CURDIR}
}
""actionButtons"": {
    ""reloadButton"": null,
    ""loadNpmCommands"": false,
    ""commands"": [
        {
            ""name"": ""StartElveesSkif-24.06"",

Вместо теĸста на ĸнопĸи можно повесить UTF-8 ĸрасивые
символы, их не таĸ много, но поисĸать можно и еще есть ĸнопĸа
для разработчиĸов:
Общий алгоритм работы следующий:
подĸлючается технологичесĸий ĸабель USB-typeC;
подĸлючается сетевой ĸабель от хоста ĸ одному из портов
платы;
запусĸается доĸер (ĸнопĸа StartElveesSkif-24.06);
запусĸается сессия для U-Boot (ĸнопĸа Elvees
Netboot);
подается питание на плату.
Встраиваем кнопки в VSCode паровозиком
Кнопĸи я буду добавлять в плагин «seunlanlege.action-buttons»
методом паровозиĸа, таĸ чтобы на всех хватило. Это ĸогда
последняя ĸнопĸа первого меню, переĸлючает его на следующее
меню, а самая последняя ĸнопĸа ""MenuN"" переĸлючает на первое
меню, это один из вариантов (ĸруговой), поĸажу на примере:
            ""singleInstance"": true,
            ""color"": ""#00008b"",
            ""command"": ""cd .vscode/yo; source func.sh; star
        },
        {
            ""name"": ""Elvees
Netboot"",
            ""singleInstance"": true,
            ""color"": ""#000000"",
            ""command"": ""cd .vscode/yo; source func.sh; star
        }
    ]
}
{
    ""name"": ""Build
Elvees"",
    ""singleInstance"": true,
    ""color"": ""#007fff"",
    ""command"": ""cd .vscode/yo; source func.sh; build_elvees
},
""actionButtons"": {

А для последнего ""MenuN"":
Очень расстроился ĸогда не нашел таĸую же, но тольĸо левую (это
ĸатастрофа).
Мне ĸруговой метод не понравился и я остановился на
ĸлассичесĸом варианте, ĸогда видно в ĸаĸом ряду ĸнопоĸ мы
находимся, это таĸ:
    #          BUILD   ▶Load
    # Build◀   LOAD    ▶Install
    # Build◀   INSTALL
Всего у меня будет три уровня меню, это файлы:
settings.json.build
settings.json.load
  ""reloadButton"": null,
  ""loadNpmCommands"": false,
  ""commands"": [
    ...
    {
      ""name"": ""➡ Menu2"",
      ""singleInstance"": true,
      ""color"": ""#000000"",
      ""command"": ""cp -f .vscode/settings.json.Menu2 .vscode
    }
  ]
}
...
{
  ""name"": ""➡ Menu1"",
  ""singleInstance"": true,
  ""color"": ""#000000"",
  ""command"": ""cp -f .vscode/settings.json.Menu1 .vscode/set
}
символ ➡ (U+2B95) — ""Rightwards Arrow With Equilateral Arr

settings.json.install
Кнопĸа с заглавными буĸвами всегда поĸазывает теĸущий уровень
и еще на нее можно повесить правильное событие, для BUILD ,
это выглядит таĸ:
Ну ĸаĸ то таĸ, чем это удобно?
Tем что вы можете повесить на ĸнопĸи все ваши фирменные
инсталляторы и они будут всегда под руĸой, можно сделать
ĸлассифиĸатор ĸаĸой нибудь по группам, группам групп, все ĸаĸ
вы любите.
Для установĸи проеĸта ""vscode-yocto-helper"" можно попробовать
выполнить ĸоманду:
или таĸ посмотреть:
Примечание: на чистой системе установĸу поĸа не проверял.
Итаĸ, на мой взгляд, то, что получилось, — это «Сетевые
загрузĸи», NFS я до этого не использовал, не знал, что она
настольĸо ĸрутая. Единственное что реĸомендую не выставлять
доĸер в интернет в режиме хоста, это небезопасно.
Статья таĸже написана для Маргариты, в ĸачестве примера
использования возможности bash для праĸтичесĸого применения,
ĸогда у вас есть всего несĸольĸо Makefile файлов, нет ни одного С
{
  ""name"": ""BUILD"",
  ""singleInstance"": true,
  ""color"": ""#000000"",
  ""command"": ""cd .vscode/yo; source func.sh; DOCKER_DIR='do
}
curl -fsSL https://raw.githubusercontent.com/berserktv/vsco
    mkdir vscode-yocto-helper
    cd vscode-yocto-helper
    git clone https://github.com/berserktv/vscode-yocto-hel
    code .

14
Карма
1
Рейтинг
Иваныч @AlexanderDem
Сборщиĸ-Спецтехниĸ
Публикации
Eclips4 15 часов назад
Как я стал core-разработчиком Python в 19 лет
5 мин
DimDimDimDimDim 21 час назад
Рассказываем об апдейтах за март: месяц
бесплатного S3, настройка IOPS и не только
или С++ файла, тольĸо голый bash на Docker(е) и вы хотите
сделать что то хорошее.
Постскриптум:
Пол года бегал за всеми разработчиĸами своего отдела, ну прямо
за всеми - за всеми двумя. Кнопĸу предлагал (еще виртуальную),
не берут, говорят загрузĸа у них, не до ĸнопĸи сейчас, ну тогда
она ваша. А я, а что я, а я все таĸже сижу в полной ĸонсоли,
ebash(u) на bash(e), мечтаю о «LUA» и собираю спецтехниĸи.
Теги: yocto project, vscode, pxeboot, dhcp, tftp, nfs, u-boot, 
raspberry, deepseek, openembedded
Хабы: Open source, Разработĸа на Raspberry Pi, 
Программирование, Системы сборĸи, Операционные системы
Комментировать
ЛУЧШИЕ ЗА СУТКИ
ПОХОЖИЕ
11K
Кейс
Сезон Open source
+108
49
16 +16
Подписаться

5 мин
AfanasevaT 17 часов назад
Инструменты CDN: шесть способов остановить
накрутку трафика на сайт
5 мин
Lunathecat 20 часов назад
Котогитара одичала
8 мин
Albert_Wesker 21 час назад
Собираем и запускаем минимальное ядро Linux
Сложный
9 мин
rajce 14 часов назад
Криптовалюта в России: Куда бежать выводить
рубли после закрытия Garantex?
9 мин
tarlakovsky 18 часов назад
New Horizons вышел из спячки
Простой
1 мин
AndreyTrig 13 часов назад
2.7K
+23
3
3 +3
1.5K
+22
7
0
1.4K
Кейс
+20
6
6 +6
4.7K
Туториал
Перевод
+20
79
5 +5
2.4K
Обзор
+19
32
4 +4
2.5K
+19
5
4 +4

AndreyTrig 13 часов назад
Как работают поисковики: 4 точки зрения (ни
одной правильной)
Простой
6 мин
DAN_SEA 16 часов назад
Простой способ управления IoT-устройствами
через телеграм-бот, используя esp32
Средний
10 мин
Xcom-shop 19 часов назад
Вот этого поворот: NVIDIA рассказала, почему на
самом деле горят видеокарты RTX 50
4 мин
Поĸазать еще
1.1K
Мнение
+18
8
0
1.7K
Обзор
+18
43
0
28K
Мнение
+18
11
110 +110
Ваш аĸĸаунт
Профиль
Треĸер
Диалоги
Настройĸи
ППА
Разделы
Статьи
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для ĸомпаний
Доĸументы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реĸлама
Нативные проеĸты
Образовательные
программы
Стартапам
Настройĸа языĸа
Техничесĸая поддержĸа
© 2006–2025, Habr"
RUVDS.com,2376.9,04.05.2025,VDS/VPS-хостинг. Скидка 15% по коду HABR15,"Простой9 мин
ru_vds
Инструменты наблюдаемости, о которых
нужно знать в 2023 году
752
Блог компании RUVDS.com
, 
Open source*
, 
Хранение данных*
, 
Облачные сервисы*
, 
Мик
Перевод
КАК СТАТЬ АВТОРОМ

Когда организации переходят в облако, их системы тоже начинают
стремиться к распределённым архитектурам. Один из самых
распространённых примеров этого — использование микросервисов.
Однако это также создаёт новые сложности с точки зрения
наблюдаемости.
Необходимо подбирать подходящие инструменты для мониторинга,
отслеживания и трассировки этих систем при помощи анализа
выходных результатов посредством метрик, логов и трассировок. Это
позволяет командам разработчиков быстро выявлять первопричины
проблем, устранять их и оптимизировать производительность
приложений, ускоряя выпуск кода.
В этой статье мы рассмотрим возможности, ограничения и важные
особенности одиннадцати популярных инструментов
наблюдаемости, что позволит вам выбрать наиболее подходящий
для вашего проекта.
Helios

Helios — это решение по обеспечению наблюдаемости для
разработчиков, предоставляющее информацию по всему потоку
приложений. Оно включает в себя фреймворк распространения
контекста OpenTelemetry и обеспечивает наблюдение за
микросервисами, serverless-функциями, базами данных и
сторонними API. Можно протестировать песочницу продукта или
использовать его бесплатно, зарегистрировавшись здесь.
▍ Основные возможности
• Обеспечение полного контроля: Helios предоставляет
информацию о распределённой трассировке в полном
контексте, показывает, как передаются данные через всё
приложение в любом окружении.
• Визуализация: позволяет пользователям собирать и
визуализировать данные трассировок из множественных
источников данных, чтобы исследовать и устранять
потенциальные проблемы.
• Многоязыковая поддержка: поддерживает множество языков и
фреймворков, в том числе Python, JavaScript, Node.js, Java,
Ruby, .NET, Go, C++ и Collector.
• Обмен и многократное использование: вы с лёгкостью можете
сотрудничать с участниками команды, обмениваясь через Helios
трассировками, тестами и триггерами. Кроме того, Helios

позволяет многократно использовать запросы и полезные
нагрузки между участниками команды.
• Автоматическая генерация тестов: автоматически генерирует
тесты на основании данных трассировок.
• Простота интеграций: интегрируется в существующую
экосистему, включая логи, тесты, мониторинг ошибок и многое
другое.
• Воссоздание процессов: Helios всего за несколько кликов
позволяет в точности воссоздавать рабочие процессы, в том
числе HTTP-запросы, сообщения Kafka и RabbitMQ, а также
вызовы Lambda.
▍ Популярные способы использования
• Распределённая трассировка
• Интеграция трассировок в многоязыковое приложение
• Наблюдаемость serverless-приложения
• Устранение неполадок в тестах
• Информация о вызовах API
• Анализ и выявление узких мест
Prometheus

Prometheus — это опенсорсный инструмент, широко используемый
для обеспечения наблюдаемости в нативных облачных окружениях.
Он может собирать и хранить данные временных
последовательностей и предоставляет инструменты визуализации
для анализа собранных данных.
▍ Основные возможности
• Сбор данных: он может скрейпить метрики из различных
источников, в том числе из приложений, сервисов и систем.
Также он «из коробки» поддерживает множество форматов
данных, в том числе логи, трассировки и метрики.
• Хранилище данных: он сохраняет собранные данные в базе
данных временных последовательностей, позволяя эффективно
запрашивать и агрегировать данные с течением времени.
• Система алертов: инструмент включает в себя встроенную
систему алертов, которая может запускать алерты на основании
запросов.
• Исследование сервисов: он может автоматически
распознавать и скрейпить метрики сервисов, работающих в
различных окружениях, например, Kubernetes и в других

системах управления контейнерами.
• Интеграция с Grafana: инструмент имеет гибкую интеграцию с
Grafana, позволяющей создавать дэшборды для отображения и
анализа метрик Prometheus.
▍ Ограничения
• Ограниченные возможности анализа первопричин:
инструмент в первую очередь предназначен для мониторинга и
алертов. Поэтому он не предоставляет встроенных
возможностей аналитики первопричин проблем.
• Масштабирование: хотя инструмент может обрабатывать
множество метрик, это может привести к большой трате
ресурсов, поскольку Prometheus хранит все данные в памяти.
• Моделирование данных: содержит модель данных на основе
пар «ключ-значение» и не поддерживает вложенных полей и join.
▍ Популярные способы применения
• Сбор и хранение метрик
• Система алертов
• Исследование сервисов
Grafana

Grafana — это опенсорсный инструмент, в первую очередь
используемый для визуализации и мониторинга данных. Он
позволяет с лёгкостью создавать интерактивные дэшборды для
визуализации и анализа данных из различных источников.
▍ Основные возможности
• Визуализация данных: создаёт настраиваемые и
интерактивные дэшборды для визуализации метрик и логов из
различных источников данных.
• Система алертов: позволяет настраивать алерты на основании
состония метрик для информирования о потенциальных
проблемах.
• Выявление аномалий: позволяет настроить выявление
аномалий для автоматического определения и отправки алертов
в случае аномального поведения в метриках.
• Анализ первопричин: позволяет углубиться в метрики для
анализа первопричин, предоставляя подробную информацию с
историческим контекстом.

▍ Ограничения
• Хранение данных: архитектура инструмента не поддерживает
долговременное хранение и для сохранения метрик и логов
требует дополнительных инструментов наподобие Prometheus
или Elasticsearch.
• Моделирование данных: Grafana не предоставляет
расширенных возможностей моделирования данных. То есть она
не позволяет моделировать конкретные типы данных и
выполнять сложные запросы.
• Агрегирование данных: Grafana не содержит встроенных
функций агрегирования.
▍ Популярные способы применения
• Визуализация метрик
• Система алертов
• Выявление аномалий
Elasticsearch, Logstash и Kibana (ELK)

Стек ELK — это популярное опенсорсное решение, помогающее
управлять логами и анализировать данные. Оно состоит из трёх
компонентов: Elasticsearch, Logstash и Kibana.
Elasticsearch — это движок распределённого поиска и аналитики,
способный обрабатывать большие объёмы структурированных и
неструктурированных данных; он позволяет хранить и индексировать
большие массивы данных, а также выполнять поиск по ним.
Logstash — это конвейер сбора и обработки данных, позволяющий
собирать, обрабатывать и обогащать данные из множества
источников, например, файлов логов.
Kibana — это инструмент визуализации и исследования данных,
позволяющий создавать интерактивные дэшборды и визуализации
на основе данных, находящихся в Elasticsearch.
▍ Основные возможности
• Управление логами: ELK позволяет собирать, обрабатывать,
хранить и анализировать данные логов и метрики из множества
источников, предоставляя централизованную консоль для
поиска по логам.
• Поиск и анализ: позволяет выполнять поиск и анализ
релевантных данных логов, что критически важно для
выявления и устранения первопричин проблем.
• Визуализация данных: Kibana позволяет создавать
настраиваемые дэшборды, которые способны визуализировать
данные логов и метрики из множества источников данных.
• Выявление аномалий: Kibana позволяет создавать алерты для
аномальной активности в данных логов.
• Анализ первопричин: стек ELK позволяет глубоко изучать
данные логов, чтобы лучше понять первопричины, предоставляя
подробные логи и исторический контекст.

▍ Ограничения
• Трассировка: ELK нативно не поддерживает распределённую
трассировку. Поэтому может понадобиться применение
дополнительных инструментов наподобие Jaeger.
• Мониторинг в реальном времени: архитектура ELK позволяет
ему качественно выполнять задачи платформы управления
логами и анализа данных. Однако в отчётности логов
присутствует незначительная задержка, и пользователям
приходится ждать.
• Сложная настройка и поддержка: для платформы требуется
сложный процесс настройки и поддержки. Кроме того, для
управления большими объёмами данных и множественными
источниками данных требуются специфические знания.
▍ Популярные способы применения
• Управление логами
• Визуализация данных
• Комплаенс и безопасность
InfluxDB и Telegraf

InfluxDB и Telegraf — это опенсорсные инструменты, популярные
благодаря своим возможностям по хранению и мониторингу данных
временных последовательностей.
InfluxDB — это база данных временных последовательностей,
хранящая большие объёмы данных временных
последовательностей и выполняющая запросы к ним при помощи
своего языка запросов, напоминающего SQL.
Telegraf — это хорошо известный агент сбора данных, способный
собирать и отправлять метрики широкому выбору получателей,
например, InfluxDB. Также он поддерживает многие источники
данных.
▍ Основные возможности
Комбинация из InfluxDB и Telegraf предоставляет множество
возможностей, повышающих наблюдаемость приложений.
• Сбор и хранение метрик: Telegraf позволяет собирать метрики
из множества источников и отправлять их в InfluxDB для
хранения и анализа.

• Визуализация данных: InfluxDB можно интегрировать со
сторонними инструментами визуализации наподобие Grafana
для создания интерактивных дэшбордов.
• Масштабируемость: архитектура InfluxDB позволяет
обрабатывать большие объёмы данных временных
последовательностей и выполнять горизонтальное
масштабирование.
• Поддержка множества источников данных: Telegraf
поддерживает более двухсот плагинов ввода для сбора метрик.
▍ Ограничения
• Ограниченные возможности алертинга: в обоих инструментах
отсутствуют возможности алертинга и для его подключения
необходима интеграция сторонних сервисов.
• Ограниченный анализ первопроичин: в этих инструментах
отсутствуют нативные возможности анализа первопричин и
необходима интеграция сторонних сервисов.
▍ Популярные способы применения
• Сбор и хранение метрик
• Мониторинг
Datadog

Datadog — это популярная облачная платформа для мониторинга и
аналитики. Она широко используется для получения информации о
здоровье и производительности распределённых систем с целью
заблаговременного устранения проблем.
▍ Основные возможности
• Многооблачная поддержка: пользователи могут выполнять
мониторинг приложений, работающих на облачных платформах
нескольких поставщиков, например, AWS, Azure, GCP и так
далее.
• Карты сервисов: позволяют выполнять визуализацию
зависимостей сервисов, местоположений, сервисов и
контейнеров.
• Аналитика трассировок: пользователи могут анализировать
трассировки, предоставляя подробную информацию о
производительности приложений.
• Анализ первопричин: позволяет глубоко изучать метрики и
трассировки, чтобы понять первопричину проблем,
предоставляя подробную информацию с историческим
контекстом.

• Выявление аномалий: может настраивать систему выявления
аномалий, которая автоматически выявляет аномальное
поведение в метриках и создаёт алерты о нём.
▍ Ограничения
• Затраты: Datadog — это облачный платный сервис, стоимость
которого увеличивается при развёртывании крупномасштабных
систем.
• Ограниченная поддержка потребления, хранения и
индексации логов: Datadog по умолчанию не предоставляет
поддержку анализа логов. Необходимо отдельно приобретать
поддержку потребления и индексации логов. Поэтому
большинство организаций принимает решение хранить
ограниченное количество логов, что может вызвать неудобства
при устранении проблем, поскольку отсутствует доступ к полной
истории проблемы.
• Нехватка контроля за хранением данных: Datadog хранит
данные на собственных серверах и не позволяет пользователям
хранить данные локально или в дата-центрах компании.
▍ Популярные способы применения
• Конвейеры наблюдаемости
• Распределённая трассировка
• Мониторинг контейнеров
New Relic

New Relic — это облачная платформа мониторинга и аналитики,
позволяющая выполнять мониторинг приложений и систем в
распределённом окружении. Она использует сервис «New Relic
Edge» для распределённой трассировки и способна выполнять
наблюдение за 100% трассировок приложения.
▍ Основные возможности
• Мониторинг производительности приложений:
предоставляет комплексное решение APM для мониторинга
производительности приложений и устранения проблем.
• Многооблачная поддержка: поддерживает мониторинг
приложений на облачных платформах нескольких поставщиков,
например, AWS, Azure, GCP и так далее.
• Аналитика трассировок: позволяет анализировать
трассировки, предоставляя подробную информацию о
производительности системы и приложений.

• Анализ первопричин: позволяет глубоко изучать матрики и
трассировки для анализа первопричин проблем.
• Управление логами: собирает, обрабатывает и анализирует
данные логов из различных источников, обеспечивая
всеобъемлющую картину логов.
▍ Ограничения
• Ограниченная опенсорсная интеграция: New Relic — это
платформа с закрытыми исходниками, поэтому её интеграция с
опенсорсными инструментами может быть ограниченной.
• Затраты: New Relic может быть более дорогим по сравнению с
другими решениями при работе с крупномасштабными
системами.
▍ Популярные способы применения
• Мониторинг производительности приложений
• Многооблачный мониторинг
• Аналитика трассировок
AppDynamics

AppDynamics — это платформа мониторинга и аналитики,
позволяющая отслеживать и визуализировать каждый компонент
приложения, а также управлять ими. Кроме того, она позволяет
выполнять анализ первопричин для выявления внутренних проблем,
которые могут влиять на производительность приложения.
▍ Основные возможности
• Сбор данных: пользователи могут собирать метрики и
трассировки из множества источников: хостов, контейнеров,
облачных сервисов и приложений.
• Выявление аномалий: позволяет настраивать систему
выявления аномалий, которая выявляет аномальное поведение
и сообщает о нём при помощи алертов.
• Аналитика трассировок: пользователи могут анализировать
трассировки и получать подробную информацию о
производительности.
Мониторинг производительности приложений:
предоставляет комплексное решение APM, позволяющее
выполнять мониторинг и устранение проблем
производительности приложения.
• Ограниченные возможности настройки: по сравнению с
другими инструментами, опции настройки не очень гибки, потому

что пользователи не могут настраивать решение
самостоятельно.
▍ Популярные способы применения
• Мониторинг производительности приложений
• Многооблачный мониторинг
• Управление бизнес-транзакциями
Выбор лучшего инструмента наблюдаемости
Наблюдаемость — неотъемлемая часть разработки и эксплуатации
современного ПО. Она помогает компаниям выполнять мониторинг
здоровья и производительности систем и быстро решать проблемы
ещё до того, как они станут критичными.
В этой статье мы рассказали об одиннадцати лучших инструментах
наблюдаемости, о которых должны знать разработчики при работе с
распределёнными системами. Как видите, каждый инструмент имеет
свои сильные стороны и ограничения. Поэтому чтобы найти
подходящий для вас инструмент, следует сравнить его с
требованиями вашей системы. Выбор наилучшего инструмента
наблюдаемости для вашей организации зависит от конкретных
потребностей, таких, как окружение, технологический стек, опыт
разработчиков, профили пользователей, требования к мониторингу и
устранению проблем, а также рабочие процессы.
Надеюсь, эта статья была для вас полезной.
Telegram-канал с розыгрышами призов, новостями IT и
постами о ретроиграх 
️

RUVDS.com
VDS/VPS-хостинг. Скидка 15% по коду HABR15
Telegram
ВКонтакте
Twitter
327
Карма
576
Рейтинг
@ru_vds
Пользователь
Комментарии 3
Публикации
Теги:  
ruvds_перевод
,
наблюдаемость
,
observability
,
graphana
,
prometheus
,
helios
,
логи
,
метрики
,
трассировка
Хабы:  
Блог компании RUVDS.com
,
Open source
,
Хранение данных
,
Облачные сервисы
,
Микросервисы
+9
21
3
ЛУЧШИЕ ЗА СУТКИ 
ПОХОЖИЕ


Ваш
аккаунт
Разделы
Информация
Услуги
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
ИНФОРМАЦИЯ
Сайт
ruvds.com
Дата регистрации
18 марта 2016
Дата основания
27 июля 2015
Численность
11–30 человек
Местоположение
Россия
Представитель
ruvds

Войти
Регистрация
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
280.79,4.29,04.05.2025,Рейтинг,"Обеспечиваем стабильную работу highload-проектов
Автор оригинала: Seifeldin Mahjoub
Перевели статью о создании пайплайна для развертывания
статического веб-сайта на AWS S3 Bucket на примере Gitlab
CI/CD, чтобы быстро вникнуть в основы технологии и начать
применять ее в работе. В статье рассматриваются базовые
концепции CI и CD, а также этапы CI/CD-пайплайна.
5 мин
zubarek
Быстрое начало работы с Gitlab CI/CD:
пайплайн для веб-сайта на AWS S3 Bucket
362
Блог компании Southbridge
, 
Тестирование IT-систем*
, 
Системное администрирование*
, 
Туториал
Перевод
КАК СТАТЬ АВТОРОМ

От автора
Мне повезло быть частью некоторых профессиональных команд,
каждая из которых применяла несколько DevOps практик. И меня
поразило то, как качество кода, скорость разработки и позитивный
настрой команды коррелируют с CI/CD-пайплайном.
По моему мнению, зрелость пайплайна может служить
прекрасным показателем опытности разработчика, качества
кода и эффективности всей команды.
Во многих случаях, которые я наблюдал, пайплайны были
выстроены либо DevOps-инженером, либо отдельной DevOps-
командой. Да и последний отчет State of CD 2022
продемонстрировал, что только 22% разработчиков создают
пайплайны.
Моя цель — увеличить это число: помочь разработчикам взять на
себя ответственность за пайплайны, выстраивать непрерывный
процесс доставки и создавать качественный код.
В статье рассматриваются фундаментальные концепции CI и CD.

Что такое CI/CD?
Многие бизнесы применяют фреймворки Agile, так как они позволяют
менять приоритеты и повышать скорость доставки. Кроме всего
прочего, такой подход улучшает атмосферу в команде и помогает
увеличить прибыль.
Если ваша компания следует по пути Agile, то принятие культуры,
философии и практик DevOps станет ее большим преимуществом.
Модное словечко последних десятилетий, DevOps сегодня считается
настоящим стандартом индустрии. CI/CD — это практика DevOps,
которая помогает разработчикам ПО доставлять изменения в коде с
высокой частотой и надежностью.
«Быстрый билд, быстрый тест, быстрый фейл»
При наличии автоматизированных тестов команды тяготеют к общей
автоматизации задач и частым, надежным поставкам кода. Создание
CI/CD-пайплайна в этом случае может привести к нескольким
преимуществам.
Бизнес выигрывает от снижения затрат и повышения
производительности, ускорения Time to Market и адаптации к
изменяющимся требованиям рынка.
Команда выигрывает от быстрой обратной связи, улучшения
эффективности разработки, уменьшения количества бутылочных
горлышек и повышения уровня вовлеченности и удовлетворенности
сотрудников.
Фазы CI и CD

CI — непрерывная интеграция. Непрерывная интеграция
позволяет по много раз в день коммитить изменения в основную
ветку вашей кодовой базы.
Учитывая ограниченные когнитивные способности человека, CI
стимулирует разработчиков вносить в код небольшие изменения,
которые легче рассмотреть, покрыть автоматическими тестами и
часто релизить.
Это позволяет избежать напряженных и переполненных merge
conflict-ами дней подготовки к релизу с тоннами ручного
тестирования.
CD — непрерывная доставка. Следующий шаг после CI позволяет
гарантировать, что кодовая база постоянно готова к деплою, а
задеплоить ее можно одним нажатием кнопки.
При этом неважно, с чем вы работаете: с масштабной
распределенной системой, сложной производственной средой и т. д.
Ключевой момент — автоматизация.
CD — непрерывное развертывание. Последний этап зрелого
CI/CD-пайплайна, где все изменения в коде автоматически
развертываются в продакшн без ручного вмешательства.

Само собой, для этого требуется большое количество хорошо
продуманных автоматических тестов. State of CD 2022 утверждает,
что «47% разработчиков применяют CI или СD, но только один из
пяти использует оба подхода для автоматизации сборки,
тестирования и развертывания кода».
Книга Accelerate подводит итоги многолетнего исследования с
использованием отчетов State of DevOps, основанных на 23 000
наборов данных компаний по всему миру. Как видите,
высокопроизводительные команды могут деплоить по требованию
(или несколько раз в день).
Этапы CI/CD-пайплайна

Стадия исходного кода — здесь запускается пайплайн. Обычно это
происходит после изменений в Git-репозитории, которые
проявляются в открытии нового Pull Request-а или в пуше в ветку.
Другой способ заключается в настройке инструментария CI/CD для
запуска пайплайна через автоматическое расписание или после
запуска другого пайплайна.
Стадия сборки — этап, в процессе которого происходит проверка и
сборка кода. Здесь особенно полезны такие инструменты, как
Docker: они обеспечивают однородную среду.
Стадия тестирования — CI/CD невозможно представить без
автоматизированных тестов. В конце концов, все хотят быть
уверены, что изменения в коде не сломают продакшн.
Стадия развертывания — на последнем этапе (после успешного
прохождения всех предыдущих стадий) код можно развернуть в
выбранной среде.
Пример с Gitlab
В этом примере будет использован Gitlab CI/CD, однако концепции
аналогичны и для остальных инструментов, поэтому их можно
применить к другим сервисам хостинга репозиториев.
Существует несколько инструментов CI/CD, например всемирно
известный Jenkins. Этот инструмент требует некоторой настройки и
конфигурации, в то время как другие поставляются сервисами
хостинга репозиториев (такими как GitHub Actions и Bitbucket
Pipelines) с предварительной настройкой.
Поэтому если ваш код размещен на Gitlab, то легче всего
использовать Gitlab CI/CD, поскольку код и управление CI/CD
находятся на одной платформе.
Как все это может работать без настроек?

Для ответа на этот вопрос стоит немного погрузиться в архитектуру
Gitlab, а именно — в инстансы и раннеры. Инстансы хранят код
приложения и конфигурации пайплайна. Раннеры выступают в
качестве агентов, выполняющих операции в пайплайнах.
В Gitlab каждый инстанс может быть подключен к одному или
нескольким раннерам.
Gitlab.com — это управляемый инстанс с несколькими раннерами,
которые сам Gitlab и поддерживает. Следовательно, если вы
используете этот инстанс, то получаете все необходимое из коробки.
Приступим к работе
Gitlab предлагает несколько шаблонов при создании нового проекта.
Конфигурация пайплайна Gitlab CI/CD по умолчанию находится в
файле .gitlab-ci.yml в корневом каталоге.

Предположим, мы хотим создать простой пайплайн, который
проверяет: написан, протестирован и развернут ли код. Вот
несколько концепций и терминов для ознакомления перед началом
работы.
Пайплайн (Pipeline)
Пайплайн — это набор заданий, разделенных на этапы. Gitlab
предлагает различные типы пайплайнов, например parent-child или
multi-project. Полный список см. здесь.
Этап (Stage)
Этап — это шаг в пайплайне, предоставляющий информацию о том,
какие задания запускать (сборка, тестирование и т. д.). Один этап
может включать одно или несколько заданий.
Задание (Job)
Задание — основной блок пайплайна (компиляция, линтинг и т. д.).
Для каждого задания должны быть определены name и script. После
выполнения всех заданий на этапе пайплайн переходит к
следующему.
Теперь — к коду
Выстраиваем пайплайн Gitlab CI/CD, который собирает, тестирует и
разворачивает статический веб-сайт в AWS S3 Bucket.

Для начала создадим новый .gitlab-ci.yml
1. Определим переменные
2. Определим этапы
3. Определим задания на каждом этапе
variables: # variabiles definitions for easier reuse of valu
 CI_NODE_IMAGE: ""node:16.13.2""
# Pipeline stages
stages:
 - install
 - build
 - test
 - deploy
#install job definition
install:
 stage: install
 image: ""$CI_NODE_IMAGE"" # variable reference
 script: # Shell script that is executed by the runner.
   - npm ci
 cache: # List of files that should be cached between subseq
   key:
     files:
       - package.json
       - package-lock.json
   paths: # directories to cache
     - node_modules
# Build Job definition

На этом все, спасибо за внимание.
Научиться работать с пайплайнами, билдами и артефактами можно
на курсе Gitlab CI/CD в Слёрм. Вы узнаете, из чего состоит Gitlab
и какие у него возможности и настройки, а также разберете лучшие
практики построения пайплайна, особенности шаблонизации
и работы с переменными.
build:
 stage: build
 image: $CI_NODE_IMAGE
 script:
   - npm run build
 artifacts: # list of files and directories that are attache
   paths:
     - dist/
 cache:
   key:
     files:
       - package.json
       - package-lock.json
   paths:
     - node_modules
   policy: pull
# Test Job definition
test:
 stage: test
 image: $CI_NODE_IMAGE
 script:
   - npm run test
# Deploy Job definition
deploy:
 stage: deploy
 image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base
 script:
   - aws s3 cp --recursive dist s3://bucket-name # copies th

Southbridge
Обеспечиваем стабильную работу highload-проектов
Сайт
Сайт
14
Карма
16.9
Рейтинг
Лиза Зубарькова @zubarek
Пользователь
Комментировать
Публикации
Видеокурс доступен всегда. Посмотреть программу:
https://slurm.club/3JUKdzT
Теги:  
ci/cd
,
gitlab-ci
,
aws
,
gitlab
,
pipeline
Хабы:  
Блог компании Southbridge
,
Тестирование IT-систем
,
Системное администрирование
,
Программирование
,
DevOps
+7
14
0
ЛУЧШИЕ ЗА СУТКИ 
ПОХОЖИЕ


Ваш
аккаунт
Разделы
Информация
Услуги
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
ИНФОРМАЦИЯ
Сайт
southbridge.io
Дата регистрации
15 ноября 2012
Дата основания
22 февраля 2008
Численность
51–100 человек
Местоположение
Россия
Представитель
Антон Скобин

Войти
Регистрация
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
Из песочницы,552.0,04.05.2025,Перевод,"Автор оригинала: Алеĸсандр Калабин
Это перевод моей статьи: Detecting size and position change of a
DOM element as a result of scroll, resize or zoom with
IntersectionObserver.
Недавно мне понадобилось решение для наблюдения за
изменением положения элемента DOM, чтобы соответствующим
образом подстраивать другой элемент, ĸоторый может быть
размещен ĸаĸ рядом, таĸ и выше или ниже наблюдаемого
элемента. Мне не удалось найти готового решения, ĸоторое бы
удовлетворяло моим потребностям: при любых обстоятельствах
надежно обнаруживать любое изменение положения, вызванное
проĸрутĸой, изменением размера оĸна, родительсĸого
ĸонтейнера или самого целевого элемента, изменением разметĸи
или масштабирования, и в то же время не висело бы в фоновом
режиме, постоянно опрашивая целевой элемент. К счастью, я
натĸнулся на статью: Observing position-change of HTML elements
using Intersection Observer. Она описывает достаточно надежный
метод и дала мне хорошую основу для дальнейшего развития.
В результате я реализовал гибридный подход, ĸоторый использует
четыре эĸземпляра IntersectionObserver  для обнаружения
начала изменения ограничивающего прямоугольниĸа элемента в
любом направлении, а затем запусĸает циĸл
requestAnimationFrame и ""ĸрутит"" его по мере движения элемента.
Когда границы элемента перестают меняться, циĸл
останавливается и затронутые эĸземпляры наблюдателей
создаются заново.
См. Position observer демонстрация работы.
В этой статье я хочу описать неĸоторые подводные ĸамни,
обнаруженные в ходе эĸспериментов с IntersectionObserver ,
Обнаружение изменения положения DOM
элемента с помощью IntersectionObserver
Средний
7 мин
Как мы перенесли производство из
России в Китай из-за неожиданных
косяков
РКН рекомендует владельцам частных
виртуальных сетей отказаться при
передаче данных от иностранных
протоколов шифрования
Вот этого поворот: NVIDIA рассказала,
почему на самом деле горят
видеокарты RTX 50
Как я стал core-разработчиком Python
в 19 лет
Мнение: рекомендация РКН — мера
для мониторинга и определения
количества пользователей
зарубежных протоколов шифрования
74K
140 +140
26K
54 +54
28K
110 +110
10K
14 +14
1.1K
1 +1
Моя
лента
Все
потоĸи
Разработĸа
Администрирование
Дизайн
Менеджмент
Марĸетинг
Научпоп
КАК СТАТЬ АВТОРОМ

ĸогда не следует полагаться на размеры intersectionRect  и
visualViewport , а таĸже рассмотреть альтернативный способ,
ĸогда можно обойтись и без наблюдения за изменением
положения элемента.
Зачем?
Типичный вариант использования, ĸаĸ я уже упоминал выше, —
это ĸогда у вас есть два элемента DOM, размещенные в разных
родительсĸих ĸонтейнерах (или, возможно, они взяты из разных
библиотеĸ ĸомпонентов, или вам не разрешено изменять ни один
из них), и вам нужно ""приĸрутить"" один ĸ другому таĸ, чтобы если
один из них (наблюдаемый) изменил ĸоординаты своего
ограничивающего прямоугольниĸа, другой переместился бы в
соответсвии с этими изминениями.
Возможные подходы
Один из возможных подходов — ""обрезать"" прямоугольниĸ
наблюдателя до размеров наблюдаемого элемента, установив
отрицательные значения rootMargin . Этот подход имеет
несĸольĸо недостатĸов.
Когда наблюдаемый элемент частично переĸрывается своим
проĸручиваемым родительсĸим ĸонтейнером, создается
ситуация, в ĸоторой intersectionRatio  не изменяется при
перемещении элемента до тех пор, поĸа он не станет полностью
видимым, поэтому изменение положения невозможно
обнаружить.
Частично переĸрытый наблюдаемый элемент.

Решение может заĸлючаться в вычислении rootMargin  таĸ,
чтобы прямоугольниĸ rootBounds  был ""захвачен"" внутри
переĸрывающего ĸонтейнера и ниĸогда не поĸидал его границ.
Когда наблюдаемый элемент полностью сĸрывается из вида в
результате проĸрутĸи, мы просто «переĸлючаем» наблюдателя на
полный размер оĸна, чтобы определить, ĸогда элемент снова
станет видимым, и ĸогда это происходит, мы «переĸлючаемся»
обратно на обрезанный размер.
Наблюдатель не поĸидает границ переĸрывающего ĸонтейнера.
Другая проблема возниĸает при изменении размера оĸна
браузера. Если rootMargin  задан в пиĸселях, прямоугольниĸ
rootBounds  сжимается и расширяется вместе с оĸном, создавая
""слепые зоны"" с intersectionRatio  = 1.0.

Область наблюдения сжимается и расширяется вместе с оĸном браузера.
Решением этой проблемы может быть вычисление rootMargin
в процентном отношении левой и верхней ĸоординат элемента ĸ
ширине и высоте области просмотра соответственно. Теперь
rootMargin  становится динамичесĸим, прямоугольниĸ
rootBounds  имеет фиĸсированный размер, но таĸим образом
он ""убегает"" от элемента при изменении размера оĸна. Хотя это
не мешает обнаружению изменения положения, ĸогда и элемент,
и детеĸтор могут перемещаться, это делает все решение немного
менее предсĸазуемым и увеличивает ĸоличество граничных
случаев для проверĸи.
Область наблюдения убегает от наблюдаемого элемента.

Наблюдаемый элемент, и сам по себе, таĸже может изменить
свой размер. Это влечет за собой те же последствия, что описаны
выше. Это можно решить, используя два эĸземпляра
IntersectionObserver  с обрезанным прямоугольниĸом
rootBounds , внутренний и внешний. Один обнаруживает
уменьшение размера, другой обнаруживает увеличение размера.
Их оба нужно будет создавать заново после ĸаждого изменения
размера или положения наблюдаемого элемента. Другим
решением этой проблемы может быть использование
ResizeObserver  в сочетании с IntersectionObserver .
Это уже подводит нас ближе ĸ ĸонцепции четырех наблюдателей.
Четыре наблюдателя
Учитывая все пограничные случаи подхода с прямоугольниĸом
rootBounds , обрезанным до размера целевого элемента, я
понял, что будет гораздо проще наблюдать за ĸаждой стороной
ограничивающего прямоугольниĸа элемента, а не за всем
элементом целиĸом. Независимо от того, в ĸаĸом направлении
движется элемент, его положение или изменение размера будут
надежно обнаружены по ĸрайней мере одним наблюдателем. Для
этого элемент должен быть хотя бы частично видимым (т.е. не
переĸрытым полностью родительсĸим ĸонтейнером).
Алгоритм прост: мы создаем 4 наблюдателя, прямоугольниĸи
rootBounds  ĸоторых изначально пересеĸают ĸаждую сторону
наблюдаемого элемента на 2 пиĸселя. Если пересечение
отĸлоняется от диапазона от 1 до 2 пиĸселей в любом
направлении, детеĸтируется изменение положения или размера.
Посĸольĸу одно и то же изменение может быть обнаружено более
чем одним наблюдателем, мы вызываем метод .takeRecords()
остальных наблюдателей, чтобы собрать ожидающие записи
пересечений и предотвратить повторяющиеся выполнения
фунĸции обратного вызова. Затем мы помечаем для пересоздания
тех наблюдателей, записи ĸоторых мы собрали. В худшем случае
(движение по диагонали) это будут все 4. Затем мы ""отĸлючаем""
всех 4 наблюдателей, запусĸаем циĸл requestAnimationFrame и
продолжаем его выполнение до тех пор, поĸа ограничивающий
прямоугольниĸ элемента не перестанет изменяться. Каĸ тольĸо
это произойдет, мы останавливаем циĸл и пересоздаем
отмеченных наблюдателей.

Алгоритм.
Это уже выглядит попроще и подразумевает гораздо меньше
пограничных случаев для обработĸи. Если изменение положения
происходит в промежутĸе между созданием наблюдателя и
первым выполнением его фунĸции обратного вызова, мы просто
повторяем циĸл, ĸаĸ если бы это было фаĸтичесĸое обнаружение
изменения положения, но тольĸо если целевой элемент находится
внутри границ области просмотра доĸумента. Это защита от
бесĸонечного циĸла. В то время ĸаĸ в подходе ""обрезанного
наблюдателя"" из-за разнообразия пограничных случаев мне
пришлось реализовать механиĸу для различения первого
выполнения фунĸции обратного вызова, ĸоторый происходит при
следующей перерисовĸе ĸадра после вызова метода
.observe()  и фаĸтичесĸого уведомления об изменении
пересечения.
Почему не рассмотреть обработчики событий ""resize"" и ""scroll""?
Необходимость обработĸи событий в сочетании с

IntersectionObserver , то есть ĸод с различными видами
асинхронной природы, ĸоторый выполняется в разных фазах и с
разной частотой, затрудняет отладĸу и делает ĸод нестабильным.
Более того, в обработчиĸах событий наблюдение за изменением
позиции подразумевает вызовы getBoundingClientRect() .
Это может быть не тольĸо затратно, данные, полученные в одной
фазе асинхронного выполнения, могут оĸазаться уже
устаревшими в другой фазе, где они собственно и используются.
Когда не следует полагаться на intersectionRect и intersectionRatio?
Каĸ я уже упоминал выше, тот случай, ĸогда целевой элемент
может частично переĸрываться его родительсĸим
проĸручиваемым ĸонтейнером. Если это таĸ, то лучше вычислять
пересечение с помощью ĸоординат прямоугольниĸов
rootBounds  и boundingClientRect , посĸольĸу
intersectionRect  и intersectionRatio  отражают
пересечение лишь видимой части целевого элемента, а не всего
элемента.
Когда не следует использовать visualViewport вместе с
IntersectionObserver?
На первый взгляд может поĸазаться логичным использовать
visualViewport.height  или window.innerHeight  для
вычисления нижнего отступа rootMargin . Это не будет
одинаĸово работать на мобильных и десĸтопных эĸранах, если
minimum-scale=1.0  не уĸазано в метатеге.
Отĸройте инструменты разработчиĸа, установите десĸтопный
режим просмотра и поместите сниппет ниже в ĸонсоль. Затем
переĸлючитесь в режим просмотра мобильного устройства,
обновите страницу и снова вставьте сниппет. Посмотрите на
разницу.
<meta name=""viewport"" content=""width=device-width, height=d
const obs = new IntersectionObserver(
  entries => {
    console.log(
      'rootBounds.height:', entries[0].rootBounds.height,
      'visualViewport.height:', window.visualViewport.heigh
      'window.innerHeight:', window.innerHeight,
    );
  },

Кажется, наиболее надежным способом определения размеров
области просмотра будет использование уже созданного
эĸземпляра IntersectionObserver  (посĸольĸу ""он уже
рассчитал"" их для себя) для вычисления rootMargin  для
другого эĸземпляра. Таĸим образом, мы имеем дело с тем же
источниĸом истины и теми же единицами независимо от
масштабирования.
Альтернативный подход (Когда можно обойтись и вовсе без
наблюдателя?)
Я не мог заĸончить, не упомянув этот заĸовыристый подход. Если
вам нужно ""приĸрутить"" один элемент ĸ другому (целевому
элементу) без использования ĸаĸого-либо наблюдения за
изменением положения, вы можете обернуть элемент во
вспомогательный ĸонтейнер с шириной и высотой, равными 0,
чтобы он не мешал естественному потоĸу доĸумента. Поместите
этот ĸонтейнер нулевого размера в родительсĸий ĸонтейнер
целевого элемента, прямо рядом с целевым элементом,
используя:
  { root: document },
);
const longDiv = document.createElement('div');
longDiv.style.width = `${20000}px`;
longDiv.style.height = `${10}px`;
longDiv.style.position = 'absolute';
document.body.appendChild(longDiv);
obs.observe(document.documentElement);
// initial viewport rect
const viewportRect = await new Promise(res => {
  const observer = new IntersectionObserver(
    entries => {
      res(entries[0].rootBounds);
      observer.unobserve(document.documentElement);
    },
    { root: document },
  );
  observer.observe(document.documentElement);
});
const { width: viewportWidth, height: viewportHeight } = vi

1
Карма
0.4
Рейтинг
Алеĸсандр Калабин @itihon
Пользователь
Комментарии
Здесь поĸа нет ни одного ĸомментария, вы можете стать первым!
Установите необходимое смещение для элемента внутри
ĸонтейнера нулевого размера и позвольте браузеру делать свое
дело.
Ограничения для этого подхода:
Если родительсĸий ĸонтейнер целевого элемента имеет
flexbox  разметĸу с установленным gap  или justify-
content : space-between; , это создаст зазоры и пробелы
для этого ĸонтейнера нулевого размера.
И это точно поломает grid  разметĸу родительсĸого
ĸонтейнера.
Эти ограничения собственно и послужили причиной того, что я
начал этот небольшой проеĸт.
Теги: scroll, resize, position, observer, intersectionobserver
Хабы: JavaScript
target.insertAdjacentElement('afterend', zeroSizedContainer
Отправить
Ваш ĸомментарий
Нажмите ""/"" для вызова меню
Подписаться

Публикации
Eclips4 15 часов назад
Как я стал core-разработчиком Python в 19 лет
5 мин
DimDimDimDimDim 21 час назад
Рассказываем об апдейтах за март: месяц
бесплатного S3, настройка IOPS и не только
5 мин
AfanasevaT 17 часов назад
Инструменты CDN: шесть способов остановить
накрутку трафика на сайт
5 мин
Lunathecat 20 часов назад
Котогитара одичала
8 мин
Albert_Wesker 21 час назад
Собираем и запускаем минимальное ядро Linux
Сложный
9 мин
ЛУЧШИЕ ЗА СУТКИ
ПОХОЖИЕ
11K
Кейс
Сезон Open source
+108
49
16 +16
2.7K
+23
3
3 +3
1.5K
+22
7
0
1.4K
Кейс
+20
6
6 +6
4.7K
Туториал
Перевод
+20
79
5 +5

rajce 14 часов назад
Криптовалюта в России: Куда бежать выводить
рубли после закрытия Garantex?
9 мин
tarlakovsky 18 часов назад
New Horizons вышел из спячки
Простой
1 мин
AndreyTrig 13 часов назад
Как работают поисковики: 4 точки зрения (ни
одной правильной)
Простой
6 мин
DAN_SEA 16 часов назад
Простой способ управления IoT-устройствами
через телеграм-бот, используя esp32
Средний
10 мин
Xcom-shop 19 часов назад
Вот этого поворот: NVIDIA рассказала, почему на
самом деле горят видеокарты RTX 50
4 мин
Поĸазать еще
2.4K
Обзор
+19
32
4 +4
2.5K
+19
5
4 +4
1.1K
Мнение
+18
8
0
1.7K
Обзор
+18
43
0
28K
Мнение
+18
11
110 +110

Ваш аĸĸаунт
Профиль
Треĸер
Диалоги
Настройĸи
ППА
Разделы
Статьи
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для ĸомпаний
Доĸументы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реĸлама
Нативные проеĸты
Образовательные
программы
Стартапам
Настройĸа языĸа
Техничесĸая поддержĸа
© 2006–2025, Habr"
Cloud4Y,71.07,04.05.2025,#1 Корпоративный облачный провайдер,"Взлом Instagram*‑аккаунта — популярный запрос в поисковиках. Поэтому есть смысл рассказать
о том, как это обычно работает. Просто для того, чтобы вы знали, откуда может пойти атака.
OSINT & Hacking — как работает фишинг для нельзяграма
 Простой
 3 мин
 1.1K
Блог компании Cloud4Y , Информационная безопасность *, Социальные сети и сообщества
Обзор
 Перевод
КАК СТАТЬ АВТОРОМ

Чтобы начать попытки заполучить доступ к аккаунту, вы должны знать ник человека, которого вы
пытаетесь взломать. Так что небольшая разведка будет очень кстати. Только не увлекайтесь.
Существуют различные инструменты для разведки, в первую очередь, поиск пользователя
в конкретной соцсети с целью узнать его ник. Я нашёл отличный инструмент под названием
«Slash», который можно использовать для поиска любых учётных записей пользователя, если он
везде регистрируется под одним ником.
Ставим Slash

git clone https://github.com/theahmadov/slash 
cd slash 
pip install -r requirements.txt 
python slash.py help
Я проверил Slash на себе, и посмотрите на эти результаты. Некоторые из учетных записей,
перечисленных здесь, были созданы много лет назад.

Slash — это простой консольный инструмент. Но вы также можете использовать такие
инструменты, как WhatsMyName Web, который совершенно бесплатен.
Вот, посмотрите. Я проверил WhatsMyName на себе. Мой ник «earthtoyash».

Теперь, когда мы знаем больше о нашем пользователе, можно использовать эти знания.

Например, через отправку фишинговых ссылок. Для этого создадим полезную нагрузку с помощью
Zphisher.
Ставим Zphisher с GitHub
Клонируем репозиторий:
git clone --depth=1 https://github.com/htr-tech/zphisher.git
Запускаем файл zphisher.sh:
cd zphisher && ./zphisher.sh
При первом запуске он установит зависимости и на этом всё. Система скажет, что Zphisher
установлен. После установки вам нужно будет снова запустить zphisher.sh в каталоге zphisher
командой ./zphisher , и тогда вы получите что-то вроде этого:

Как вы можете видеть, есть много вариантов и шаблонов, благодаря чему любой может
заниматься фишингом. Мы сосредоточимся на нельзяграме. Итак, введите «2» и нажмите Enter.

Следующий шаг полностью зависит от вас, выберите любой из них.
Затем появится окно с выбором. Я выбрал третий вариант, так как он минималистичный и удобен
для того, чтобы показать возможности инструмента.

Опять же, чтобы все было просто, я пропущу пользовательский порт, но если вы уже используете
порт 8080, то можете изменить его на 8000. Если нет, оставляйте всё как есть. Также важно
маскировать URL, ну просто в целях безопасности. Можно использовать что‑то вроде этого:

Всё, Zphisher создал фишинговую ссылку, которую можно отправить жертве. Как только она
нажмёт на ссылку, вы начнёте получать информацию о ней. Например, IP‑адреса, имена
пользователей, пароли и т. д. Ещё можно использовать обратный поиск IP, чтобы определить
местоположение вашей цели и многое другое.
Итак, вот эти фишинговые ссылки.

При нажатии открывается страница, похожая на официальную страницу входа в запрещённую
соцсеть.

Вот она, нехорошая
После ввода учётных данных можно получить много информации на «хакерской» стороне
терминала.

Вот так, господа и дамы, можно без особого труда взломать учетную запись в нельзяграме.
Поэтому в очередной раз напоминаем: нельзя нажимать на ссылки, которым вы не доверяете.
Само собой разумеется, не используйте информацию из этой статьи с намерением причинить
кому-либо вред. OSINT законен, но фишинг и кража личных данных даже в запрещённой соцсети
является уголовным преступлением. И да, * Организация Meta, а также её продукт Instagram, на
которые мы ссылаемся в этой статье, признаны экстремистскими и запрещены на территории РФ.
Спасибо за внимание!

Cloud4Y
#1 Корпоративный облачный провайдер
Сайт
Facebook
Twitter
ВКонтакте
Telegram
Что ещё интересного есть в блоге Cloud4Y
→ Информационная безопасность и глупость: необычные примеры
→ NAS за шапку сухарей
→ Взлом Hyundai Tucson, часть 1, часть 2
→ Столетний язык программирования — какой он
→ 50 самых интересных клавиатур из частной коллекции
Теги:  взлом, соцсети, osint
Хабы:  Блог компании Cloud4Y, Информационная безопасность, 
Социальные сети и
сообщества
 0
 19
 1


149
Карма
53.5
Рейтинг
Cloud4Y @Cloud4Y
Корпоративный облачный провайдер
Сайт
ВКонтакте
Telegram
 Комментарии 1
Публикации
ЛУЧШИЕ ЗА СУТКИ
ПОХОЖИЕ



 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
И Н Ф О Р М А Ц И Я
Сайт
www.cloud4y.ru

Ваш аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Дата регистрации
29 июля 2011
Дата основания
2009
Численность
51–100 человек
Местоположение
Россия
Представитель

Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные программы
Стартапам
Мегапроекты
Настройка языка
Техническая поддержка Вернуться на старую версию
© 2006–2023, Habr"
Альфа-Банк,404.32,04.05.2025,Лучший мобильный банк по версии Markswebb,"В Альфа-Банке мы внедрили ИИ-агентов, которые проектируют, разрабатывают и проверяют
автотесты. При этом полностью автономно, как QA-инженеры, но в разы быстрее и точнее.
Подобных примеров, когда ИИ разрабатывает автотесты от анализа требований до пул-реквеста,
в нашей стране, пожалуй, ещё не было.
Что умеют агенты?
Анализировать контекст из Jira и Confluence, вычленяя суть задачи.
Прогнозировать риски, зависимости и даже «пограничные» сценарии.
Генерировать DTO для REST API и превращать ручные сценарии в Java-тесты за минуты.
Сверять код с бизнес-логикой и техстандартами Альфы, защищая прод от случайных
ошибок.
Создавать вариативные проверки — от позитивных кейсов до сложных негативных условий.
Автоматизировать рутину.
В ИИ-команде QA есть несколько агентов, каждый работает над своей частью из перечная выше.
Сейчас решение пилотируется в нескольких продуктовых командах, но результаты уже видны:
ИИ-агенты в Альфа-Банке: нейросети создают автотесты без
участия человека
1 мин
717
Блог компании Альфа-Банк, Искусственный интеллект, Тестирование IT-систем*
Войти
Моя
лента
Все
потоки Разработка Администрирование Дизайн Менеджмент Маркетинг Научпоп
КАК СТАТЬ АВТОРОМ
Зарплаты айтишников
Миграция за ночь? Легко! Без сна и с адре…

Альфа-Банк
Лучший мобильный банк по версии Markswebb
Сайт
Хабр Карьера
14
Карма
0.3
Рейтинг
@AlfaTeam
Пользователь
Сайт
Facebook
ВКонтакте
Другие новости
mefdayy 19 минут назад
Nvidia и Broadcom тестируют передовой процесс производства чипов
Intel
2 мин
меньше ошибок в проде, предсказуемые дедлайны и высвобожденные ресурсы для творческих
задач.
«Одна команда ИИ-агентов экономит десятки часов работы, увеличивает скорость релизов и
находит на 30% больше багов»
Святослав Соловьев, Директор по генеративному ИИ в ИТ Альфа-Банка.
В ближайшее время подробнее опишем как устроены агенты, какие технологии используем и как
мы измеряем их эффективность.
Теги: автоматизация, искусственный интеллект, тестирование, автотесты
Хабы: Блог компании Альфа-Банк, Искусственный интеллект, Тестирование IT-систем
Редакторский дайджест
Присылаем лучшие статьи раз в месяц
Электропочта
Комментарии 11
123
Подписаться"
2,5.0,04.05.2025,Рейтинг,"Data Science сейчас во многом благодаря активному маркетингу
становится очень популярной темой. Быть датасаентистом – модно
и, как говорят многие рекламки, которые часто попадаются на глаза,
не так уж и сложно. Ходят слухи, что работодатели стоят в очереди
Простой9 мин
TourmalineCore
Почему Data Science не для вас?
2.1K
Big Data*
, 
Data Engineering*
Мнение
КАК СТАТЬ АВТОРОМ

за возможность взять человека с курсов. Получить оффер на работу
крайне легко, ведь в ваши обязанности будет входить требование
данных от заказчика (как обычно говорят, чем больше данных – тем
лучше) и закидывать их в искусственный интеллект, который
работает по принципу черного ящика. Кстати, еще и платят
немереное количество денег за всё это. 
Спойлер: это не так.
В этой душераздирающей статье решили попробовать отговорить
людей, которые готовы оставить кучу денег за курсы по Data Science,
браться за это дело, а может быть и помочь определиться с тем, что
на самом деле стоит сделать, чтобы встать на путь истинный.
Обзор понятий
И начнем, пожалуй, с того, что может быть вам и не очень-то нужно
быть датасаентистом. Есть много направлений, поди попробуй
разберись. Датасаентист, дата аналитик, дата инженер… Часто
бывает, что всех этих людей гребут под одну гребенку, и совсем не
разделяют их обязанностей. Разберемся, что это за звери такие и с
чем их едят. 
Дата аналитики обычно заняты тем, что получают данные и
пытаются найти в них закономерности. Эти люди отвечают на
вопросы бизнеса: что, почему, как, как сделать лучше, а еще вот
можете на график посмотреть. Аналитики чаще контактируют с
другими людьми: чтобы выстроить правильную коммуникацию в
команде и правильно описать и презентовать результаты своего
анализа. Ваши друзья здесь: мат.статистика, python/R, SQL,
платформы типа PowerBI/Tableau/Qlik и прочее необходимое для
визуализации результатов. Также необходимо глубокое понимание
области, в которой вы проводите анализ.
Дата инженеры же заняты поставкой данных и их хранением. Эти
люди настраивают хранилища, заставляют данные сопоставляться
между собой и быть пригодными к использованию. Создание
пайплайна обработки и архитектуры данных  – вот их задача. 

Датасаентисты – более расплывчатое понятие. Сначала они
анализируют данные, на которых дальше строится предобработка. В
предобработку входит очистка от выбросов, заполнение
пропущенных значений, трансформация, нормализация и еще куча
всякого разного. И после всего этого датасаентисты  обучают
модели, которые будут давать какой-то предикт. От этих ребят нужен
тот самый «искусственный интеллект» (кстати, стоит убрать из
своего лексикона эти слова на собеседовании, расскажем дальше,
почему). Здесь надо знать и уметь в машин и дип лёрнинг, опять таки
уметь в матстат и обработку того, что вы видите, понимать
предметную область, уметь продумать, какие данные нужны для
обучения и составить ТЗ по их сбору. Будет большим плюсом
понимание того, на каких машинах модели, которые вы собираетесь
обучать, будут запускаться. 
Хороший доклад на тему того, чем заняты разные люди из разных
ветвлений размытого понятия data scientist, есть по ссылке.
У описанных направлений совершенно разные ключевые навыки и
компетенции. Чем больше компания, тем вероятнее, что в ней есть
разделение на эти направления. Но если вы с курсов решили
устроиться в стартап, где есть биг дата, но особо нет людей на эту
биг дату, тогда вашим ключевым навыком должно быть умение
выживать. Именно здесь обычно нужен Data Scientist, который на все
руки мастер. Готовы ли вы к этому?
Почему всё-таки Data Science не для вас?
1. Data Science – для усидчивых. Над одной и той же задачей
придется сидеть очень долго. Пока найдешь все необходимое в
данных, пока найдешь оптимальный способ обработки данных,
пока погрузишься в область, пока переберешь все модельки,
которые могут потенциально хорошо решить эту задачу… А еще
надо дождаться, пока модель обучится - это ж целая вечность
пройдет! Потом еще выясняется, что у модели метрики
недостаточно хорошие, и весь этот путь нужно пройти заново, но

с новыми идеями. 
Хватит ли вам умения занять себя другими делами во время
обучения модели? Вряд ли проджект будет в восторге, если
узнает, что несколько дней вы пили кофе, пока модель
обучалась. Хватит ли вам терпения перебирать идеи до тех пор,
пока точность модели не достигнет нужного бизнесу числа?
2. Математика останавливается не на 2+2 и даже не на
интегралах. Вам точно понадобятся знания по мат.статистике,
линейной алгебре, теории вероятностей. Нет, вам не хватит
встроенных в библиотечки функций. Может быть для какого-то
поверхностного анализа и составления простецкой модели – да,
Но чтобы лучше анализировать огромные массивы данных, в
математике действительно нужно разбираться.
3. Вам нужно знать Python/R/Scala или еще что-то, на чем вы
соберете ваше решение. Вы не бэкенд-разработчик, но вам
нужно приготовить умную штуку, которую можно будет встроить в
прод. Нужно будет составлять POC-шки, функции предобработки
данных, которые затем будет имплементировать бэкенд-разраб.
Необходимо уметь общаться с бэкендерами на их языке, если
им понадобится помощь при внедрении вашего решения.
4. Еще немного о встраивании модели в прод: вам нужно
интересоваться тем, на каком железе будет запущена модель.
Ну не получится запустить трансформер на сервачке заказчика с
двумя ядрами и без малейшего признака GPU. А решение,
которое работает на вашем компе и не работает на устройствах
клиента не будет принято и, соответственно, оплачено.
5. Нужно знать фреймворки, которые приняты в команде. Если вы
до этого делали fit на керасе, а потом внезапно пришли в
команду, которая работает на pytorch, уйдет много времени на
обучение работе с новыми инструментами.
Справедливости ради, вряд ли вас возьмут на работу со стеком,
в котором у вас нет опыта, но на всякий случай лучше задавать
этот вопрос на первых этапах собеседования.

6. По ходу проектирования решения нужно будет использовать
огромное количество, библиотек и лучше знать как ими
пользоваться до начала работы над проектом. Или же уметь
быстро ориентироваться в документации, а в процессе только
добирать необходимое. Обучаться всему и сразу плохая идея.
8. Вам нужно уметь использовать тулзины, которые тесно связаны
с разработкой моделей. Модели и данные нуждаются в
версионировании. В этом могут помочь DVC, MLflow или,
например, Weights&Biases. А еще модели нужно сервить. В этом
случае могут быть пригодны TorchServe или Tensorflow Serving. А
может быть вам нужно будет написать свою обвязку вокруг
модели, чтобы ее можно было быстро потестить. Этот зоопарк
огромен. Нужно выбрать из него именно те вещи, которые вам
помогут, и учиться ими пользоваться.
9. Нужно уметь не только чистить данные, но и размечать их, когда
вам не дали нормальной разметки, искать, какие данные можно
добавить к выданному заказчиком датасету, если его явно не
хватает.

10. Важной частью вашей работы будет общение с бизнесом для
того, чтобы точно определить цель того, что вы делаете, и не
сделать того, что не нужно. Иногда заказчики дают расплывчатое
ТЗ, внимательно вчитываясь в которое вы обнаружите, что
заказчик хочет всё и сразу, но при этом непонятно зачем.
Поэтому нужно будет суметь задать такие вопросы, которые
прояснят, что действительно требуется от вас, или суметь
сократить скоуп работ до реально реализуемого.
11. Если проджект где-то там пообещал нереальные сроки для
выполнения вашей задачи, нужно вовремя суметь сказать, что
пятилетку за три года – не получится. Нельзя просто так взять и
выстроить радужные мечты вокруг того, как быстро вы сможете
сделать задачу. А с вас точно потребуют сроки, в которые будет
необходимо уложиться.
Вопрос оценки времени на реализацию – очень сложен. Здесь
важно не только правильно декомпозировать задачу, но и
добиться понимания от вышестоящих людей, почему эта задача
не может быть реализована в очень сжатые сроки. Так что
составляем план, и его придерживаемся. А если что-то выходит
из-под контроля срочно трубим о том, что ничего не успевается и
с этим надо что-то делать.
12. А еще вам самим придется составлять ТЗ по данным, которые
вы хотите получить. Из нашего опыта, чаще приходят заказчики,
которые не понимают, что вам от них нужно и в каком объеме.
Будьте готовы отвечать на вопрос сколько и каких данных вам
надо, вникать в задачу на этапе обсуждения проекта и
предполагать, какие кейсы могут возникать в вашей задаче.
Также количество размеченных данных, следует запрашивать в
таком объеме, который сможет удовлетворить заказчика. Если
вы потребуете терабайты размеченных данных, а другой
исполнитель скажет, что ему хватит пары гигов, то выберут
скорее его, а не вас, просто потому что разметка данных стоит
немалых денег. А ответ «чем данных больше – тем лучше»
никого не устроит.

13. Data Science – не только про генерацию красивых картинок и
красивой музыки без помощи человека. Частый запрос бизнеса
– проанализировать информацию о клиентах. Из этой бизнес-
задачи может вытекать DS-задача, которая вам не понравится.
Например, выстроить контекстную рекламу так, чтобы новые
покупатели приобрели товар подороже, или завысить цену
продукта в соответствии с предполагаемым уровнем дохода
покупателя. Будет ли такая задача вписываться в ваши
моральные рамки? Возможно, у вас будет опция отказаться от
задач, которые не подходят вашему пониманию хорошо-
плохо.Но бывает и так, что вас не спрашивают. Конечно, вопрос,
стоит ли работать с компанией с которой у вас разное
понимание границ не в плоскости data science, а скорее в
общем. Но будьте готовы к тому, что в data science часто встает
вопрос этики использования данных, и эта этика зафиксирована
в достаточно размытом формате.
Вы можете сказать, что на самом деле многие навыки из этого
списка входят в программу популярных курсов. Да, это так. Но дадут
ли вам необходимое количество разнородных задач, которые
присутствуют в реальном мире? Насколько смешанные, странные и
неполные данные будут присутствовать в этих задачах? Требования
от заказчиков в реальном мире будут сильно сложнее, чем обычно
определяют на курсах. На курсах вам создадут рафинированную
среду, в которой все понятно, четко и ясно определено в
требованиях и точно опирается на предыдущий опыт из лекций. К
сожалению, на работе будет не так. Придётся ловить на лету и
определять, как действовать, очень быстро. Так что наше мнение:
пойти на курсы, чтобы стать датасаентистом, недостаточно. 
Иметь высшее образование, кстати, тоже. Знаем, бывали. Даже если
ваша вышка с уклоном в дата саенс, по факту, она часто дает не
сильно больше курсов. Не спорим, есть разные университеты, но, по
нашему опыту, вам там дадут примерно такую же базу, как и на
курсах, только чуть более разностороннюю (и то не факт). Но все-
таки, это обучение длится подольше, и скорее всего, информации вы
впитаете побольше. Еще и курсы по философии и экологии
подкинут :)

Важное качество в профессии датасаентиста – способность
постоянно учиться, находить для себя новые задачи и расти на этом
практическом опыте. А еще постоянно следить за событиями в
сфере, потому что кажется, что она обновляется чаще и
кардинальнее, чем другие сферы IT. Поэтому специализированные
курсы – это хорошо, высшее образование – тоже, но важно
понимать, что это ещё далеко не всё, это только начало длинного и
тяжелого пути.
Cекция ""вопрос-ответ"" в лучших традициях пиар-
страниц курсов
1. Датасаенс – это весело?
Конечно! Но только если вы действительно упороты и любите искать
что-то странное и копаться в куче данных, чтобы в итоге делать
штуку, которая будет помогать бизнесу в реальных задачах с
большой точностью. Но будьте готовы и к не самым веселым
моментам: на этом самурайском пути много препятствий. В каком-то

смысле, датасаенс – это образ жизни, при котором нужно всегда
держать руку на пульсе и интересоваться происходящим в области.
Став датасаентистом однажды, больше уже не сможешь смотреть на
все эти умные штуки как на абсолютную магию.
2. Я математик по образованию и по желанию и очень хочу в DS.
Получится?
Отличная база. Математика как основа – это очень хорошо. Но вам
еще очень многое придется освоить. Удачи вам в этом нелегком
пути!
3. А я вот из программиста решил переквалифицироваться в
датасаентиста, каковы шансы?
Вам будет тяжело. Шанс есть всегда, но это будет очень сложный
путь. На нашем опыте, понять программирование для человека с
математическим бэкграундом проще, чем программисту математику.
Мы все проходили курс по высшей математике в универе и помним
матешу со школы, но это не тот уровень, который будет требоваться

на месте работы.
4. А почему вы говорите, что искусственного интеллекта сейчас не
существует?
Искусственный интеллект – интересное понятие. Этим термином
внезапно стало принято называть всё, что может делать что-то за
человека. Но до «интеллекта» там далеко. Да данный момент то, что
мы называем ИИ, это алгоритмы, которые могут решать
узконаправленную задачу. Распознавание лиц? Детекция объектов?
Генерация контекстной рекламы? Интеллектуальный анализ
данных? Все это узконаправленные сферы. Разве мы можем назвать
калькулятор искусственным интеллектом? Ну, это вряд ли. Хотя он
также решает узконаправленную задачу – решение математических
уравнений. А пару столетий назад это казалось задачей
искусственного интеллекта. В целом, можно сказать, что ИИ
существует, но в очень примитивном виде. Его эволюцию можно
сравнить в эволюцией человека. На ранних стадиях задачи человека
также были узконаправленными и примитивными, но человек
эволюционировал. Так же можно предположить и с ИИ, он может
эволюционировать. И не обязательно базой для «прогрессивного
ИИ» будут нейронные сети.

Подведем итоги
• Data Science – это профессия с высоким порогом входа. Нужно
многое знать, нужно многое уметь. Если вы хотите в IT, и вам
кто-то сказал, что через дата саенс это сделать проще, чем
через другие профессии, то не слушайте этого человека.
Обратите внимание на другие возможные варианты входа в IT,
например, верстку или ручное тестирование. 
• Data Science – это не только про построить предсказывающую
модель в jupyter-notebook и отдать ее дальше. Скорее всего, вам
придется делать сильно больше этого функционала.
• В работе с данными есть разные ветвления профессий,
например, инженер данных или аналитик данных. Для них
требуются иные навыки. Может быть, если ваше желание
именно работать с данными, вам стоит посмотреть на эти
специализации.

Пользователь
Комментарии 5
Публикации
• Data Science – про постоянное обучение и слежение за новыми
разработками в этой сфере. Держать руку на пульсе – это один
из ключевых навыков датасаентиста.
• Курсов, на которых вам за несколько месяцев дают всё
необходимое для профессии – не существует. Вам могут дать
базу, но стоит ли эта база тех денег, которые за нее просят, это
спорный вопрос.
• Есть множество курсов по DS, которые находятся в открытом
доступе абсолютно бесплатно, и дают примерно тот же
материал, что и дорогостоящие. А практические задачи можно
найти на kaggle. Кстати, там же есть и решения других людей,
которые могут вам помочь обучиться и понять, как же все-таки
делать лучше. Рассмотрите этот вариант. Возможно, в будущем
мы сделаем статью-сборник с такими материалами, а пока
посоветуем отличный ресурс для начала обучения.
Теги:  
ML
,
data science
,
курсы
,
курсы data science
,
machine-learning
Хабы:  
Big Data
,
Data Engineering
+2
19
5

ЛУЧШИЕ ЗА СУТКИ 
ПОХОЖИЕ


 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 

ИСТОРИИ

РАБОТА

Ваш
аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Data Scientist
131 вакансия
Все вакансии

Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
КАК СТАТЬ АВТОРОМ,419.0,04.05.2025,Зарплаты айтишников,"Еще до начала MWC в Барселоне было очевидно, что хотя бы один оператор представит
амбициозный проект по созданию смартфона совместно с ведущей AI-компанией. И вот он:
Deutsche Telekom (DT) сообщает, что готовит «AI Phone» — недорогой аппарат, разработанный в
тесном сотрудничестве с Perplexity, а также Picsart и другими партнерами, и дополняет его новым
приложением-ассистентом под названием «Magenta AI».
DT планирует представить устройство во второй половине этого года, а продавать его начнет в
2026-м по цене менее 1 000 долларов. Как уточнил представитель компании, в первую очередь
модель будет ориентирована на европейский рынок.
Deutsche Telekom и Perplexity объявили о новом «AI Phone»
стоимостью менее 1 000 долларов
4 мин

«Мы становимся AI-компанией», — заявила на пресс-конференции в понедельник член
правления DT, отвечающая за технологии и инновации, Клаудия Немат. При этом она добавила,
что оператор не создает фундаментальные большие языковые модели, а разрабатывает «AI-
агентов».
Примечательно, что Perplexity, стартап из Кремниевой долины, который, по слухам, уже
оценивается примерно в 9 миллиардов долларов, отводится ключевая роль в создании
смартфона. Это показывает, что компания, прежде всего известная благодаря генеративному AI-
поисковику, делает шаг к созданию более «проактивных» решений.
«Perplexity переходит от простой “машины ответов” к “машине действий”, — отметил
сооснователь и генеральный директор Perplexity Аравинд Шринивас на сцене мероприятия. —
Теперь мы не просто отвечаем на вопросы, но и можем бронировать рейсы, столики в
ресторанах, отправлять письма, сообщения, совершать звонки и многое другое, включая
установку умных напоминаний».
Хотя это, по всей видимости, первая крупная сделка Perplexity с оператором связи для
разработки AI-интерфейса смартфона, компания уже имеет некоторый опыт в сфере
помощников: в январе Perplexity выпустила Android-приложение, которое, судя по всему, может
служить прообразом нового «AI Phone».
Эта новость — очередная глава знакомой истории из мира телекоммуникаций. Долгие годы как
мобильные, так и проводные операторы искали пути усилить позиции в конкурентной борьбе с
технологическими гигантами.
В частности, они пытались соперничать с Apple и Google, чьи операционные системы и
смартфоны в значительной степени отодвигают операторов на периферию, лишая их
существенной доли прибыли от приложений и прямого взаимодействия с пользователями. За эти
Войти
Моя
лента
Все
потоки Разработка Администрирование Дизайн Менеджмент Маркетинг Научпоп

годы были попытки объединиться, к примеру, с Mozilla для создания «операторского» смартфона,
который смог бы конкурировать с этими двумя компаниями (телефон под названием Firephone,
впрочем, так и не нашел отклика). Были и «теплые» отношения с Facebook, стремившейся
укрепить собственные позиции в мобильном мире (ныне Meta переключила усилия на другие
направления в сфере оборудования и сетей).
Подход «двигаться быстро и ломать все на своем пути» не слишком близок консервативным
телекомам. Perplexity и Deutsche Telekom сотрудничают уже с апреля 2024 года, а впервые о «AI
Phone» DT заговорила год назад на предыдущем Mobile World Congress.
Немат не раскрыла подробностей о технических характеристиках и производителе нового
девайса, а также не уточнила, на какой операционной системе он будет работать (на
презентационных рендерах можно заметить явные черты Android). Представитель DT сообщил,
что эта информация появится во второй половине года.
Известно лишь, что в смартфон будет глубоко интегрирован AI, созданный с участием Perplexity,
чтобы, по словам Немат, «пользователь получил весь спектр возможностей». Она подчеркнула,
что AI будет работать прямо с экрана блокировки.
Кроме Perplexity, в создании телефона принимают участие Google Cloud, ElevenLabs и Picsart,
сообщили в DT.
Приложение Magenta AI, являющееся самостоятельной версией голосового помощника от DT,
будет доступно для установки на любые Android- и iOS-устройства, но только для 300 миллионов
клиентов оператора, добавила Немат.
Стремясь использовать нынешний всеобщий интерес к искусственному интеллекту — главную
тему MWC этого года, — DT в очередной раз пытается закрепиться в сфере «якорного»
оборудования, предлагая и приложение для тех, кто не хочет или не может купить фирменный
смартфон.
Perplexity же конкурирует не только с хорошо финансируемыми OpenAI и Anthropic, но и с такими
гигантами, как Google, уже внедрившей свою модель Gemini во все основные продукты поиска.
Выход на рынок «машин действий» в сотрудничестве с крупным оператором связи дает компании
определенное преимущество, пусть и временное.
Теперь Perplexity, похоже, переходит к следующему этапу эволюции, чтобы предоставить
пользователям еще более удобные AI-инструменты.
«Раньше для решения этих задач нужно было по отдельности осваивать разные приложения, —
говорит Аравинд Шринивас. — Теперь все станет проще, и вы сможете сосредоточиться на более
важных делах. Это действительно следующий виток развития, где AI перестанет быть чисто
реактивным и превратится в неотъемлемую функцию вашего смартфона, которая всегда на связи
и готова помогать проактивно».
Пока не ясно, смогут ли DT и Perplexity добиться успеха в сложном рынке смартфонов, где
доминируют считаные игроки, а крупные корпорации вроде LG в итоге полностью ушли из этой
сферы.

17
Карма
4.4
Рейтинг
Технократия @technokratiya
ИТ-Компания
Сайт
Сайт
Тем не менее это свидетельствует о том, насколько силен «притягательный эффект» AI сегодня,
как даже давние игроки видят в нем спасительное решение, а передовые стартапы —
возможность укрепить свои позиции на фоне жесткой конкуренции.
Источник: TechCrunch
Чтобы не пропустить анонс новых материалов подпишитесь на «Голос Технократии» — мы
регулярно рассказываем о новостях про AI, LLM и RAG, а также делимся полезными
мастридами и актуальными событиями.
Теги: смартфоны, ии, искусственный интеллект, мобильные телефоны, ai, artificial intelligence, 
perplexity, deutsche telekom
Хабы: Искусственный интеллект, Смартфоны
Редакторский дайджест
Присылаем лучшие статьи раз в месяц
Электропочта
Подписаться"
ЧИТАЮТ СЕЙЧАС,26.0,04.05.2025,Как мы перенесли производство из,"10 апреля 2025 года состоялся релиз отĸрытого проеĸта Gzip
1.14 — популярной утилиты сжатия и восстановления (распаĸовĸи)
файлов, использующей алгоритм Deflate. Самое примечательное:
«gzip -d» на 40% быстрее на процессорах x86_64 с поддержĸой
pclmul. Почему? Потому что оĸоло половины времени тратится
на вычисление ĸонтрольной суммы CRC, и этот ĸод теперь
намного эффеĸтивнее. Даже на 10-летних процессорах
без поддержĸи pclmul он ~20% быстрее.
Проеĸт Gzip находится в разработĸе более 16 лет. Версия Gzip
1.14 готовилась почти два года. В ней были исправлены ранее
обнаруженные ошибĸи и баги. Изменения (58 ĸоммитов) в ĸод
проеĸта внесли и отработали семь мейнтейнеров проеĸта.
Релиз Gzip 1.14
1 мин
косяков
РКН рекомендует владельцам частных
виртуальных сетей отказаться при
передаче данных от иностранных
протоколов шифрования
Вот этого поворот: NVIDIA рассказала,
почему на самом деле горят
видеокарты RTX 50
Как я стал core-разработчиком Python
в 19 лет
Мнение: рекомендация РКН — мера
для мониторинга и определения
количества пользователей
74K
140 +140
26K
54 +54
28K
110 +110
10K
14 +14
Моя
лента
Все
потоĸи
Разработĸа
Администрирование
Дизайн
Менеджмент
Марĸетинг
Научпоп
КАК СТАТЬ АВТОРОМ

903
Карма
619.4
Рейтинг
Денис @denis-19
Информационная служба Хабра
Telegram
Комментарии
Здесь поĸа нет ни одного ĸомментария, вы можете стать первым!
Другие новости
dilnaz_04 31 минуту назад
Наиболее заметное в Gzip 1.14 обновление для пользователей:
утилита обеспечивает более высоĸую производительность
распаĸовĸи на процессорах Intel и AMD x86_64: «gzip теперь
распаĸовывает значительно быстрее, вычисляя CRC с помощью
алгоритма slice by 8, и ещё быстрее на платформах x86-64,
ĸоторые поддерживают инструĸции pclmul». PCLMUL существует
со времён Intel Westmere или со стороны AMD со времён Bulldozer.
Таĸ что, по сути, если ПК на Intel/AMD Linux находится в пределах
последнего десятилетия или полутора десятилетий, то, сĸорее
всего, он будет иметь поддержĸу PCLMUL для боле быстрой
отработĸи Carry-Less Multiplication Quadword.
Теги: Gzip 1.14, Gzip
Хабы: Open source, Разработĸа под Linux, Софт, Алгоритмы, Веб-
разработĸа
зарубежных протоколов шифрования
1.1K
1 +1
Отправить
Ваш ĸомментарий
Нажмите ""/"" для вызова меню
Подписаться

Исследование Microsoft показывает, что модели
AI по-прежнему испытывают трудности с
отладкой программного обеспечения
3 мин
dilnaz_04 32 минуты назад
Институт Аллена запускает OLMoTrace:
инструмент для отслеживания источников
ответов языковых моделей в обучающих данных
2 мин
TimurTukaev 1 час назад
Обновления платформы Cozystack 0.24−0.29:
провиженинг нод по PXE, мониторинг RTT между
ДЦ и выделенные IP-адреса для VM
4 мин
denis-19 2 часа назад
Мнение: рекомендация РКН — мера для
мониторинга и определения количества
пользователей зарубежных протоколов
шифрования
3 мин
daniilshat 5 часов назад
На ЦКАД запустили тестовое движение
беспилотных грузовиков
1 мин
daniilshat 6 часов назад
92
0
0
0
27
0
0
1 +1
100
0
0
0
1.1K
+2
1
1 +1
804
+6
0
4 +4

Аналитики: если Apple перенесёт производство в
США, то iPhone будет стоить около 3,5 тыс.
долларов
1 мин
darya_kiwi 7 часов назад
Обновление для Microsoft Ofﬁce 2016 сломало
Outlook, Word и Excel: выпущено исправление
1 мин
Lexx_Nimofff 8 часов назад
Вышло обновление платформы «Аврора Центр»
5.2.0
2 мин
Lexx_Nimofff 9 часов назад
Cloud.ru разрабатывает гибридное облако с AI-
инструментами
2 мин
dilnaz_04 9 часов назад
Стартап LiveKit получает $45 млн на развитие
облачной платформы для потоковой передачи
мультимедиа
2 мин
Поĸазать еще
1.5K
+1
0
7 +7
970
+6
3
1 +1
428
+6
1
0
311
+6
1
1 +1
198
+1
0
0
Ваш аĸĸаунт
Разделы
Информация
Услуги

Профиль
Треĸер
Диалоги
Настройĸи
ППА
Статьи
Новости
Хабы
Компании
Авторы
Песочница
Устройство сайта
Для авторов
Для ĸомпаний
Доĸументы
Соглашение
Конфиденциальность
Корпоративный блог
Медийная реĸлама
Нативные проеĸты
Образовательные
программы
Стартапам
Настройĸа языĸа
Техничесĸая поддержĸа
© 2006–2025, Habr"
RUVDS.com,2394.92,20.03.2025,VDS/VPS-хостинг. Скидка 15% по коду HABR15,"образов этих дисков остаётся актуальным. Многие операционные системы поставляются в
виде ISO-образов, а администраторам необходимо поддерживать разношёрстный парк
старых персональных компьютеров.
artyomsoft
Как создать аппаратный эмулятор CD-ROM без паяльника
Средний
19 мин
9.2K
Блог компании RUVDS.com, Системное администрирование*, Разработка под Linux*, Разработка на Raspberry Pi*, 
КАК СТАТЬ АВТОРОМ
Вызовы для k8s. Чего ждать операторам в будущем

Существует множество решений, как можно установить операционную систему с ISO-
образа без записи его на оптический носитель. Я уже затрагивал тему ISO-образов в моих
статьях: «Раскрываем секреты загрузочных ISO-образов» и «Что вам нужно знать о
внешних загрузочных дисках».
В этой статье я хочу рассказать о ещё одном способе, который, как оказывается, вшит в
ядро Linux. Если ваш одноплатный компьютер имеет USB OTG-разъём, и на него
возможна установка Linux, то вы c большой долей вероятности можете сделать из
одноплатника аппаратный эмулятор привода оптических дисков.
Меня этот способ заинтересовал. Я проверил его сам и, получив положительный результат
у себя, решил поделиться с вами.
Я сам узнал много интересного, систематизировал свои знания, поэтому надеюсь, что
чтение будет познавательно и интересно для вас.
Как всегда, если вы хотите посмотреть, что получится в итоге, уточнить детали, вы всегда
можете найти исходный код в моём репозитории на GitHub.
При написании статьи я поставил себе следующие цели:
1. Аппаратный эмулятор CD-ROM должен быть реализован без использования
паяльника и макетных плат.
2. Реализация должна быть понятна человеку, имеющему лишь базовые представления
о Linux, USB и Bluetooth.
3. Решение должно быть таким, чтобы его можно было с небольшими изменениями
реализовать на различных одноплатных компьютерах.
4. Побудить интерес читателя к изучению используемых в статье технологий.
5. Изложить материал, необходимый для решения задачи лаконично и просто. Не
уверен, что у меня это получилось из-за большого объёма темы. Буду признателен,
если вы в отзывах напишете своё мнение.
Оглавление
Суть решения
Проверка решения на практике
От проверки идеи до реализации

Операционная система Linux
USB
Bluetooth
Сборка и модификация дистрибутива Raspberry Pi OS
Реализация
Как пользоваться эмулятором
Особенности моего эмулятора
Выводы
Суть решения
Решение заключается в том, что, модифицируя операционную систему Linux на
одноплатном компьютере (встраиваемой системе), можно получить из него устройство,
которое будет распознаваться компьютером как внешний оптический привод USB или
флеш-накопитель.
В ядро Linux включена поддержка эмуляции CD-ROM и эмуляции флеш-накопителя. Но
это не значит, что любую встраиваемую систему можно превратить в них. Для этого ещё
необходимо, чтобы встраиваемая система имела USB OTG-контроллер или USB-
контроллер периферийного устройства.
Проверка решения на практике
Я делал эмулятор оптических дисков, используя Raspberry Pi Zero 2 W. Но вы можете
использовать и другие одноплатные компьютеры. Естественно, вам тогда придётся самим
разбираться с некоторыми проблемами, которые с большой долей вероятностью у вас
возникнут. У меня других одноплатных компьютеров кроме Raspberry Pi не было, поэтому
привожу алгоритм, как делал я.
1. Скачать образ Raspberry OS Light с сайта raspberrypi.org.
2. Записать образ на SD-карту. Я использовал программу balenaEtcher.
3. Добавить строку dtoverlay=dwc2  в файле config.txt на SD-карте.
4. Записать файлы ssh и wpa_supplicant.conf на SD-карту. Файл userconf.txt нужен, чтобы
установить пароль для пользователя, ssh — чтобы включить SSH, wpa_supplicant.conf
— чтобы указать точку доступа и пароль для Wi-Fi.
5. Вставить SD-карту в Raspberry Pi Zero 2 W.
6. Подключить USB-разъём Raspberry Pi Zero 2 W к USB-разъёму компьютера.

7. Подождать, пока выполнится первая загрузка и Raspberry Pi Zero 2 W подключится к
Wi-Fi-сети.
8. Найти IP-адрес Raspberry Pi Zero 2 W в Wi-Fi-сети и подключиться к нему по протоколу
SFTP. Я использовал приложение WinSCP.
9. Записать ISO-образы, которые вы хотите эмулировать, в файловую систему Raspberry
Pi.
10. Подключиться через SSH к Raspberry Pi W 2. Это можно сделать при помощи
приложения PuTTY.
11. Для того, чтобы ваш Raspberry Pi Zero 2 W стал внешним USB CD-ROM, ввести
команду:
$ sudo modprobe g_mass_storage cdrom=y removable=y stall=n file=/full/filename/w
После чего у вас на компьютере распознается внешний USB CD-ROM, в который
вставлен диск.
12. Для прекращения эмуляции ввести команду:
$ sudo modprobe -r g_mass_storage
Приведённый файл userconf.txt устанавливает для пользователя pi пароль «raspberry».
Файл ssh — это пустой файл, который не содержит никаких данных.
От проверки идеи до реализации
Приведённая выше последовательность шагов позволяет вам посмотреть работу
эмуляции в действии. Однако это решение обладает рядом недостатков.
1. Чтобы загрузить и выбрать образ для эмуляции, необходимо наличие Wi-Fi.
Файл userconf.txt
Файл wpa_supplicant.conf

2. При перезагрузке Raspberry Pi необходимо заново монтировать образ.
3. Если нужно эмулировать образ для загрузки с него операционной системы,
понадобится ещё один компьютер для управления Raspberry Pi.
4. Эмулировать можно образ размером максимум 2 Gib.
Если вам интересно, как избавиться от этих недостатков, у вас есть время и интерес
разобраться в этом вопросе, то предлагаю продолжить чтение.
Краткое содержание моей реализации следующее:
1. Для общения с Raspberry Pi будет использоваться Bluetooth.
2. Чтобы работа устройства была возможна в автономном режиме (без подключений Wi-
Fi и Bluetooth), управляющий скрипт оформляется в виде службы Systemd.
3. Для управления по Bluetooth будет использоваться приложение Serial Bluetooth
Terminal c Google Play.
4. Для эмуляции оптических дисков с образов размером больше 2Gib необходимо внести
небольшие изменения в модуль ядра Linux и выполнить перекомпиляцию.
Приведу кратко, что вам нужно знать, чтобы лучше понять суть того, что мы будем делать.
Операционная система Linux
▍ Ядро Linux
Ядро Linux содержит в себе абстракции для работы с устройствами там, где оно
запускается. Реализуются эти абстракции в специальных программах, называемых
драйверами. В ОС Linux драйвер может находиться непосредственно в файле ядра, а
может быть оформлен в виде отдельного модуля. В большинстве случаев предпочтителен
второй способ, так как модули можно динамически удалять и добавлять. Например, если
устройство не подключено к системе или с ним не осуществляется работа, драйвер нам не
нужен, и его можно выгрузить из памяти или не загружать вообще.
При загрузке ядра ему необходима информация об устройствах, которые присутствуют в
системе, чтобы корректно загрузить драйверы (модули) для них. Эта информация может
передаваться из различных источников. Например, в архитектуре x86 это будет ACPI. В
архитектуре ARM это Device Tree.
▍ Device Tree и Overlays

Иногда Device Tree нужно модифицировать, чтобы можно было загрузить корректно
драйвера для устройств. Делается это при помощи подключения overlays. Они содержат
информацию, что необходимо изменить в исходном Device Tree.
▍ Headless-режим работы Raspberry Pi
Очень часто в различных статьях и самоучителях по работе с Raspberry Pi необходимо
подключение монитора, клавиатуры и мыши. Но на самом деле есть возможность
работать с ним в так называемом headless-режиме. В этом режиме вы работаете с
Raspberry Pi при помощи эмулятора терминала. Соединение его с Raspberry Pi может быть
UART, USB, Bluetooth, Ethernet, Wi-Fi.
Главная сложность заключается в том, как можно работать в этом режиме с самого
начала, сразу после записи образа операционной системы на SD-карту, если у вас нет
лишнего монитора и клавиатуры. Как активировать SSH, настроить Wi-Fi на использование
определённой точки доступа?
В Raspberry Pi OS такая возможность есть. Достаточно разместить определённые файлы в
разделе FAT32 на SD-карте и загрузиться с неё. Raspberry Pi OS сделает необходимые
настройки сама.
▍ Файловые системы, блочные устройства, разделы, монтирование
Меня всегда восхищала идея, что в Linux всё является файлом. Правильно используя
средства Linux, можно практически без программирования выполнять сложные задачи.
Блочное устройство — это некоторый файл, в который можно записывать и считывать
данные блоками байтов различной длины. Что будет происходить при этом, зависит от
того, с чем реально ассоциирован этот файл. Например, если он ассоциирован с жёстким
диском, то тогда будут читаться/записываться данные на жёсткий диск, не обращая
внимание на разделы и файловые системы. Если он ассоциирован с разделом жёсткого
диска, то будут читаться/записываться данные, не обращая внимание на файловую
систему.
При помощи команды losetup можно добиться того, что он будет ассоциироваться с
обычным файлом на диске, что позволит создавать образы разделов и дисков.
Ещё полезной командой Linux является команда kpartx, которая создаёт блочные
устройства из файла образа диска. Каждое из устройств будет ассоциировано с образом
раздела, который хранится в этом файле.

Форматирование раздела в Linux выполняется одной командой. В качестве параметра
необходимо передать имя файла блочного устройства. Например, для создания файловой
системы exFAT на блочном устройстве /dev/mmcblk0p3:
$ mkfs.exfat /dev/mmcblk0p3
Чтобы можно было работать с файлами файловой системы, размещённой на блочном
устройстве, нужно примонтировать файловую систему к корневой файловой системе при
помощи команды mount.
$ mkdir -p /mnt/data
$ mount -t auto /dev/mmcblk0p3 /mnt/data
Обратите внимание, что директория, куда будет производиться монтирование, должна
существовать до того, как вы будете монтировать. Если нужно размонтировать файловую
систему, используется команда umount.
$umount /mnt/data
Чтобы посмотреть, какие у вас есть блочные устройства, и куда они примонтированы,
можно использовать команду:
$ lsblk
▍ Systemd
Загрузка Linux происходит в несколько этапов. Сначала загружается ядро операционной
системы, затем ядро запускает процесс init. Задача процесса init загрузить и
инициализировать процессы пространства пользователя и находиться в памяти до
перезагрузки или выключения компьютера (устройства). За долгие годы существования
Linux было написано множество реализаций init. На данный момент во многих Linux-
дистрибутивах используется реализация, называемая systemd. Её мы и будем
использовать.
Минимум команд, которые необходимо знать для работы с systemd.

Команда
Назначение
systemctl start
sn.service
запустить службу
systemctl stop
sn.service
остановить службу
systemctl status
sn.service
посмотреть статус службы
systemctl enable
sn.service
включить службу (служба будет автоматически запущена при
следующей загрузке Linux)
systemctl disable
sn.service
выключить службу
journalctl -u
sn.service -b
посмотреть логи службы, начиная с момента последней
загрузки Linux
▍ Терминалы, PuTTY, sshd, agetty
Для администрирования ОС Linux из Windows часто используют эмулятор терминала
PuTTY. Он позволяет подключаться к компьютеру или устройству c ОС Linux с помощью
различных соединений (Ethernet, Wi-Fi, эмулируемого последовательного порта на
Bluetooth или USB) и работать удалённо с консолью Linux в Windows. Чтобы такое было
возможно, в ОС Linux должна быть запущена специальная программа, которая будет
взаимодействовать с PuTTY. Это может быть sshd в случае SSH-соединения или agetty в
случае последовательного порта.
При подключении через последовательный порт по умолчанию вы увидите чёрно-белый
экран без поддержки манипулятора мышь. Чтобы добавить поддержку мыши и цветного
экрана, необходимо изменить значение переменной окружения TERM в файле
/usr/lib/systemd/system/serial-getty@.service.
[Service]
Environment=TERM=xterm
USB

Чтобы два USB-устройства могли работать друг с другом, необходимо наличие у каждого
из них USB-контроллера. USB-контроллер в конкретный момент времени может работать в
режиме хоста (Host) или режиме периферийного устройства (Device). Если одно из
взаимодействующих устройств работает в режиме Host, то другое должно работать в
режиме Device. Существуют следующие виды USB-контроллеров:
Host — всегда работает в режиме Host.
Device — всегда работает в режиме Device.
OTG — может работать или в режиме хоста или в режиме периферийного устройства.
Переключение режимов может быть аппаратным (при помощи особой распайки
кабеля OTG кабель переводит в контроллер режим хоста) или программным
Режим хоста подразумевает посылку команд, а режим периферийного устройства — их
обработку.
▍ OTG USB-контроллер
Возьмём Android-телефон с OTG-контроллером. Это означает, что при сопряжении по USB
с компьютером (для записи файлов с компьютера на телефон), он будет играть роль
периферийного устройства, а при сопряжении по USB с периферийным устройством
(мышью, клавиатурой, сетевой картой, флэш-накопителем, монитором, принтером)
телефон будет играть роль хоста.
Обычно USB-контроллер периферийного устройства или USB OTG-контроллер
присутствуют во встраиваемых устройствах. Также они могут быть интегрированы в
однокристальную систему (SoC). Но по факту на устройстве может отсутствовать
физический USB-разъём для подключения.
Например, на всех Raspberry Pi установлена SoC, которая имеет OTG-контроллер, но
фактически физический разъём для него есть только в Raspberry Pi Zero (Zero W, Zero 2
W) и в Raspberry Pi 4.
▍ Дескрипторы USB
Каждое USB-устройство имеет дескрипторы. Дескрипторы — это информация о USB-
устройстве, которая используется операционной системой для корректного выбора
драйвера для устройства. Мне понравилось описание, которое приведено на сайте
Microsoft.

▍ Создание USB-устройств в Linux
Ядро Linux содержит модули, которые позволяют создавать виртуальные USB-устройства.
Это может быть Mass Storage, последовательный порт, сетевая карта. Загрузив и настроив
эти модули, вы можете сделать так, чтобы компьютером ваш одноплатник распознавался
одним или несколькими такими устройствами.
Если вам достаточно одного устройства, то вы можете загрузить модуль для этого
устройства, опционально передав ему параметры для конфигурации при помощи команды
modprobe. Когда отпадёт необходимость в этом устройстве, его можно выгрузить при
помощи команды modprobe -r.
Чтобы на одном физическом порту у вас распознавалось несколько устройств
одновременно, нужно использовать модуль libcomposite и сконфигурировать эти
устройства при помощи создания структур в файловой системе ConfigFS в директории
/sys/kernel/config/usb_gadget.
Такие устройства называются композитными USB-устройствами. Вы, скорее всего,
встречались с такими, например, если у вас беспроводная клавиатура и мышь, а для них
используется один приёмопередатчик.
В нашем случае мы создадим композитное USB-устройство, которое будет
последовательным портом и устройством хранения. Последовательный порт мы будем
использовать для подключения к нашему эмулятору оптических дисков через PuTTY.
Изначально я хотел, что бы это была сетевая карта и SSH, но карта требует настройки в
операционной системе компьютера, поэтому для простоты отказался от этой идеи в пользу
последовательного порта.
▍ Создание композитного USB-устройства при помощи ConfigFS
1. Загружаем модуль libcomposite.
modprobe libcomposite
2. Заполняем дескрипторы для устройства.
$ usb_dev=/sys/kernel/config/usb_gadget/cdemu
$ mkdir -p $usb_dev

$ echo 0x0137 > $usb_dev/idProduct
$ echo 0x0100 > $usb_dev/bcdDevice
$ echo 0x0200 > $usb_dev/bcdUSB
$ echo 0xEF  > $usb_dev/bDeviceClass
$ echo 0x02 > $usb_dev/bDeviceSubClass
$ echo 0x01 > $usb_dev/bDeviceProtocol
$ mkdir -p $usb_dev/strings/0x409
$ echo ""abababababababa"" > $usb_dev/strings/0x409/serialnumber
$ echo ""Linux Foundation"" > $usb_dev/strings/0x409/manufacturer
$ echo ""USB CD-ROM Emulator"" > $usb_dev/strings/0x409/product
3. Создаём конфигурацию.
mkdir -p $usb_dev/configs/c.1
mkdir -p $usb_dev/configs/c.1/strings/0x409
echo ""acm+usb"" > $usb_dev/configs/c.1/strings/0x409/configuration
echo ""0x80"" > $usb_dev/configs/c.1/bmAttributes
echo 250 > $usb_dev/configs/c.1/MaxPower
4.Создаём и подключаем функцию acm (последовательный порт через USB).
$ mkdir -p $usb_dev/functions/acm.usb0
$ ln -s $usb_dev/functions/acm.usb0 $usb_dev/configs/c.1
5. Создаём и подключаем функцию mass_storage. Mass_storage в данном случае — это
эмуляция CD-ROM для ISO-образа /home/pi/1.iso.
$ mkdir -p $usb_dev/functions/mass_storage.usb0/lun.0
$ echo 1 > $usb_dev/functions/mass_storage.usb0/lun.0/cdrom
$ echo 1 > $usb_dev/functions/mass_storage.usb0/lun.0/removable
$ echo 0 > $usb_dev/functions/mass_storage.usb0/lun.0/nofua
$ echo 0 > $usb_dev/functions/mass_storage.usb0/stall
$ echo ""/home/pi/1.iso"" > $usb_dev/functions/mass_storage.usb0/lun.0/file
$ ln -s $usb_dev/functions/mass_storage.usb0 $usb_dev/configs/c.1
6. Активируем созданное устройство.

$ ls /sys/class/udc > $usb_dev/UDC
▍ Удаление композитного USB-устройства при помощи ConfigFS
1. Деактивируем устройство.
$ usb_dev=/sys/kernel/config/usb_gadget/cdemu
$ echo """"> $usb_dev/UDC
2. Удаляем функцию mass_storage.
$ rm $usb_dev/configs/c.1/mass_storage.usb0
$ rmdir $usb_dev/functions/mass_storage.usb0
3. Удаляем функцию acm.
$ rm $usb_dev/configs/c.1/acm.usb0
$ rmdir $usb_dev/functions/acm.usb0
4. Удаляем конфигурацию.
$ rmdir $usb_dev/configs/c.1/strings/0x409
$ rmdir $usb_dev/configs/c.1
5. Удаляем устройство.
$ rmdir $usb_dev/strings/0x409
$ rmdir $usb_dev
6. Выгружаем загруженные устройством модули.

$ modprobe -r usb_f_mass_storage
$ modprobe -r usb_f_acm
$ modprobe -r libcomposite
Cтруктура файловой системы для созданного эмулятора CD-ROM
Bluetooth
Тема Bluetooth очень объёмная, и её невозможно изложить в одной статье, поэтому
приведу только тот минимум, который позволяет понять, как мы будем использовать
Bluetooth.
Bluetooth — технология, которая позволяет связывать устройства без проводов по
радиоканалу. На данный момент существует множество версий спецификации Bluetooth.
Спецификация Bluetooth освещает множество вопросов.
Чтобы передать данные с одного устройства на другое, необходимо наличие на обоих

устройствах контроллеров и стеков Bluetooth.
Bluetooth-контроллер — аппаратное устройство, обычно выполненное в виде микросхемы
или части более сложной микросхемы, позволяющее получать/передавать данные по
радиоканалу в соответствии со спецификацией Bluetooth.
Bluetooth-стек — программная реализация протоколов, описанных в спецификации
Bluetooth.
Протоколы Bluetooth, предназначенные для решения определённых задач, группируются в
профили Bluetooth.
Мы будем использовать два профиля Bluetooth:
1. Generic Access Profile (GAP), который поддерживается всеми Bluetooth-устройствами.
2. Serial Port Profile (SPP), который подразумевает использование последовательного
порта поверх соединения Bluetooth.
▍ Поддержка Bluetooth операционными системами
Bluetooth-контроллеры могут иметь различные аппаратные интерфейсы для доступа. Это
может быть UART, USB, PCIe. В случае операционной системы многие детали скрываются,
и можно о них не думать. С контроллером можно работать на низком уровне через
драйвер или уже используя высокоуровневые библиотеки и приложения,
предоставляемые стеком Bluetooth, например, в Linux широко распространён стек BlueZ.
▍ BlueZ
Стек Bluetooth BlueZ состоит из двух частей.
Одна часть представлена модулями ядра Linux, уже включена в ядро. Если она
отсутствует, то её нужно включить и перекомпилировать ядро.
Вторая часть представлена приложениями для пространства пользователя. Приложения
позволяют конфигурировать и работать со стеком Bluetooth.
На данный момент многие приложения считаются устаревшими, и разработчики BlueZ
рекомендуют использовать более новые приложения и интерфейс D-Bus для работы со
стеком.

Но, как мне кажется, именно те старые, устаревшие приложения позволяют лучше понять
работу Bluetooth, поэтому в учебных целях я буду использовать их, для чего нужно будет
инициализировать BlueZ в режиме совместимости.
$ bluetoothd --noplugin=sap -C
▍ Протоколы Bluetooth
Я не буду утомлять вас различными схемами, диаграммами, которые вы легко можете
найти в интернете. Расскажу только о тех протоколах, с которыми нам предстоит
столкнуться и нужно будет сконфигурировать.
▍ Service Discovery Protocol (SDP)
При помощи протокола SDP можно определить, какие приложения (сервисы) находятся на
хосте, и с ними возможен обмен данными через Bluetooth
Чтобы можно было увидеть сервис с другого устройства, его необходимо зарегистрировать
в SDP database. Например, если мы хотим зарегистрировать службу, представляющую
эмуляцию последовательного порта в Bluetooth, это можно сделать следующей командой:
$ sdptool add SP
Чтобы можно было посмотреть службы, зарегистрированные у вас на хосте, нужно ввести
команду:
$ sdptool browse local
▍ Radio Frequency Communications (RFCOMM)
Протокол RFCOMM позволяет создавать виртуальное соединение по последовательному
порту между двумя хостами.
На одном из хостов создаётся сервер, которому выделяется канал RFCOMM, второй из
хостов подключается к нему, указывая MAC-адрес и номер канала
Канал RFCOMM немного напоминает порт в UDP или TCP, но если у них и у источника и у
получателя есть порты, то у RFCOMM для источника и получателя один и тот же канал.

Поэтому невозможно создать несколько подключений на один и тот же канал.
В Linux можно использовать команду rfcomm для создания процесса, который будет
слушать определённый канал RFCOMM и при соединении запускать другой процесс.
$ rfcomm -r watch hci0 1 /usr/local/bin/cdemu-cmd /dev/rfcomm0 /dev/rfcomm0
В данном случае на Bluetooth-контроллере hci0 RFCOMM будет прослушиваться канал 1 и
запускаться процесс cdemu-cmd с двумя параметрами командной строки /dev/rfcomm0 и
/dev/rfcomm0.
▍ Утилита bluetoothctl
Утилита Bluetoothctl позволяет сопрягать устройство, на котором вы её запустили с другим
устройством.
Вы можете сделать устройство видимым для обнаружения другими устройствами, а также
найти другое устройство и выполнить с ним сопряжение. Более подробно расписано в
документации к утилите, которая доступна по команде:
$ man bluetoothctl
▍ Serial Bluetooth Terminal
Для отладки приложений, использующих Bluetooth, удобно использовать приложение для
Android Serial Bluetooth Terminal. Это приложение позволяет работать с Bluetooth-
устройствами, у которых доступен профиль SPP. В нашем случае мы будем использовать
его как визуальный интерфейс для работы с нашим эмулятором оптических дисков.
Сборка и модификация дистрибутива Raspberry Pi OS
Чтобы сделать полноценный аппаратный эмулятор оптических дисков, нам придётся
немного модифицировать исходный дистрибутив Linux. Это подразумевает
перекомпиляцию ядра, изменение нескольких конфигурационных файлов и добавление
своего программного кода. Для меня это было удобно сделать при помощи Docker.
▍ Кросс-компиляция ядра Linux
Кросс-компиляция позволяет на компьютере с одной архитектурой получать исполняемые

файлы для другой архитектуры. Мы можем компилировать ядро Linux для Raspberry Pi на
Raspberry Pi, а можем, используя кросс-компиляцию, сделать это на обычном компьютере
с архитектурой x86, что существенно сократит время компиляции из-за большего
быстродействия компьютера. Подробно о том, как выполнять кросс-компиляцию Raspberry
Pi OS, можно почитать тут.
▍ Chroot и запуск бинарных файлов другой архитектуры
Команда Linux chroot позволяет запускать процессы с изменённой корневой системой. Это
кажется немного запутанным, но суть в следующем. В качестве параметра команде
передаётся путь к корневой директории. В результате запуска команды через chroot
запущенный процесс будет считать, что корнем файловой системы является та
директория, которую передали в качестве параметра.
Применений у команды chroot несколько, например, её можно использовать, чтобы
запустить команду apt для Raspberry Pi в Docker-контейнере.
Интересно, что Docker Desktop для Windows позволяет запускать исполняемые файлы для
архитектуры ARM. В Linux-версии Docker такое сделать можно, но нужна дополнительная
настройка.
Реализация
Созданный мной проект состоит из следующих файлов:
1. Dockerfile и скрипт, который выполняется в Docker-контейнере.
2. Файлы, которые необходимо добавить или обновить в исходном дистрибутиве:
cdemu — основная логика работы эмулятора оптических дисков, написанная на
языке bash;
cdemu-cmd — bash-скрипт для обработки команд от пользователя и передачи их
эмулятору;
bash-utils.sh — bash-скрипт co вспомогательными функциями;
cdemu-bluetooth-ui.service — systemd-служба, которая запускает интерпретатор
команд на создаваемом RFCOMM-соединении телефона и Raspberry Pi;
cdemu.service — systemd-служба, которая запускает эмулятор оптических дисков
при загрузке;
bluetooth.service — изменённая служба systemd для инициализации bluetooth;

serial-getty@.service — изменённая служба systemd для запуска agetty на
создаваемом соединении на последовательном порту;
firstboot.service — служба systemd для запуска скрипта при первой загрузке
операционной системы. Я её позаимствовал из проекта raspberian-firstboot;
config.txt — изменённый файл конфигурации для загрузки Raspberry Pi. Содержит
подключение overlay dwc. Это необходимо, чтобы USB-контроллер мог работать в
device mode;
fistboot.sh — скрипт, который запускается службой systemd firstboot.service;
userconf.txt — файл, который необходим, чтобы установить пароль для
пользователя pi. В последних версиях Raspberry Pi OS пользователь pi не
активирован по умолчанию, поэтому необходимо наличие этого файла;
ssh — файл необходим, чтобы активировать ssh, который отключён по
умолчанию;
wpa_supplicant.conf — файл, необходимый, если вы хотите настроить Raspberry Pi
на работу с вашей точкой доступа.
Листинги файлов не привожу, так как это ещё больше раздует и так большую статью.
Ознакомиться вы с ними можете здесь.
Как пользоваться эмулятором
1. Собираем Docker-образ.
docker build -t raspi-image . 
2. Собираем образ RaspberryPi OS.
docker run --privileged -v c:\temp:/build --name raspi-image -it --rm raspi-image
3. Записываем образ на SD-карту. Вставляем её в Raspberry Pi.
4. Подключаем Rapsberry Pi Zero 2 W к компьютеру.
5. Через некоторое время у вас появится съёмный накопитель.
6. На этот съёмный накопитель, содержащий файл Readme.txt, копируем образы, которые
хотим эмулировать.
7. Находим виртуальный COM-порт, созданный после подключения Raspberry Pi к
компьютеру.

8. Подключаемся к Raspberry Pi через с помощью Putty через виртуальный COM-порт.
9. Запускаем интерактивное приложение для управления эмулятором.
$ sudo cdemu-cmd
10. Если хотим сделать управление с телефона, то выполняем сопряжение телефона и
Raspberry Pi. Для чего вводим в эмуляторе терминала команду:
$ sudo bluetoothctl
11. Делаем Raspberry Pi доступным для обнаружения:
discoverable on
12. Находим его на телефоне и выполняем полключение. После чего соглашаемся с PIN-
кодом на телефоне и Raspberry Pi.
yes
13. Выходим из bluetoothctl.
exit
14. Запускаем на телефоне Serial Bluetooth Terminal и выполняем подключение к Raspberry
Pi из него. Теперь можно посылать команды созданному эмулятору CD-ROM.
Команды, которые можно посылать эмулятору:
1. hdd — переключение в режим эмуляции внешних жёстких дисков.
2. cdrom — переключение в режим эмуляции внешних приводов оптических дисков.
3. list — вывести список доступных ISO-образов, которые можно эмулировать.
4. insert <порядковый номер> — поместить ISO-образ для эмуляции.
5. eject — извлечь ISO-образ из эмулятора.
6. help — показать список доступных команд в текущем режиме.
Особенности моего эмулятора

Интересно, но в Linux по умолчанию нельзя эмулировать ISO-образы размером больше 2
Gib. Я просмотрел исходный код драйвера в файле
drivers/usb/gadget/function/storage_common.c и предположил, что нет оснований не
применять патч к ядру Linux от Adam Bambuch, который просто удаляет одно условие.
Образы эмулировались нормально и при снятии ISO-образа с эмулируемого CD-ROM он
был идентичен исходному. Поверял по хеш-коду для файла ISO-образа.
Не пойму, почему есть это ограничение в Linux и почему его до сих пор не убрали? Если
вы знаете ответ, ответьте в комментариях.
Моя реализация не требует никаких дополнительных деталей. Нужен только Raspberry Pi
Zero 2 W, один или два кабеля USB и адаптер питания, если будете использовать два
кабеля USB. Один для питания, второй для передачи данных. Хоть и использование
дополнительного кабеля и адаптера добавляет громоздкости, это решает проблему
перезагрузки Raspberry Pi, если компьютер или ноутбук отключает ненадолго питание при
перезагрузке.
Кроме того, я не использую Python, только bash.
Выводы
Полученное программно-аппаратное решение, хоть и обладает рядом недостатков по
сравнению с карманом Zalman (не поддерживается USB 3.0, нет интерактивного меню на
самом устройстве), позволит вам установить практически любую операционную систему
на широкий спектр компьютеров путём простого копирования ISO-образа.
Решение является прототипом, но вместе с тем позволяет углубить знания по многим
темам, или получить, если вы были с ними не знакомы.
Так как основной целью была разработка прототипа, я запускал bluetoothd в режиме
совместимости, и почти всю логику написал на bash.
Я хотел показать возможность превратить встраиваемое устройство с операционной
системой Linux в аппаратный эмулятор флеш-накопителя или привода оптических дисков,
приложив минимум усилий. Надеюсь, что это удалось.
Чтобы уместить всё в одной статье, я лишь поверхностно коснулся тех тем, которые
необходимы для понимания. Если вас заинтересовало, вы можете самостоятельно
изучить их углублённо.

Объём статьи не позволяет осветить все интересности, с которыми я столкнулся при
разработке эмулятора, и решения, которые применял и проверял. Приведу лишь
несколько из них.
Например, я долго боролся с зависанием при удалении составного устройства. Помогло
использование службы serial-getty вместо getty, хотя во многих статьях упоминалась getty.
Я долго разбирался, как можно сделать сопряжение через Bluetooth между Raspberry и
телефоном, использовал команду bt-agent, но потом всё-таки отказался от неё в пользу
bluetoothctl.
При переключении эмулятора в режим HDD для записи ISO-образов изначально я
открывал для доступа всю SD-карту и хранил ISO-образы в отдельном разделе, но потом
посчитал, что для безопасности лучше хранить образ диска с ISO-образами в отдельном
файле и открывать доступ только к нему, хоть это и снизило скорость записи, но
пользователя не обескураживают появляющиеся несколько дисков.
Разработанный прототип есть куда улучшать. Можно, например, создать более
минималистичный дистрибутив Linux, который будет содержать только то, что реально
используется для эмуляции, или создать более удобное графическое приложение для
Android для работы с эмулятором. А можно упростить работу с Bluetooth, напрямую
работая с драйверами bluetooth или используя интерфейс D-Bus для работы с Bluetooth-
устройствами. Или вообще всё-таки взяться за паяльник и сделать устройство, более
похожее по функционалу на карман Zalman. Но главное, вы увидели, что это реально
сделать, а когда видишь положительный результат, это вдохновляет на большее
творчество.
В процессе тестирования и отладки программного кода было замечено, что на Lenovo X1
Extreme Gen 2 эмулятор CD-ROM дисков великолепно определялся в Windows 10, но
отказывался определяться в BIOS. Эмпирически было определено, что помогает
отключение режима экономии энергии процессора в BIOS. Также ноутбук отключал
питание на usb при перезагрузке, поэтому понадобилось дополнительное питание
Raspberry Pi.
Интересно, но на ASUS K53E и Gigabyte BRIX всё работает без проблем.
Решение с небольшими модификациями можно реализовать на Raspberry Pi 4. Но если вы
поняли суть решения, вы его сможете повторить и на других одноплатных компьютерах,
которые имеют выведенные USB-порты для OTG или USB-контроллеры периферийных
устройств.

RUVDS.com
VDS/VPS-хостинг. Скидка 15% по коду HABR15
Telegram
ВКонтакте
Twitter
84
Карма
82.1
Рейтинг
@artyomsoft
Пользователь
Комментарии 17
Dockerfile на данный момент только выполняется в Docker Desktop для Windows. В Linux
он работать не будет.
В заключение хочу сказать, что существует ещё один способ эмулировать оптические
диски, который я не пробовал, но знаю о его существовании из ваших комментариев к
одной из моих статей — это программа DriveDroid для Android. Я ей не пользовался, так
как для её работы нужно получать права root на телефоне. Но, скорее всего, из-за
ограничений в ядре Linux программа поддерживает ISO-образы до 2 Gib и/или работает
только с гибридными ISO-образами. Если я не прав, буду рад увидеть ваши опровержения
в комментариях.
Telegram-канал с розыгрышами призов, новостями IT и постами о ретроиграх 🕹️
Теги:  linux kernel, usb, bluetooth, bluez, linux modules, эмуляция, iso, cd-rom, systemd, 
agetty, ruvds_статьи
Хабы:  Блог компании RUVDS.com, Системное администрирование, 
Разработка под Linux, Разработка на Raspberry Pi, DIY или Сделай сам
Редакторский дайджест
Присылаем лучшие статьи раз в месяц
Электропочта

Публикации
RationalAnswer
9 часов назад
Как обнулялся Credit Suisse: разбираем траекторию погружения
на дно швейцарского гига-банка
12 мин
kesn
10 часов назад
Байки погромиста. Если кто-то скажет, что программирование —
это скучно
12 мин
Tutelka
9 часов назад
Обещания — настоящие и не очень
Простой
7 мин
alizar
9 часов назад
Удивительное рядом. Как устроен буфер обмена в Windows и Linux
Простой
6 мин
ЛУЧШИЕ ЗА СУТКИ
ПОХОЖИЕ
12K
Обзор
+75
26
49
11K
Мнение
+75
33
9
2.7K
Мнение
+34
24
10
4.7K
+31
46
10

unxed
3 часа назад
Linux-порт Far Manager: новости весны 2023
Средний
4 мин
Показать еще
1.8K
Дайджест
+29
14
7
ИНФОРМАЦИЯ
Сайт
ruvds.com
Дата регистрации
18 марта 2016
Дата основания
27 июля 2015
Численность
11–30 человек
Местоположение
Россия
Представитель
ruvds
ССЫЛКИ
VPS / VDS сервер от 130 рублей в месяц.
ruvds.com
Дата-центры RUVDS в Москве, Санкт-Петербурге, Казани, Екатеринбурге, Новосибирске, Лондоне,
Франкфурте, Цюрихе, Амстердаме
ruvds.com
Помощь и вопросы
ruvds.com
Партнерская программа RUVDS
ruvds.com
VPS (CPU 1x2ГГц, RAM 512Mb, SSD 10 Gb) — 190 рублей в месяц
ruvds.com
VPS Windows от 523 рублей в месяц. Бесплатный тестовый период 3 дня.
ruvds.com
VDS в Цюрихе. Дата-центр TIER III — швейцарское качество по низкой цене.
Ваш аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr

ruvds.com
Антивирусная защита виртуального сервера. Легкий агент для VPS.
ruvds.com
VPS в Лондоне. Дата-центр TIER III — английская точность за рубли.
ruvds.com
VPS с видеокартой на мощных серверах 3,4ГГц
ruvds.com
ПРИЛОЖЕНИЯ
RUVDS Client
Приложение для мониторинга и управления виртуальными серверами RUVDS с мобильных устройств.
Android
iOS
ВИДЖЕТ
БЛОГ НА ХАБРЕ
5 часов назад
Как устроено индексирование баз данных
1.7K
0

9 часов назад
Удивительное рядом. Как устроен буфер обмена в Windows и Linux
вчера в 14:00
Будни техпода. Размещение игрового сервера на VDS
вчера в 08:45
Ностальгические игры: Parasite Eve
20 мар в 18:00
Инструменты наблюдаемости, о которых нужно знать в 2023 году
4.7K
10
2.9K
12
3.4K
4
3.2K
4"
Ænix,41.74,04.05.2025,Подписаться,"Cozystack, хотя за последние полтора месяца выпустили уже
шесть новых версии: 0.24, 0.25, 0.26, 0.27, 0.28, 0.29. Посмотрим
на изменения более подробно — от самой свежей версии до
релиза 0.24.
Главные изменения
1. Стабилизация платформы для использования в мульти-ЦОД-
ĸонфигурациях. Провели большую работу по настройĸе etcd,
Cilium, Kuve-OVN, Linstor и других ĸомпонентов. 
2. Усиление и улучшение observability-стеĸа. Добавили
дашборды для ряда ĸомпонентов и оптимизировали
настройĸи Grafana ĸоторые усĸорили ее работу.
3. Релиз дополнительной утилиты cozy-proxy, ĸоторая позволяет
выдавать виртуальным машинам в K8s IP-адреса (причем
выделять адреса целиĸом, а не отĸрывать отдельные порты).
4. Появление Vertical Pod Autoscaler. VPA автоматичесĸи
выставляет лимиты на ресурсы, ĸоторые может потреблять
приложение. Лимиты определяются на основе историчесĸих
метриĸ. 
5. Рефаĸторинг и добавление новых разделов в доĸументацию.
Обновления платформы Cozystack 0.24−0.29:
провиженинг нод по PXE, мониторинг RTT
между ДЦ и выделенные IP-адреса для VM
4 мин
89
Блог ĸомпании Ænix, Kubernetes*, DevOps*, Облачные вычисления*, 
Open source*
Что таĸое Cozystack
ИНФОРМАЦИЯ
Сайт
aenix.io
Дата регистрации 22 февраля 2024
Численность
2–10 человеĸ
Местоположение
Чехия
Представитель
Andrei Kvapil
Моя
лента
Все
потоĸи
Разработĸа
Администрирование
Дизайн
Менеджмент
Марĸетинг
Научпоп
КАК СТАТЬ АВТОРОМ

6. Переезд репозитория платформы и вспомогательных утилит
из организации aenix-io в организацию cozystack после
передачи проеĸта в CNCF Sandbox.
Cozystack v0.29
В рамĸах релиза v0.29.0 ĸоманда разработчиĸов сосредоточилась
на повышении стабильности и надежности платформы, в том
числе устранении CVE-2025-1974 в ingress-nginx. Но были и новые
фичи: мы добавили большой набор пресетов, ĸоторые приложений
ограничивают потребление ресурсов, реализовали
автоматичесĸий перевыпусĸ сертифиĸатов и подĸлючили VPA ĸ
еще несĸольĸим ĸомпонентам платформы.
Другие изменения:
Добавился Cilium host firewall, ĸоторый позволяет улучшить
безопасность ĸластера «из ĸоробĸи».
Добавлен процесс для запусĸа e2e-тестов в GitHub CI.
В рамĸах передачи Cozystack в CNCF Sandbox появилась
первая версия струĸтуры управления проеĸтом и определены
основные роли.
Flux Operator был обновлен до версии 0.18.0.
Talos Linux был обновлен до версии 1.9.5.
Подробности: v0.29.0, v0.29.1.
Cozystack v0.28
Главное изменение — появления Vertical Pod Autoscaler, ĸоторый
автоматичесĸи выставляет лимиты на ресурсы, доступные
различным приложениям. Кроме того, репозиторий Cozystack был
перемещен из aenix-io в GitHub-организацию cozystack.
Другие изменения:
Изоляция тенантов теперь вĸлючена по умолчанию.
Ответственность за валидацию source-ip передана от Cilium в
Kube-OVN.
Исправлены небольшие баги в LINSTOR, Kube-OVN, KubeVirt.
Сilium был обновлен до версии 1.17.1, Kube-OVN  — до версии
1.13.3.
Подробности: v0.28.0, v0.28.2.
БЛОГ НА ХАБРЕ
10 деĸ 2024 в 17:52
Неизбежное будущее Kubernetes:
почему оркестратор должен пойти по
пути Linux Kernel
29 ноя 2024 в 18:16
Азбука: FluxCD — перенастраиваем
kubernetes с одного репозитория на
другой
26 ноя 2024 в 16:28
Как мы создавали динамический
Kubernetes API server для API
Aggregation Layer в Cozystack
8 авг 2024 в 13:15
Погружение в облака: K8S по следам
Ænix с gohost. Часть 1. Установка
Kubernetes-кластера под управлением
Cozystack
31 июл 2024 в 17:13
FreeIPA tips & tricks: перенос FreeIPA из
LXC-контейнера CentOS 7 в Rocky Linux,
дебаг и истекшие сертификаты
12K
25 +25
3.3K
3 +3
1.6K
1 +1
3.7K
11 +11
2.6K
5 +5
0
0
0
лента
потоĸи

Cozystack v0.27
В этом релизе мы снова уделили особое внимание стабилизации
платформы, а таĸже написали набор сĸриптов linstor plunger для
автоматичесĸого исправления ошибоĸ в LINSTOR (например,
DRBD lost connection, зависшее loop-устройство и т.п.) и добавили
возможность распределения реплиĸ PostgreSQL по разным
нодам.
Другие изменения:
Появились удобные дашборды для мониторинга ClickHouse и
Piraeus.
etcd-operator обновлен до версии 0.4.1.
В параметре maxLabelsTimeseries маĸсимальное ĸоличество
лейблов для timeseries увеличено с 30 до 60.
Исправлен дашборд Goldfinger, утилиты для отслеживания
latency сети в ĸластерах, ноды ĸоторых распределены между
разными дата-центрами.
Подробности: v0.27.0.
Cozystack v0.26
В этом релизе мы серьезно поработали над улучшением
стабильности Cozystack при работе в мульти-ДЦ-ĸонфигурациях и
добавили мониторинг сетевой связности. На основе этих данных
можно более осмысленно подбирать параметры основных
ĸомпонентов платформы.
Другие изменения:
Добавлена возможность ограничивать ресурсы для отдельных
тенантов внутри ĸластера.

Добавлен инструмент Goldpinger, ĸоторый позволяет
мониторить latency между дата-центрами и выводит данные в
дашборд в Grafana.
Лайв-миграция виртуальных машин теперь вĸлючена по
умолчанию.
Появилась возможность создавать снапшоты томов LINSTOR,
это первый шаг на пути ĸ полноценной системе бэĸапов. 
Исправили TLS handling в etcd helm chart. Теперь etcd не
ломается из-за просроченных ĸорневых сертифиĸатов (ранее
они выписывались на 90 дней). 
Подробности: v0.26.0, v0.26.1.
Cozystack v0.25
В релиз 0.25 вошел новый вспомогательный инструмент, ĸоторый
можно использовать отдельно от Cozystack — cozy-proxy. Он
позволяет выделять IP-адреса виртуальным машинам — причем
не отдельные порты, а адрес целиĸом. В Cosyastack виртуальные
машины базируются на KubeVirt и управляются примерно таĸ же,
ĸаĸ и поды. А Kubernetes не предусматривает выделение подам
IP-адресов целиĸом. cozy-proxy эту проблему решает, что важно,
например, для ĸлиентов сервис-провайдеров, приложения
ĸоторых работают в виртуальных машинах и ĸоторым необходим
отдельный IP-адрес.
Другие изменения:
Улучшен мониторинг etcd, Flux, Kafka и добавлены
соответствующие дашборды.
Talos Linux обновлен до версии 1.9.3.
У пользователей ĸоторые имеют доступ тольĸо ĸ отдельным
тенантам, появилась возможность сĸачивать kubeconfig.
Подробности: v0.25.0, v0.25.1, v0.25.2, v0.25.3.

Instance
Allx
X<
CallType
AllX
X<
L
OverallHealth
GoldpingerNodes
Increasein#Erro...
3
Unhealthyseenbyinstance
Time
2025-03-1116:21:00
2025-03-1116:22:00
2025-03-1116:23:00
2025-03-1116:24:00
2025-03-1116:25:00
2025-03-1116:26:00
goldpinger_instance
node1
nodel
node1
node1
node1
node1
Unhealthynodesincrease[30m]
%Unhealthynodesreported

Cozystack v0.24
В этом релизе появилась возможность PXE провиженинга для нод,
чтобы автоматичесĸи загружать на них Talos Linux. Для этого в
Cozystack были имплементирован паĸет smee (dhcp+pxe server) из
набора Tinkerbell.
Другие изменения:
Cert-manager обновлен до 16 версии.
darkhttp заменен на собственную разработĸу cozystack-
assets-server.
В образ Grafana были вшиты плагины, чтобы Grafana
запусĸалась быстрее.
Подробности: v0.24.0, v0.24.1.
Что дальше
Мы заĸанчиваем работу над добавлением поддержĸи GPU в
виртуальных машинах и уже начали тестирование
фунĸциональности. Это позволит запусĸать в рамĸах платформы
AI- и ML-нагрузĸи.
Присоединяйтесь к нашему комьюнити
Telegram (ru, en)
Slack
Community Meeting Calendar
Теги: cozystack, aenix, kubernetes, devops, platform engineering, 
cloud platform, virtualization, gpu, paas, cncf
Хабы: Блог ĸомпании Ænix, Kubernetes, DevOps, Облачные
вычисления, Open source

Ænix
Компания
Сайт
Telegram
Github
Twitter
79
Карма
6.3
Рейтинг
Тимур Туĸаев @TimurTukaev
Head of Marketing @ Ænix, Open Source
Enthusiast
Комментарии
Здесь поĸа нет ни одного ĸомментария, вы можете стать первым!
Другие новости
denis-19 тольĸо что
Релиз Gzip 1.14
1 мин
dilnaz_04 25 минут назад
Исследование Microsoft показывает, что модели
AI по-прежнему испытывают трудности с
отладкой программного обеспечения
3 мин
0
0
0
0
76
Подписаться
Отправить
Ваш ĸомментарий
Нажмите ""/"" для вызова меню
Подписаться

dilnaz_04 25 минут назад
Институт Аллена запускает OLMoTrace:
инструмент для отслеживания источников
ответов языковых моделей в обучающих данных
2 мин
denis-19 2 часа назад
Мнение: рекомендация РКН — мера для
мониторинга и определения количества
пользователей зарубежных протоколов
шифрования
3 мин
daniilshat 5 часов назад
На ЦКАД запустили тестовое движение
беспилотных грузовиков
1 мин
daniilshat 5 часов назад
Аналитики: если Apple перенесёт производство в
США, то iPhone будет стоить около 3,5 тыс.
долларов
1 мин
darya_kiwi 7 часов назад
Обновление для Microsoft Ofﬁce 2016 сломало
Outlook, Word и Excel: выпущено исправление
1 мин
0
0
0
24
0
0
1 +1
1.1K
+2
1
1 +1
791
+6
0
4 +4
1.4K
+1
0
6 +6
950
+6
3
1 +1

Lexx_Nimofff 8 часов назад
Вышло обновление платформы «Аврора Центр»
5.2.0
2 мин
Lexx_Nimofff 8 часов назад
Cloud.ru разрабатывает гибридное облако с AI-
инструментами
2 мин
dilnaz_04 8 часов назад
Стартап LiveKit получает $45 млн на развитие
облачной платформы для потоковой передачи
мультимедиа
2 мин
Поĸазать еще
423
+6
1
0
306
+6
1
1 +1
197
+1
0
0
Ваш аĸĸаунт
Профиль
Треĸер
Диалоги
Настройĸи
ППА
Разделы
Статьи
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для ĸомпаний
Доĸументы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реĸлама
Нативные проеĸты
Образовательные
программы
Стартапам
Настройĸа языĸа
Техничесĸая поддержĸа
© 2006–2025, Habr"
Cloud4Y,71.07,04.05.2025,#1 Корпоративный облачный провайдер,"Взлом Instagram*аккаунта — популярный запрос в поисковиках.
Поэтому есть смысл рассказать о том, как это обычно работает.
Просто для того, чтобы вы знали, откуда может пойти атака.
Простой3 мин
Cloud4Y
OSINT & Hacking — как работает фишинг для
нельзяграма
1.1K
Блог компании Cloud4Y
, 
Информационная безопасность*
, 
Социальные сети и сообщест
Обзор
Перевод
КАК СТАТЬ АВТОРОМ

Чтобы начать попытки заполучить доступ к аккаунту, вы должны
знать ник человека, которого вы пытаетесь взломать. Так
что небольшая разведка будет очень кстати. Только не увлекайтесь.
Существуют различные инструменты для разведки, в первую
очередь, поиск пользователя в конкретной соцсети с целью узнать
его ник. Я нашёл отличный инструмент под названием «Slash»,
который можно использовать для поиска любых учётных записей
пользователя, если он везде регистрируется под одним ником.
Ставим Slash
Я проверил Slash на себе, и посмотрите на эти результаты.
Некоторые из учетных записей, перечисленных здесь, были созданы
много лет назад.
git clone https://github.com/theahmadov/slash 
cd slash 
pip install -r requirements.txt 
python slash.py help

Slash — это простой консольный инструмент. Но вы также можете
использовать такие инструменты, как WhatsMyName Web, который
совершенно бесплатен.
Вот, посмотрите. Я проверил WhatsMyName на себе. Мой ник
«earthtoyash».


Теперь, когда мы знаем больше о нашем пользователе, можно
использовать эти знания. Например, через отправку фишинговых
ссылок. Для этого создадим полезную нагрузку с помощью Zphisher.
Ставим Zphisher с GitHub
Клонируем репозиторий:
Запускаем файл zphisher.sh:
При первом запуске он установит зависимости и на этом всё.
Система скажет, что Zphisher установлен. После установки вам
нужно будет снова запустить zphisher.sh в каталоге zphisher
командой ./zphisher , и тогда вы получите что-то вроде этого:
git clone --depth=1 https://github.com/htr-tech/zphisher.git
cd zphisher && ./zphisher.sh

Как вы можете видеть, есть много вариантов и шаблонов, благодаря
чему любой может заниматься фишингом. Мы сосредоточимся на
нельзяграме. Итак, введите «2» и нажмите Enter.
Следующий шаг полностью зависит от вас, выберите любой из них.
Затем появится окно с выбором. Я выбрал третий вариант, так как он
минималистичный и удобен для того, чтобы показать возможности
инструмента.

Опять же, чтобы все было просто, я пропущу пользовательский порт,
но если вы уже используете порт 8080, то можете изменить его на
8000. Если нет, оставляйте всё как есть. Также важно маскировать
URL, ну просто в целях безопасности. Можно использовать чтото
вроде этого:
Всё, Zphisher создал фишинговую ссылку, которую можно
отправить жертве. Как только она нажмёт на ссылку, вы начнёте

получать информацию о ней. Например, IPадреса, имена
пользователей, пароли и т. д. Ещё можно использовать обратный
поиск IP, чтобы определить местоположение вашей цели и многое
другое.
Итак, вот эти фишинговые ссылки.
При нажатии открывается страница, похожая на официальную
страницу входа в запрещённую соцсеть.

Вот она, нехорошая
После ввода учётных данных можно получить много информации на
«хакерской» стороне терминала.
Вот так, господа и дамы, можно без особого труда взломать учетную
запись в нельзяграме. Поэтому в очередной раз напоминаем: нельзя

нажимать на ссылки, которым вы не доверяете.
Само собой разумеется, не используйте информацию из этой статьи
с намерением причинить кому-либо вред. OSINT законен, но фишинг
и кража личных данных даже в запрещённой соцсети является
уголовным преступлением. И да, * Организация Meta, а также её
продукт Instagram, на которые мы ссылаемся в этой статье,
признаны экстремистскими и запрещены на территории РФ.
Спасибо за внимание!
Что ещё интересного есть в блоге Cloud4Y
→ Информационная безопасность и глупость: необычные примеры
→ NAS за шапку сухарей
→ Взлом Hyundai Tucson, часть 1, часть 2
→ Столетний язык программирования — какой он
→ 50 самых интересных клавиатур из частной коллекции
Теги:  
взлом
,
соцсети
,
osint
Хабы:  
Блог компании Cloud4Y
,
Информационная безопасность
,
Социальные сети и сообщества
0
19
1

Cloud4Y
#1 Корпоративный облачный провайдер
Сайт
Facebook
Twitter
ВКонтакте Telegram
149
Карма
53.5
Рейтинг
Cloud4Y @Cloud4Y
Корпоративный облачный провайдер
Сайт
ВКонтакте Telegram
Комментарии 1
Публикации
ЛУЧШИЕ ЗА СУТКИ 
ПОХОЖИЕ

 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 

Ваш
аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
ИНФОРМАЦИЯ
Сайт
www.cloud4y.ru
Дата регистрации
29 июля 2011
Дата основания
2009
Численность
51–100 человек
Местоположение
Россия
Представитель

Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
414.35,4.74,04.05.2025,Рейтинг,"Рассказываем о том, как строить карьеру в IT
Весь интернет уже готовится к выходу Windows 12. Вероятно,
следующая версия будет во многом сосредоточена на поддержке
работы с ИИ. На это намекает в том числе недавняя утечка от Intel, а
5 мин
Arnak
Новые утечки. Что мы знаем о выходе
Windows 12
6.3K
Блог компании getmatch
, 
Разработка под Windows*
, 
Софт
, 
Искусственный интеллект
КАК СТАТЬ АВТОРОМ

также последние действия AMD и направление развития Bing.
Мы знаем, что и Intel, и Microsoft готовятся к поддержке работы
Windows 12 на новых процессорах. Об этом нам говорит утечка от
leaf_hobby, который известен тем, что раскрывает полные
спецификации чипов Intel Xeon перед их запуском. На этот раз
leaf_hobby опубликовали подробности аппаратных показателей
десктопной платформы Intel Meteor Lake, которую планируется
выпустить в этом или в следующем году. Сейчас их твиты уже
защищены, но интернет помнит™, а у журналистов отдельных
изданий, вроде Insider и The Verge, к ним есть доступ.
Сообщается, что Intel в имейле для своих сотрудников упоминает,
что ее процессоры следующего поколения будут поддерживать
Windows 12. Для этого Meteor Lake должен содержать 20 линий PCIe
Gen5.
Хотя Microsoft не объявляла о каких-либо планах в отношении
Windows 12, уже есть признаки того, что компания планирует
будущие версии Windows с расчетом на глубокую интеграцию
функций ИИ. Даже последнее обновление Windows 11 уже
интегрирует новую версию Bing с искусственным интеллектом прямо
в панель задач. А ещё в этом обновлении бизнес-пользователи
получают рекомендованный ИИ контент в меню «Пуск». Скоро
искусственный интеллект придет в Edge, а потом — и во все
остальные аспекты продуктов Microsoft. Компания очень
воодушевлена успехом своей инвестиции в ChatGPT, и собирается
сделать на него очень сильную ставку в надежде победить
конкурентов, в том числе Google, у которой дело с инвестициями в
ИИ пошло не так хорошо.

Один из слайдов от Intel
В начале января руководитель разработки Windows Паноса Паная на
CES заявил, что «ИИ собирается заново переизобрести всё то, что
вы делаете в Windows». Команда Microsoft Surface также сообщила,
что «ИИ изменит то, как мы используем ПК». Всё однозначно
указывает на то, что в следующей версии Windows компания
собирается очень широко использовать ИИ. Это будет главная новая
«фишка» платформы. А чтобы всё это могло работать, Microsoft
приходится тесно сотрудничать с партнерами по аппаратному
обеспечению, такими как Intel и AMD. Ей нужно, чтобы новые
процессоры смогли справляться с высокими рабочими нагрузками
ИИ, и без ошибок работали с новой технологией. Это объясняет то,
почему Intel, как сообщается, уже упоминает об оптимизации под
Windows 12 внутри компании.
AMD недавно выпустила свои мобильные процессоры Ryzen 7000, и
похвасталась тем, что они являются первыми процессорами x86,
содержащими специальный механизм искусственного интеллекта,
способный поддерживать эффекты Windows Studio. Эти функции, в

том числе удаление фонового шума, размытие фона и
автоматическое кадрирование, будут доступны только для техники с
ускорителями на чипах ARM, которые работают с помощью
специального нейронного процессора (NPU).
То есть, AMD и Microsoft сейчас тоже активно совместно работают
над внедрением расширенного числа функций на основе ИИ в свои
продукты. И такие возможности, как заявляют компании, в
дальнейшем будут более широко доступны в традиционных
ноутбуках с Windows, работающих на AMD. Возможно, это тоже
является подготовкой новых поколений процессоров к запуску с
Windows 12.
Все эти даты очень хорошо стыкуются. Новые процессоры от Intel и
AMD ожидают в конце этого года или в 2024-м. А на разработку
новой версии ОС у Microsoft раньше уходило 2-3 года. Windows 11
была выпущена в октябре 2021-го. Так что, если новые утечки верны,
следующую основную версию Windows можно ожидать в 2024 году
— как раз под ряд новых процессоров.
Как она будет выглядеть

То, что Windows 12 точно находится в разработке, мы узнали и из
утечек декабря 2022 года. Тогда во время мероприятия Ignite Keynote
2022 компания Microsoft (вполне возможно, намеренно) «засветила»
интерфейс следующего большого обновления Windows. Потом об
этом зудел весь интернет, споря о том, что это могло быть. Что,
согласитесь, совсем неплохо для одного скриншота.
Изображение, «случайно» показанное на Ignite Keynote,
демонстрирует ряд нехарактерных для Windows 11 особенностей:
плавающая (а не доходящая до краев экрана) панель задач;
плавающее меню поиска; системные значки в верхней (а не
привычной нижней) части экрана справа. И интересный виджет
погоды слева вверху.
Видно, что версия будет заметно отличаться от всех предыдущих.
Коллективный разум сейчас считает, что она выйдет, скорее всего, в
2024 году, и будет называться Windows 12 как минимум из-за
большого количества разных новшеств — так же, как это было с
Windows 11.
Скорее всего, так будет выглядеть следующая ОС

Следующее крупное обновление Windows пока находится на стадии
прототипа, но источники, знакомые с ситуацией, говорят, что
показанный во время Ignite интерфейс отображает то, к чему
стремится Microsoft в следующей версии своей операционной
системы. На мероприятии показали только часть возможных
новшеств — в реальности их будет больше. Например, ожидается,
что в Windows 12 появится новый экран блокировки, новый центр
уведомлений, новый поиск. Ну и ИИ везде, где только можно.
В плане интерфейса глобальная цель — сделать его более удобным
для сенсорного ввода. У Microsoft пока всё не очень хорошо с
балансом по этой части: Windows 8 была чересчур сильно
ориентированной именно на «тач-взаимодействие», а Windows 10,
наоборот, заточена под работу с мышью и клавиатурой. В Windows
11 компания попыталась найти золотую середину, но не получилось:
всё-таки удобство управления при помощи мыши однозначно
осталось на первом месте.
Туманная перспектива
Облачная, точнее. Ходят не очень приятные слухи (впрочем, смотря
с какой стороны посмотреть). Что, мол, Windows 12 может стать

первой облачной ОС от Microsoft. В последние годы Сатья Наделла
переносит всё в сеть, в том числе MS Office. И говорит, что за этим
будущее, а «облако изменит всё». Microsoft 365 активно развивается,
в том числе за счет Windows 365, облачного компьютера, который
можно использовать на любом устройстве, способном поддерживать
браузер.
Сервис был запущен компанией в 2021 году, работать так можно как
с Windows 10, так и с Windows 11. Компания позиционирует это как
альтернативу облачным сервисам Google: теперь у неё в облаке
тоже можно и хранить данные, и редактировать документы, и даже
ходить по меню «Пуск» и папкам в привычном интерфейсе, даже
если у вас стоит Ubuntu или вы вообще сидите с планшетом на
Android. Если Windows 12 будет доступна только в виде такой
облачной платформы (по крайней мере, изначально) — это может
серьезно повысить видимость пакета 365 в глазах рядовых
пользователей. А там, глядишь, многие и задумаются, не удобнее ли
им так будет хранить данные, и продолжать работать в одной ОС с
разных устройств.
Система может быть во многом похожа на традиционные варианты
виртуальных рабочих столов, которые уже много лет
развертываются предприятиями для поддержки сценариев BYOD. Но
с более простой структурой ценообразования, удобным запуском и
ориентацией на более широкую аудиторию. Это также может стать
более контролируемым способом для Microsoft проверить
механизмы работы своих новых ИИ-помощников. При запуске
облачной ОС им не придется отпускать ИИ «гулять» на каждый из
компьютеров пользователей, все процедуры будут мониториться на
собственных серверах.
Будем надеяться, что это один из тех наборов слухов, которые скоро
будут опровергнуты. Возможно, команда поэкспериментировала с
этой идеей, и поняла, что она не приживается. Но пока что — нужно
быть морально готовыми к тому, что со всё большим числом
сервисов, в том числе от Microsoft, мы будем взаимодействовать
через окно браузера.

getmatch
Рассказываем о том, как строить карьеру в IT
Telegram
Сайт
ВКонтакте
Twitter
160
Карма
198.6
Рейтинг
@Arnak
Пользователь
P.S. Тысячи крутых вакансий в РФ и за рубежом — в телеграм-боте
getmatch. Задаете нужную зарплату, и к вам приходят лучшие
предложения, а наши эксперты помогают пройти интервью. Не нужно
ни резюме, ни портфолио, настройка занимает меньше 30 секунд. А
ещё это отличный способ следить за текущим рынком труда.
Откликаться не обязательно.
Теги:  
windows
,
microsoft
,
windows 12
,
AI
,
intel
,
chatgpt
Хабы:  
Блог компании getmatch
,
Разработка под Windows
,
Софт
,
Искусственный интеллект
+11
8
32

Комментарии 32
Публикации
ЛУЧШИЕ ЗА СУТКИ 
ПОХОЖИЕ

 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
 · 
ИНФОРМАЦИЯ
Сайт
getmatch.ru
Дата регистрации
30 июля 2020
Численность
51–100 человек
Местоположение
Россия

Ваш
аккаунт
Войти
Регистрация
Разделы
Публикации
Новости
Хабы
Компании
Авторы
Песочница
Информация
Устройство сайта
Для авторов
Для компаний
Документы
Соглашение
Конфиденциальность
Услуги
Корпоративный блог
Медийная реклама
Нативные проекты
Образовательные
программы
Стартапам
Мегапроекты
Настройка языка
Техническая поддержка
Вернуться на старую версию
© 2006–2023, Habr"
